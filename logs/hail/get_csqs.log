2022-11-07 10:53:24 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-07 10:53:25 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-07 10:53:26 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-07 10:53:26 AbstractConnector: INFO: Stopped Spark@7bca62be{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-07 10:53:26 SparkUI: INFO: Stopped Spark web UI at http://compf010.hpc.in.bmrc.ox.ac.uk:4040
2022-11-07 10:53:26 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-07 10:53:26 MemoryStore: INFO: MemoryStore cleared
2022-11-07 10:53:26 BlockManager: INFO: BlockManager stopped
2022-11-07 10:53:26 BlockManagerMaster: INFO: BlockManagerMaster stopped
2022-11-07 10:53:26 OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: INFO: OutputCommitCoordinator stopped!
2022-11-07 10:53:26 SparkContext: INFO: Successfully stopped SparkContext
2022-11-07 10:53:26 ShutdownHookManager: INFO: Shutdown hook called
2022-11-07 10:53:26 ShutdownHookManager: INFO: Deleting directory /tmp/spark-900c7bbb-7a9f-44ad-8477-1763df1adcfa
2022-11-07 10:53:26 ShutdownHookManager: INFO: Deleting directory /tmp/spark-d0c2480c-1041-4d4f-b7af-917b129629f0
2022-11-07 10:53:26 ShutdownHookManager: INFO: Deleting directory /tmp/spark-900c7bbb-7a9f-44ad-8477-1763df1adcfa/pyspark-6a4e1703-f7b9-43f6-b8a2-b3ef8442675c
2022-11-07 10:56:50 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-07 10:56:51 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-07 10:56:51 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-07 10:56:52 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-07 10:56:52 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-07 10:56:52 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compf002.hpc.in.bmrc.ox.ac.uk:39826 (size: 23.0 KB, free: 413.9 MB)
2022-11-07 10:56:52 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-07 10:56:52 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr.vcf.bgz returned 0 files: 
2022-11-07 10:56:52 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.chr.vcf.bgz' refers to no files
2022-11-07 10:56:52 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-07 10:56:52 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-07 10:56:53 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-07 10:56:53 AbstractConnector: INFO: Stopped Spark@18ab7669{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-07 10:56:53 SparkUI: INFO: Stopped Spark web UI at http://compf002.hpc.in.bmrc.ox.ac.uk:4040
2022-11-07 10:56:53 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-07 10:56:53 MemoryStore: INFO: MemoryStore cleared
2022-11-07 10:56:53 BlockManager: INFO: BlockManager stopped
2022-11-07 10:56:53 BlockManagerMaster: INFO: BlockManagerMaster stopped
2022-11-07 10:56:53 OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: INFO: OutputCommitCoordinator stopped!
2022-11-07 10:56:53 SparkContext: INFO: Successfully stopped SparkContext
2022-11-07 10:56:53 ShutdownHookManager: INFO: Shutdown hook called
2022-11-07 10:56:53 ShutdownHookManager: INFO: Deleting directory /tmp/spark-b129e030-430a-43bf-ae12-a23ccde884bf
2022-11-07 10:56:53 ShutdownHookManager: INFO: Deleting directory /tmp/spark-3e39608a-eb6e-4c15-a6a7-a726fcb941c6/pyspark-1dee7ba7-7dcf-450d-810e-0be44d480b52
2022-11-07 10:56:53 ShutdownHookManager: INFO: Deleting directory /tmp/spark-3e39608a-eb6e-4c15-a6a7-a726fcb941c6
2022-11-07 14:54:43 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-07 14:54:44 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-07 14:54:45 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-07 14:54:45 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-07 14:54:46 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-07 14:54:46 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe042.hpc.in.bmrc.ox.ac.uk:43179 (size: 23.0 KB, free: 413.9 MB)
2022-11-07 14:54:46 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-07 14:54:46 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr.vcf.bgz returned 0 files: 
2022-11-07 14:54:46 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.chr.vcf.bgz' refers to no files
2022-11-07 14:54:46 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-07 14:54:46 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-07 14:54:46 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-07 14:54:46 AbstractConnector: INFO: Stopped Spark@56104b1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-07 14:54:46 SparkUI: INFO: Stopped Spark web UI at http://compe042.hpc.in.bmrc.ox.ac.uk:4040
2022-11-07 14:54:46 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 10:45:01 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 10:45:02 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 10:45:03 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 10:45:03 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 10:45:04 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 10:45:04 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe067.hpc.in.bmrc.ox.ac.uk:38268 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 10:45:04 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 10:45:04 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr21.vcf.bgz returned 1 files: ukb_wes_450k.qced.chr21.vcf.bgz
2022-11-09 10:45:04 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.chr21.vcf.bgz returned 1 files: ukb_wes_450k.qced.chr21.vcf.bgz
2022-11-09 10:45:04 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 10:45:04 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 10:45:04 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compe067.hpc.in.bmrc.ox.ac.uk:38268 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 10:45:04 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 10:45:04 root: INFO: timing SparkBackend.parse_matrix_ir total 1.686s self 1.686s children 0.000ms %children 0.00%
2022-11-09 10:45:05 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 10:45:05 AbstractConnector: INFO: Stopped Spark@1d26a1ec{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 10:45:05 SparkUI: INFO: Stopped Spark web UI at http://compe067.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 10:45:05 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 10:45:05 MemoryStore: INFO: MemoryStore cleared
2022-11-09 10:45:05 BlockManager: INFO: BlockManager stopped
2022-11-09 10:45:05 BlockManagerMaster: INFO: BlockManagerMaster stopped
2022-11-09 10:45:05 OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: INFO: OutputCommitCoordinator stopped!
2022-11-09 10:45:05 SparkContext: INFO: Successfully stopped SparkContext
2022-11-09 10:45:05 ShutdownHookManager: INFO: Shutdown hook called
2022-11-09 10:45:05 ShutdownHookManager: INFO: Deleting directory /tmp/spark-de164619-eb03-4a45-b4eb-93c6c17429b8
2022-11-09 10:45:05 ShutdownHookManager: INFO: Deleting directory /tmp/spark-de164619-eb03-4a45-b4eb-93c6c17429b8/pyspark-78b8e419-a3a4-4ad2-a2f3-1b536b747eff
2022-11-09 10:45:05 ShutdownHookManager: INFO: Deleting directory /tmp/spark-a608f14e-31f1-4c9b-a193-3896b8e0b835
2022-11-09 10:47:09 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 10:47:10 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 10:47:10 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 10:47:11 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 10:47:11 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 10:47:11 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe071.hpc.in.bmrc.ox.ac.uk:45862 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 10:47:11 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 10:47:11 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr21.vcf.bgz returned 1 files: ukb_wes_450k.qced.chr21.vcf.bgz
2022-11-09 10:47:11 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.chr21.vcf.bgz returned 1 files: ukb_wes_450k.qced.chr21.vcf.bgz
2022-11-09 10:47:12 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 10:47:12 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 10:47:12 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compe071.hpc.in.bmrc.ox.ac.uk:45862 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 10:47:12 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 10:47:12 root: INFO: timing SparkBackend.parse_matrix_ir total 1.721s self 1.721s children 0.000ms %children 0.00%
2022-11-09 10:47:12 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 10:47:12 AbstractConnector: INFO: Stopped Spark@20032fa7{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 10:47:12 SparkUI: INFO: Stopped Spark web UI at http://compe071.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 10:47:12 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 10:47:12 MemoryStore: INFO: MemoryStore cleared
2022-11-09 10:47:12 BlockManager: INFO: BlockManager stopped
2022-11-09 10:47:13 BlockManagerMaster: INFO: BlockManagerMaster stopped
2022-11-09 10:47:13 OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: INFO: OutputCommitCoordinator stopped!
2022-11-09 10:47:13 SparkContext: INFO: Successfully stopped SparkContext
2022-11-09 10:47:13 ShutdownHookManager: INFO: Shutdown hook called
2022-11-09 10:47:13 ShutdownHookManager: INFO: Deleting directory /tmp/spark-521c4ee8-f1df-49bc-8e40-c5043283ac04
2022-11-09 10:47:13 ShutdownHookManager: INFO: Deleting directory /tmp/spark-42160785-af0f-4f05-80a1-2dea569e99da
2022-11-09 10:47:13 ShutdownHookManager: INFO: Deleting directory /tmp/spark-521c4ee8-f1df-49bc-8e40-c5043283ac04/pyspark-8f9bc488-3ba1-4cdb-90b8-13878293c7e4
2022-11-09 11:30:57 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 11:30:58 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 11:30:59 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 11:31:00 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 11:31:00 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 11:31:00 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compa020.hpc.in.bmrc.ox.ac.uk:45574 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 11:31:00 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 11:31:01 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr21.vcf.bgz returned 1 files: ukb_wes_450k.qced.chr21.vcf.bgz
2022-11-09 11:31:01 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.chr21.vcf.bgz returned 1 files: ukb_wes_450k.qced.chr21.vcf.bgz
2022-11-09 11:31:01 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 11:31:01 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 11:31:01 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compa020.hpc.in.bmrc.ox.ac.uk:45574 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 11:31:01 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 11:31:01 root: INFO: timing SparkBackend.parse_matrix_ir total 2.425s self 2.425s children 0.000ms %children 0.00%
2022-11-09 11:31:01 root: INFO: timing SparkBackend.parse_value_ir total 26.639ms self 26.639ms children 0.000ms %children 0.00%
2022-11-09 11:31:01 root: INFO: starting execution of query hail_query_1 of initial size 3
2022-11-09 11:31:02 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 3: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr21.ht\",\"overwrite\":false,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead None False False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.chr21.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-09 11:31:02 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 3:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr21.ht\",\"overwrite\":false,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead None True False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.chr21.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-09 11:31:02 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 16: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr21.ht\",\"overwrite\":false,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (TableMapGlobals
      (TableMapGlobals
        (TableMapRows
          (TableRead None False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.chr21.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
          (InsertFields
            (Ref row)
            None
            (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
              (MakeArray Array[Struct{}]))))
        (InsertFields
          (Ref global)
          None
          (__cols (MakeArray Array[Struct{s:String}]))))
      (SelectFields () (Ref global)))
    (SelectFields 
      (locus alleles rsid qual filters info)
      (Ref row))))
2022-11-09 11:31:02 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-09 11:31:02 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 2:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr21.ht\",\"overwrite\":false,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableRead
    Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],info:Struct{}}}
    False
    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.chr21.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
2022-11-09 11:31:02 root: INFO: interpreting non compilable node: TableWrite
2022-11-09 11:31:02 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-09 11:31:02 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-09 11:31:02 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-09 11:31:02 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 11:31:02 DAGScheduler: INFO: Missing parents: List()
2022-11-09 11:31:02 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-09 11:31:02 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-09 11:31:02 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-09 11:31:02 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compa020.hpc.in.bmrc.ox.ac.uk:45574 (size: 7.4 KB, free: 413.8 MB)
2022-11-09 11:31:02 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-09 11:31:03 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-09 11:31:03 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-09 11:31:03 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2022-11-09 11:31:03 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-09 11:31:03 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-09 11:31:03 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 11:31:03 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 11:31:03 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 11:31:05 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1504 bytes result sent to driver
2022-11-09 11:31:05 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 2449 ms on localhost (executor driver) (1/1)
2022-11-09 11:31:05 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 2.631 s
2022-11-09 11:31:05 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-09 11:31:05 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 2.756250 s
2022-11-09 11:31:05 Hail: INFO: Coerced sorted dataset
2022-11-09 11:31:05 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-09 11:31:06 root: INFO: instruction count: 3: __C1etypeEncode.<init>
2022-11-09 11:31:06 root: INFO: instruction count: 5: __C1etypeEncode.apply
2022-11-09 11:31:06 root: INFO: instruction count: 3: __C1etypeEncode.__m2ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 11:31:06 root: INFO: instruction count: 3: __C3indexwriter.<init>
2022-11-09 11:31:06 root: INFO: instruction count: 234: __C3indexwriter.apply
2022-11-09 11:31:06 root: INFO: instruction count: 445: __C3indexwriter.__m12writeInternalNode
2022-11-09 11:31:06 root: INFO: instruction count: 13: __C3indexwriter.__m13ENCODE_o_tuple_of_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 11:31:06 root: INFO: instruction count: 49: __C3indexwriter.__m14ENCODE_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 11:31:06 root: INFO: instruction count: 45: __C3indexwriter.__m15ENCODE_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 11:31:06 root: INFO: instruction count: 4: __C3indexwriter.__m16ENCODE_r_int64_TO_r_int64
2022-11-09 11:31:06 root: INFO: instruction count: 19: __C3indexwriter.__m17ENCODE_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 11:31:06 root: INFO: instruction count: 23: __C3indexwriter.__m18ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 11:31:06 root: INFO: instruction count: 16: __C3indexwriter.__m19ENCODE_r_binary_TO_r_binary
2022-11-09 11:31:06 root: INFO: instruction count: 4: __C3indexwriter.__m20ENCODE_r_int32_TO_r_int32
2022-11-09 11:31:06 root: INFO: instruction count: 53: __C3indexwriter.__m21ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 11:31:06 root: INFO: instruction count: 3: __C3indexwriter.__m22ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 11:31:06 root: INFO: instruction count: 379: __C3indexwriter.__m23writeLeafNode
2022-11-09 11:31:06 root: INFO: instruction count: 23: __C3indexwriter.__m24ENCODE_o_tuple_of_r_int64ANDr_array_of_r_tuple_of_r_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_int64ANDr_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 11:31:06 root: INFO: instruction count: 49: __C3indexwriter.__m25ENCODE_r_array_of_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 11:31:06 root: INFO: instruction count: 25: __C3indexwriter.__m26ENCODE_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 11:31:06 root: INFO: instruction count: 52: __C3indexwriter.__m27flush
2022-11-09 11:31:06 root: INFO: instruction count: 150: __C3indexwriter.init
2022-11-09 11:31:06 root: INFO: instruction count: 4: __C3indexwriter.setObjects
2022-11-09 11:31:06 root: INFO: instruction count: 28: __C3indexwriter.close
2022-11-09 11:31:06 root: INFO: instruction count: 7: __C3indexwriter.trackedOS
2022-11-09 11:31:06 root: INFO: instruction count: 9: __C3indexwriter.setPartitionIndex
2022-11-09 11:31:06 root: INFO: instruction count: 4: __C3indexwriter.addPartitionRegion
2022-11-09 11:31:06 root: INFO: instruction count: 3: __C29FSContainer.<init>
2022-11-09 11:31:06 root: INFO: instruction count: 28: __C29FSContainer.init_filesystem
2022-11-09 11:31:06 root: INFO: instruction count: 3: __C29FSContainer.<clinit>
2022-11-09 11:31:06 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-09 11:31:06 root: INFO: instruction count: 3: __C32etypeEncode.<init>
2022-11-09 11:31:06 root: INFO: instruction count: 5: __C32etypeEncode.apply
2022-11-09 11:31:06 root: INFO: instruction count: 94: __C32etypeEncode.__m33ENCODE_r_tuple_of_r_locusANDr_array_of_r_stringANDo_stringANDo_float64ANDo_set_of_r_stringANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryANDo_binaryANDo_float64ANDo_array_of_r_binaryANDr_struct_of_ENDEND
2022-11-09 11:31:06 root: INFO: instruction count: 23: __C32etypeEncode.__m34ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 11:31:06 root: INFO: instruction count: 16: __C32etypeEncode.__m35ENCODE_r_binary_TO_r_binary
2022-11-09 11:31:06 root: INFO: instruction count: 4: __C32etypeEncode.__m36ENCODE_r_int32_TO_r_int32
2022-11-09 11:31:06 root: INFO: instruction count: 53: __C32etypeEncode.__m37ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 11:31:06 root: INFO: instruction count: 16: __C32etypeEncode.__m38ENCODE_o_binary_TO_o_binary
2022-11-09 11:31:06 root: INFO: instruction count: 4: __C32etypeEncode.__m39ENCODE_o_float64_TO_o_float64
2022-11-09 11:31:06 root: INFO: instruction count: 53: __C32etypeEncode.__m40ENCODE_o_array_of_r_binary_TO_o_array_of_r_binary
2022-11-09 11:31:06 root: INFO: instruction count: 3: __C32etypeEncode.__m41ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-09 11:31:07 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compa020.hpc.in.bmrc.ox.ac.uk:45574 in memory (size: 7.4 KB, free: 413.8 MB)
2022-11-09 11:31:07 SparkContext: INFO: Starting job: collect at ContextRDD.scala:166
2022-11-09 11:31:07 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:166) with 1 output partitions
2022-11-09 11:31:07 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:166)
2022-11-09 11:31:07 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 11:31:07 DAGScheduler: INFO: Missing parents: List()
2022-11-09 11:31:07 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-09 11:31:07 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 316.6 KB, free 411.6 MB)
2022-11-09 11:31:07 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 116.6 KB, free 411.5 MB)
2022-11-09 11:31:07 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compa020.hpc.in.bmrc.ox.ac.uk:45574 (size: 116.6 KB, free: 413.7 MB)
2022-11-09 11:31:07 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-09 11:31:07 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-09 11:31:07 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-09 11:31:07 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8047 bytes)
2022-11-09 11:31:07 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-09 11:31:07 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-09 11:31:07 root: INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 11:31:08 root: INFO: RegionPool: REPORT_THRESHOLD: 4.0M allocated (3.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 11:31:09 root: INFO: RegionPool: REPORT_THRESHOLD: 8.0M allocated (7.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 11:31:11 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 916 bytes result sent to driver
2022-11-09 11:31:11 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 3835 ms on localhost (executor driver) (1/1)
2022-11-09 11:31:11 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:166) finished in 3.899 s
2022-11-09 11:31:11 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:166, took 3.907576 s
2022-11-09 11:31:11 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-09 11:31:11 Hail: INFO: wrote table with 190854 rows in 1 partition to data/ht/ukb_wes_450k.qced.chr21.ht
    Total size: 3.90 MiB
    * Rows: 3.90 MiB
    * Globals: 11.00 B
    * Smallest partition: 190854 rows (3.90 MiB)
    * Largest partition:  190854 rows (3.90 MiB)
2022-11-09 11:31:11 root: INFO: took 9.374s
2022-11-09 11:31:11 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 1: 
(Begin)
2022-11-09 11:31:11 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Begin)
2022-11-09 11:31:11 root: INFO: finished execution of query hail_query_1
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON total 9.791s self 140.258ms children 9.650s %children 98.57%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 143.458ms self 0.822ms children 142.635ms %children 99.43%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.408ms self 0.408ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 142.190ms self 71.939ms children 70.251ms %children 49.41%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 70.251ms self 4.657ms children 65.594ms %children 93.37%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 5.152ms self 5.152ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 6.870ms self 6.870ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 17.043ms self 17.043ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 11.088ms self 11.088ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 2.077ms self 2.077ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 21.856ms self 21.856ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.160ms self 0.160ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.023ms self 0.023ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.081ms self 0.081ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.472ms self 0.472ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.029ms self 0.029ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.742ms self 0.742ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.038ms self 0.038ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 36.389ms self 0.033ms children 36.356ms %children 99.91%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.006ms self 0.006ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 35.868ms self 35.868ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.482ms self 0.482ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 91.479ms self 0.066ms children 91.413ms %children 99.93%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.031ms self 0.031ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 91.323ms self 36.910ms children 54.413ms %children 59.58%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 54.413ms self 0.160ms children 54.253ms %children 99.71%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 9.292ms self 9.292ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.376ms self 0.376ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 28.693ms self 28.693ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 1.647ms self 1.647ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.073ms self 0.073ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 11.678ms self 11.678ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.288ms self 0.288ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.208ms self 0.208ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.297ms self 0.297ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.400ms self 0.400ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.029ms self 0.029ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.383ms self 0.383ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.107ms self 0.107ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.035ms self 0.035ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.050ms self 0.050ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.334ms self 0.334ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.024ms self 0.024ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.339ms self 0.339ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.059ms self 0.059ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 9.377s self 0.032ms children 9.377s %children 100.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.012ms self 0.012ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 9.376s self 9.376s children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.527ms self 0.527ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 2.052ms self 0.016ms children 2.036ms %children 99.20%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.011ms self 0.011ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 2.015ms self 0.937ms children 1.078ms %children 53.48%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 1.078ms self 0.063ms children 1.015ms %children 94.15%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.136ms self 0.136ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.382ms self 0.382ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.088ms self 0.088ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.259ms self 0.259ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.030ms self 0.030ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.120ms self 0.120ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.010ms self 0.010ms children 0.000ms %children 0.00%
2022-11-09 11:31:11 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.028ms self 0.028ms children 0.000ms %children 0.00%
2022-11-09 11:31:12 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 11:31:12 AbstractConnector: INFO: Stopped Spark@6f15eddc{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 11:31:12 SparkUI: INFO: Stopped Spark web UI at http://compa020.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 11:31:12 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 11:31:12 MemoryStore: INFO: MemoryStore cleared
2022-11-09 11:31:12 BlockManager: INFO: BlockManager stopped
2022-11-09 11:31:12 BlockManagerMaster: INFO: BlockManagerMaster stopped
2022-11-09 11:31:12 OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: INFO: OutputCommitCoordinator stopped!
2022-11-09 11:31:12 SparkContext: INFO: Successfully stopped SparkContext
2022-11-09 11:31:12 ShutdownHookManager: INFO: Shutdown hook called
2022-11-09 11:31:12 ShutdownHookManager: INFO: Deleting directory /tmp/spark-237aa94f-b69c-4833-bc16-ad0ec0da1e80
2022-11-09 11:31:12 ShutdownHookManager: INFO: Deleting directory /tmp/spark-c097deb4-0d61-415c-abf7-1c6e5782a018/pyspark-0a52b7c6-2c91-4720-9e64-3d1b044f1817
2022-11-09 11:31:12 ShutdownHookManager: INFO: Deleting directory /tmp/spark-c097deb4-0d61-415c-abf7-1c6e5782a018
2022-11-09 11:46:56 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 11:46:57 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 11:46:58 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 11:46:58 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 11:46:59 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 11:46:59 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe057.hpc.in.bmrc.ox.ac.uk:46128 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 11:46:59 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 11:46:59 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr21.vcf.bgz returned 1 files: ukb_wes_450k.qced.chr21.vcf.bgz
2022-11-09 11:46:59 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.chr21.vcf.bgz returned 1 files: ukb_wes_450k.qced.chr21.vcf.bgz
2022-11-09 11:46:59 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 11:46:59 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 11:46:59 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compe057.hpc.in.bmrc.ox.ac.uk:46128 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 11:46:59 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 11:46:59 root: INFO: timing SparkBackend.parse_matrix_ir total 1.637s self 1.637s children 0.000ms %children 0.00%
2022-11-09 11:47:00 root: INFO: timing SparkBackend.parse_value_ir total 267.975ms self 267.975ms children 0.000ms %children 0.00%
2022-11-09 11:47:00 root: INFO: starting execution of query hail_query_1 of initial size 41
2022-11-09 11:47:00 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 41: 
(GetField rows
  (TableCollect
    (TableHead 11
      (TableMapRows
        (TableMapRows
          (TableOrderBy (Alocus Aalleles)
            (MatrixRowsTable
              (MatrixRead None False False
                "{\"files\":[\"data/vcf/ukb_wes_450k.qced.chr21.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
          (InsertFields
            (SelectFields ()
              (SelectFields 
                (locus alleles rsid qual filters info)
                (Ref row)))
            None
            (locus (GetField locus (Ref row)))
            (alleles (GetField alleles (Ref row)))
            (rsid (GetField rsid (Ref row)))
            (qual (GetField qual (Ref row)))
            (filters (GetField filters (Ref row)))))
        (InsertFields
          (SelectFields ()
            (SelectFields (locus alleles rsid qual filters)
              (Ref row)))
          None
          (locus
            (ApplySpecial showStr () String
              (GetField locus (Ref row))))
          (alleles
            (ApplySpecial showStr () String
              (GetField alleles (Ref row))))
          (rsid
            (ApplySpecial showStr () String
              (GetField rsid (Ref row))))
          (qual
            (ApplySpecial showStr () String
              (GetField qual (Ref row))))
          (filters
            (ApplySpecial showStr () String
              (GetField filters (Ref row)))))))))
2022-11-09 11:47:00 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 25:
(GetField rows
  (TableCollect
    (TableMapRows
      (TableHead 11
        (TableOrderBy (Alocus Aalleles)
          (MatrixRowsTable
            (MatrixRead
              Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String]},entry:Struct{}}
              True False
              "{\"files\":[\"data/vcf/ukb_wes_450k.qced.chr21.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))))
      (InsertFields
        (SelectFields () (Ref row))
        None
        (locus
          (ApplySpecial showStr () String
            (GetField locus (Ref row))))
        (alleles
          (ApplySpecial showStr () String
            (GetField alleles (Ref row))))
        (rsid
          (ApplySpecial showStr () String
            (GetField rsid (Ref row))))
        (qual
          (ApplySpecial showStr () String
            (GetField qual (Ref row))))
        (filters
          (ApplySpecial showStr () String
            (GetField filters (Ref row))))))))
2022-11-09 11:47:00 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 38: 
(GetField rows
  (TableCollect
    (TableMapRows
      (TableHead 11
        (TableOrderBy (Alocus Aalleles)
          (TableMapRows
            (TableMapGlobals
              (TableMapGlobals
                (TableMapRows
                  (TableRead
                    Table{global:Struct{__cols:Array[Struct{s:String}]},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String],`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{}]}}
                    False
                    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.chr21.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
                  (InsertFields
                    (Ref row)
                    None
                    (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
                      (MakeArray Array[Struct{}]))))
                (InsertFields
                  (Ref global)
                  None
                  (__cols (MakeArray Array[Struct{s:String}]))))
              (SelectFields () (Ref global)))
            (SelectFields (locus alleles rsid qual filters)
              (Ref row)))))
      (InsertFields
        (SelectFields () (Ref row))
        None
        (locus
          (ApplySpecial showStr () String
            (GetField locus (Ref row))))
        (alleles
          (ApplySpecial showStr () String
            (GetField alleles (Ref row))))
        (rsid
          (ApplySpecial showStr () String
            (GetField rsid (Ref row))))
        (qual
          (ApplySpecial showStr () String
            (GetField qual (Ref row))))
        (filters
          (ApplySpecial showStr () String
            (GetField filters (Ref row))))))))
2022-11-09 11:47:00 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-09 11:47:00 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 24:
(GetField rows
  (TableCollect
    (TableMapRows
      (TableHead 11
        (TableOrderBy (Alocus Aalleles)
          (TableRead
            Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],rsid:String,qual:Float64,filters:Set[String]}}
            False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.chr21.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
      (InsertFields
        (SelectFields () (Ref row))
        None
        (locus
          (ApplySpecial showStr () String
            (GetField locus (Ref row))))
        (alleles
          (ApplySpecial showStr () String
            (GetField alleles (Ref row))))
        (rsid
          (ApplySpecial showStr () String
            (GetField rsid (Ref row))))
        (qual
          (ApplySpecial showStr () String
            (GetField qual (Ref row))))
        (filters
          (ApplySpecial showStr () String
            (GetField filters (Ref row))))))))
2022-11-09 11:47:00 root: INFO: interpreting non compilable node: TableCollect
2022-11-09 11:47:00 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-09 11:47:00 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-09 11:47:00 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-09 11:47:00 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 11:47:00 DAGScheduler: INFO: Missing parents: List()
2022-11-09 11:47:00 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-09 11:47:01 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-09 11:47:01 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-09 11:47:01 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compe057.hpc.in.bmrc.ox.ac.uk:46128 (size: 7.4 KB, free: 413.8 MB)
2022-11-09 11:47:01 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-09 11:47:01 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-09 11:47:01 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-09 11:47:01 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2022-11-09 11:47:01 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-09 11:47:01 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-09 11:47:01 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 11:47:01 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 11:47:01 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 11:47:02 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1504 bytes result sent to driver
2022-11-09 11:47:03 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 1907 ms on localhost (executor driver) (1/1)
2022-11-09 11:47:03 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 2.062 s
2022-11-09 11:47:03 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 2.112934 s
2022-11-09 11:47:03 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-09 11:47:03 Hail: INFO: Coerced sorted dataset
2022-11-09 11:47:03 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:351
2022-11-09 11:47:03 DAGScheduler: INFO: Got job 1 (runJob at ContextRDD.scala:351) with 1 output partitions
2022-11-09 11:47:03 DAGScheduler: INFO: Final stage: ResultStage 1 (runJob at ContextRDD.scala:351)
2022-11-09 11:47:03 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 11:47:03 DAGScheduler: INFO: Missing parents: List()
2022-11-09 11:47:03 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at ContextRDD.scala:239), which has no missing parents
2022-11-09 11:47:03 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 131.0 KB, free 411.7 MB)
2022-11-09 11:47:03 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 42.6 KB, free 411.7 MB)
2022-11-09 11:47:03 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compe057.hpc.in.bmrc.ox.ac.uk:46128 (size: 42.6 KB, free: 413.7 MB)
2022-11-09 11:47:03 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-09 11:47:03 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[2] at mapPartitions at ContextRDD.scala:239) (first 15 tasks are for partitions Vector(0))
2022-11-09 11:47:03 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-09 11:47:03 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8047 bytes)
2022-11-09 11:47:03 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-09 11:47:03 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 666 bytes result sent to driver
2022-11-09 11:47:03 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 103 ms on localhost (executor driver) (1/1)
2022-11-09 11:47:03 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-09 11:47:03 DAGScheduler: INFO: ResultStage 1 (runJob at ContextRDD.scala:351) finished in 0.128 s
2022-11-09 11:47:03 DAGScheduler: INFO: Job 1 finished: runJob at ContextRDD.scala:351, took 0.134312 s
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 47
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 40
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 45
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-09 11:47:03 root: INFO: optimize optimize: compileLowerer, initial IR: before: IR size 21: 
(Coalesce
  (InsertFields
    (SelectFields ()
      (In
        +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
        1))
    None
    (locus
      (ApplySpecial showStr () String
        (GetField locus
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1))))
    (alleles
      (ApplySpecial showStr () String
        (GetField alleles
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1))))
    (rsid
      (ApplySpecial showStr () String
        (GetField rsid
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1))))
    (qual
      (ApplySpecial showStr () String
        (GetField qual
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1))))
    (filters
      (ApplySpecial showStr () String
        (GetField filters
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1)))))
  (Die
    Struct{locus:String,alleles:String,rsid:String,qual:String,filters:String}
    -1
    (Str "Internal e...")))
2022-11-09 11:47:03 root: INFO: optimize optimize: compileLowerer, initial IR: after: IR size 21:
(Coalesce
  (InsertFields
    (SelectFields ()
      (In
        +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
        1))
    None
    (locus
      (ApplySpecial showStr () String
        (GetField locus
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1))))
    (alleles
      (ApplySpecial showStr () String
        (GetField alleles
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1))))
    (rsid
      (ApplySpecial showStr () String
        (GetField rsid
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1))))
    (qual
      (ApplySpecial showStr () String
        (GetField qual
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1))))
    (filters
      (ApplySpecial showStr () String
        (GetField filters
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1)))))
  (Die
    Struct{locus:String,alleles:String,rsid:String,qual:String,filters:String}
    -1
    (Str "Internal e...")))
2022-11-09 11:47:03 root: INFO: optimize optimize: compileLowerer, after InlineApplyIR: before: IR size 21: 
(Coalesce
  (InsertFields
    (SelectFields ()
      (In
        +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
        1))
    None
    (locus
      (ApplySpecial showStr () String
        (GetField locus
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1))))
    (alleles
      (ApplySpecial showStr () String
        (GetField alleles
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1))))
    (rsid
      (ApplySpecial showStr () String
        (GetField rsid
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1))))
    (qual
      (ApplySpecial showStr () String
        (GetField qual
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1))))
    (filters
      (ApplySpecial showStr () String
        (GetField filters
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1)))))
  (Die
    Struct{locus:String,alleles:String,rsid:String,qual:String,filters:String}
    -1
    (Str "Internal e...")))
2022-11-09 11:47:03 root: INFO: optimize optimize: compileLowerer, after InlineApplyIR: after: IR size 21:
(Coalesce
  (InsertFields
    (SelectFields ()
      (In
        +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
        1))
    None
    (locus
      (ApplySpecial showStr () String
        (GetField locus
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1))))
    (alleles
      (ApplySpecial showStr () String
        (GetField alleles
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1))))
    (rsid
      (ApplySpecial showStr () String
        (GetField rsid
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1))))
    (qual
      (ApplySpecial showStr () String
        (GetField qual
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1))))
    (filters
      (ApplySpecial showStr () String
        (GetField filters
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1)))))
  (Die
    Struct{locus:String,alleles:String,rsid:String,qual:String,filters:String}
    -1
    (Str "Internal e...")))
2022-11-09 11:47:03 root: INFO: optimize optimize: compileLowerer, after LowerArrayAggsToRunAggs: before: IR size 21: 
(Coalesce
  (InsertFields
    (SelectFields ()
      (In
        +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
        1))
    None
    (locus
      (ApplySpecial showStr () String
        (GetField locus
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1))))
    (alleles
      (ApplySpecial showStr () String
        (GetField alleles
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1))))
    (rsid
      (ApplySpecial showStr () String
        (GetField rsid
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1))))
    (qual
      (ApplySpecial showStr () String
        (GetField qual
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1))))
    (filters
      (ApplySpecial showStr () String
        (GetField filters
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1)))))
  (Die
    Struct{locus:String,alleles:String,rsid:String,qual:String,filters:String}
    -1
    (Str "Internal e...")))
2022-11-09 11:47:03 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compe057.hpc.in.bmrc.ox.ac.uk:46128 in memory (size: 7.4 KB, free: 413.7 MB)
2022-11-09 11:47:03 root: INFO: optimize optimize: compileLowerer, after LowerArrayAggsToRunAggs: after: IR size 21:
(Coalesce
  (InsertFields
    (SelectFields ()
      (In
        +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
        1))
    None
    (locus
      (ApplySpecial showStr () String
        (GetField locus
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1))))
    (alleles
      (ApplySpecial showStr () String
        (GetField alleles
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1))))
    (rsid
      (ApplySpecial showStr () String
        (GetField rsid
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1))))
    (qual
      (ApplySpecial showStr () String
        (GetField qual
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1))))
    (filters
      (ApplySpecial showStr () String
        (GetField filters
          (In
            +PCStruct{locus:+PCLocus(GRCh38),alleles:+PCArray[+PCString],rsid:PCString,qual:PFloat64,filters:PCSet[+PCString]}
            1)))))
  (Die
    Struct{locus:String,alleles:String,rsid:String,qual:String,filters:String}
    -1
    (Str "Internal e...")))
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 42
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 36
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 43
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 28
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 44
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 31
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 37
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 34
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 33
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 35
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 27
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 49
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 38
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 29
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 48
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 50
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 26
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 41
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 39
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 46
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 30
2022-11-09 11:47:03 ContextCleaner: INFO: Cleaned accumulator 32
2022-11-09 11:47:04 BlockManagerInfo: INFO: Removed broadcast_3_piece0 on compe057.hpc.in.bmrc.ox.ac.uk:46128 in memory (size: 42.6 KB, free: 413.8 MB)
2022-11-09 11:47:04 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-09 11:47:04 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-09 11:47:04 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-09 11:47:04 root: INFO: instruction count: 3: __C46etypeEncode.<init>
2022-11-09 11:47:04 root: INFO: instruction count: 5: __C46etypeEncode.apply
2022-11-09 11:47:04 root: INFO: instruction count: 13: __C46etypeEncode.__m47ENCODE_r_tuple_of_r_stringEND_TO_r_struct_of_r_binaryEND
2022-11-09 11:47:04 root: INFO: instruction count: 16: __C46etypeEncode.__m48ENCODE_r_binary_TO_r_binary
2022-11-09 11:47:04 MemoryStore: INFO: Block broadcast_4 stored as values in memory (estimated size 128.0 B, free 411.9 MB)
2022-11-09 11:47:04 MemoryStore: INFO: Block broadcast_4_piece0 stored as bytes in memory (estimated size 115.0 B, free 411.9 MB)
2022-11-09 11:47:04 BlockManagerInfo: INFO: Added broadcast_4_piece0 in memory on compe057.hpc.in.bmrc.ox.ac.uk:46128 (size: 115.0 B, free: 413.8 MB)
2022-11-09 11:47:04 SparkContext: INFO: Created broadcast 4 from broadcast at SparkBackend.scala:250
2022-11-09 11:47:04 root: INFO: instruction count: 3: __C1Compiled.<init>
2022-11-09 11:47:04 root: INFO: instruction count: 578: __C1Compiled.apply
2022-11-09 11:47:04 root: INFO: instruction count: 23: __C1Compiled.__m11setup_null
2022-11-09 11:47:04 root: INFO: instruction count: 5: __C1Compiled.__m14addIRIntermediate
2022-11-09 11:47:04 root: INFO: instruction count: 12: __C1Compiled.__m17setup_null
2022-11-09 11:47:04 root: INFO: instruction count: 12: __C1Compiled.__m20setup_null
2022-11-09 11:47:04 root: INFO: instruction count: 12: __C1Compiled.__m25setup_null
2022-11-09 11:47:04 root: INFO: instruction count: 12: __C1Compiled.__m30setup_null
2022-11-09 11:47:04 root: INFO: instruction count: 12: __C1Compiled.__m35setup_null
2022-11-09 11:47:04 root: INFO: instruction count: 12: __C1Compiled.__m38setup_null
2022-11-09 11:47:04 root: INFO: instruction count: 9: __C1Compiled.setPartitionIndex
2022-11-09 11:47:04 root: INFO: instruction count: 4: __C1Compiled.addPartitionRegion
2022-11-09 11:47:04 root: INFO: instruction count: 23: __C1Compiled.__m44DECODE_r_struct_of_r_binaryEND_TO_r_tuple_of_r_stringEND
2022-11-09 11:47:04 root: INFO: instruction count: 31: __C1Compiled.__m45INPLACE_DECODE_r_binary_TO_r_binary
2022-11-09 11:47:04 root: INFO: instruction count: 36: __C1Compiled.addLiterals
2022-11-09 11:47:04 root: INFO: instruction count: 3: __C49applySpills.<init>
2022-11-09 11:47:04 root: INFO: instruction count: 3: __C8RGContainer_GRCh38.<init>
2022-11-09 11:47:04 root: INFO: instruction count: 15: __C8RGContainer_GRCh38.<clinit>
2022-11-09 11:47:04 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-09 11:47:04 root: INFO: instruction count: 3: __C53etypeEncode.<init>
2022-11-09 11:47:04 root: INFO: instruction count: 5: __C53etypeEncode.apply
2022-11-09 11:47:04 root: INFO: instruction count: 53: __C53etypeEncode.__m54ENCODE_r_tuple_of_r_stringANDr_stringANDr_stringANDr_stringANDr_stringEND_TO_r_struct_of_r_binaryANDr_binaryANDr_binaryANDr_binaryANDr_binaryEND
2022-11-09 11:47:04 root: INFO: instruction count: 16: __C53etypeEncode.__m55ENCODE_r_binary_TO_r_binary
2022-11-09 11:47:04 SparkContext: INFO: Starting job: collect at RVD.scala:762
2022-11-09 11:47:04 DAGScheduler: INFO: Got job 2 (collect at RVD.scala:762) with 1 output partitions
2022-11-09 11:47:04 DAGScheduler: INFO: Final stage: ResultStage 2 (collect at RVD.scala:762)
2022-11-09 11:47:04 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 11:47:04 DAGScheduler: INFO: Missing parents: List()
2022-11-09 11:47:04 DAGScheduler: INFO: Submitting ResultStage 2 (MapPartitionsRDD[8] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-09 11:47:04 MemoryStore: INFO: Block broadcast_5 stored as values in memory (estimated size 307.8 KB, free 411.6 MB)
2022-11-09 11:47:04 MemoryStore: INFO: Block broadcast_5_piece0 stored as bytes in memory (estimated size 87.4 KB, free 411.5 MB)
2022-11-09 11:47:04 BlockManagerInfo: INFO: Added broadcast_5_piece0 in memory on compe057.hpc.in.bmrc.ox.ac.uk:46128 (size: 87.4 KB, free: 413.7 MB)
2022-11-09 11:47:04 SparkContext: INFO: Created broadcast 5 from broadcast at DAGScheduler.scala:1161
2022-11-09 11:47:04 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[8] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-09 11:47:04 TaskSchedulerImpl: INFO: Adding task set 2.0 with 1 tasks
2022-11-09 11:47:04 TaskSetManager: INFO: Starting task 0.0 in stage 2.0 (TID 2, localhost, executor driver, partition 0, PROCESS_LOCAL, 8141 bytes)
2022-11-09 11:47:04 Executor: INFO: Running task 0.0 in stage 2.0 (TID 2)
2022-11-09 11:47:04 Executor: INFO: Finished task 0.0 in stage 2.0 (TID 2). 1280 bytes result sent to driver
2022-11-09 11:47:04 TaskSetManager: INFO: Finished task 0.0 in stage 2.0 (TID 2) in 77 ms on localhost (executor driver) (1/1)
2022-11-09 11:47:04 TaskSchedulerImpl: INFO: Removed TaskSet 2.0, whose tasks have all completed, from pool 
2022-11-09 11:47:04 DAGScheduler: INFO: ResultStage 2 (collect at RVD.scala:762) finished in 0.092 s
2022-11-09 11:47:04 DAGScheduler: INFO: Job 2 finished: collect at RVD.scala:762, took 0.096566 s
2022-11-09 11:47:04 root: INFO: decoder cache miss (0 hits, 1 misses, 0.000
2022-11-09 11:47:04 root: INFO: instruction count: 3: __C56etypeDecode.<init>
2022-11-09 11:47:04 root: INFO: instruction count: 5: __C56etypeDecode.apply
2022-11-09 11:47:04 root: INFO: instruction count: 51: __C56etypeDecode.__m57DECODE_r_struct_of_r_binaryANDr_binaryANDr_binaryANDr_binaryANDr_binaryEND_TO_r_tuple_of_r_stringANDr_stringANDr_stringANDr_stringANDr_stringEND
2022-11-09 11:47:04 root: INFO: instruction count: 31: __C56etypeDecode.__m58INPLACE_DECODE_r_binary_TO_r_binary
2022-11-09 11:47:04 root: INFO: took 4.111s
2022-11-09 11:47:04 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 2: 
(GetField rows
  (Literal
    Struct{rows:Array[Struct{locus:String,alleles:String,rsid:String,qual:String,filters:String}],global:Struct{}}
    <literal value>))
2022-11-09 11:47:04 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Literal
  Array[Struct{locus:String,alleles:String,rsid:String,qual:String,filters:String}]
  <literal value>)
2022-11-09 11:47:04 root: INFO: optimize optimize: compileLowerer, initial IR: before: IR size 2: 
(MakeTuple (0)
  (Literal
    Array[Struct{locus:String,alleles:String,rsid:String,qual:String,filters:String}]
    <literal value>))
2022-11-09 11:47:04 root: INFO: optimize optimize: compileLowerer, initial IR: after: IR size 1:
(Literal
  Tuple[Array[Struct{locus:String,alleles:String,rsid:String,qual:String,filters:String}]]
  <literal value>)
2022-11-09 11:47:04 root: INFO: optimize optimize: compileLowerer, after InlineApplyIR: before: IR size 1: 
(Literal
  Tuple[Array[Struct{locus:String,alleles:String,rsid:String,qual:String,filters:String}]]
  <literal value>)
2022-11-09 11:47:04 root: INFO: optimize optimize: compileLowerer, after InlineApplyIR: after: IR size 1:
(Literal
  Tuple[Array[Struct{locus:String,alleles:String,rsid:String,qual:String,filters:String}]]
  <literal value>)
2022-11-09 11:47:04 root: INFO: optimize optimize: compileLowerer, after LowerArrayAggsToRunAggs: before: IR size 1: 
(Literal
  Tuple[Array[Struct{locus:String,alleles:String,rsid:String,qual:String,filters:String}]]
  <literal value>)
2022-11-09 11:47:04 root: INFO: optimize optimize: compileLowerer, after LowerArrayAggsToRunAggs: after: IR size 1:
(Literal
  Tuple[Array[Struct{locus:String,alleles:String,rsid:String,qual:String,filters:String}]]
  <literal value>)
2022-11-09 11:47:04 root: INFO: encoder cache miss (0 hits, 3 misses, 0.000)
2022-11-09 11:47:04 root: INFO: instruction count: 3: __C68etypeEncode.<init>
2022-11-09 11:47:04 root: INFO: instruction count: 5: __C68etypeEncode.apply
2022-11-09 11:47:04 root: INFO: instruction count: 9: __C68etypeEncode.__m69ENCODE_r_tuple_of_r_tuple_of_r_array_of_r_tuple_of_r_stringANDr_stringANDr_stringANDr_stringANDr_stringENDENDEND_TO_r_struct_of_r_struct_of_r_array_of_r_struct_of_r_binaryANDr_binaryANDr_binaryANDr_binaryANDr_binaryENDENDEND
2022-11-09 11:47:04 root: INFO: instruction count: 13: __C68etypeEncode.__m70ENCODE_r_tuple_of_r_array_of_r_tuple_of_r_binaryANDr_binaryANDr_binaryANDr_binaryANDr_binaryENDEND_TO_r_struct_of_r_array_of_r_struct_of_r_binaryANDr_binaryANDr_binaryANDr_binaryANDr_binaryENDEND
2022-11-09 11:47:04 root: INFO: instruction count: 49: __C68etypeEncode.__m71ENCODE_r_array_of_r_tuple_of_r_binaryANDr_binaryANDr_binaryANDr_binaryANDr_binaryEND_TO_r_array_of_r_struct_of_r_binaryANDr_binaryANDr_binaryANDr_binaryANDr_binaryEND
2022-11-09 11:47:04 root: INFO: instruction count: 53: __C68etypeEncode.__m72ENCODE_r_tuple_of_r_binaryANDr_binaryANDr_binaryANDr_binaryANDr_binaryEND_TO_r_struct_of_r_binaryANDr_binaryANDr_binaryANDr_binaryANDr_binaryEND
2022-11-09 11:47:04 root: INFO: instruction count: 16: __C68etypeEncode.__m73ENCODE_r_binary_TO_r_binary
2022-11-09 11:47:04 MemoryStore: INFO: Block broadcast_6 stored as values in memory (estimated size 744.0 B, free 411.5 MB)
2022-11-09 11:47:04 MemoryStore: INFO: Block broadcast_6_piece0 stored as bytes in memory (estimated size 369.0 B, free 411.5 MB)
2022-11-09 11:47:04 BlockManagerInfo: INFO: Added broadcast_6_piece0 in memory on compe057.hpc.in.bmrc.ox.ac.uk:46128 (size: 369.0 B, free: 413.7 MB)
2022-11-09 11:47:04 SparkContext: INFO: Created broadcast 6 from broadcast at SparkBackend.scala:250
2022-11-09 11:47:04 root: INFO: instruction count: 3: __C59Compiled.<init>
2022-11-09 11:47:04 root: INFO: instruction count: 3: __C59Compiled.apply
2022-11-09 11:47:04 root: INFO: instruction count: 9: __C59Compiled.setPartitionIndex
2022-11-09 11:47:04 root: INFO: instruction count: 4: __C59Compiled.addPartitionRegion
2022-11-09 11:47:04 root: INFO: instruction count: 23: __C59Compiled.__m63DECODE_r_struct_of_r_struct_of_r_array_of_r_struct_of_r_binaryANDr_binaryANDr_binaryANDr_binaryANDr_binaryENDENDEND_TO_r_tuple_of_r_tuple_of_r_array_of_r_tuple_of_r_stringANDr_stringANDr_stringANDr_stringANDr_stringENDENDEND
2022-11-09 11:47:04 root: INFO: instruction count: 15: __C59Compiled.__m64INPLACE_DECODE_r_struct_of_r_array_of_r_struct_of_r_binaryANDr_binaryANDr_binaryANDr_binaryANDr_binaryENDEND_TO_r_tuple_of_r_array_of_r_tuple_of_r_binaryANDr_binaryANDr_binaryANDr_binaryANDr_binaryENDEND
2022-11-09 11:47:04 root: INFO: instruction count: 52: __C59Compiled.__m65INPLACE_DECODE_r_array_of_r_struct_of_r_binaryANDr_binaryANDr_binaryANDr_binaryANDr_binaryEND_TO_r_array_of_r_tuple_of_r_binaryANDr_binaryANDr_binaryANDr_binaryANDr_binaryEND
2022-11-09 11:47:04 root: INFO: instruction count: 43: __C59Compiled.__m66INPLACE_DECODE_r_struct_of_r_binaryANDr_binaryANDr_binaryANDr_binaryANDr_binaryEND_TO_r_tuple_of_r_binaryANDr_binaryANDr_binaryANDr_binaryANDr_binaryEND
2022-11-09 11:47:04 root: INFO: instruction count: 31: __C59Compiled.__m67INPLACE_DECODE_r_binary_TO_r_binary
2022-11-09 11:47:04 root: INFO: instruction count: 32: __C59Compiled.addLiterals
2022-11-09 11:47:04 root: INFO: finished execution of query hail_query_1
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON total 4.739s self 46.331ms children 4.692s %children 99.02%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 337.193ms self 0.598ms children 336.595ms %children 99.82%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.377ms self 0.377ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 336.166ms self 67.687ms children 268.479ms %children 79.87%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 268.479ms self 1.554ms children 266.926ms %children 99.42%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 3.657ms self 3.657ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 5.732ms self 5.732ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 20.584ms self 20.584ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 154.644ms self 154.644ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 1.800ms self 1.800ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 57.804ms self 57.804ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.580ms self 0.580ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.574ms self 0.574ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.405ms self 0.405ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 2.839ms self 2.839ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 2.944ms self 2.944ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 2.427ms self 2.427ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.472ms self 0.472ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.498ms self 0.498ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.383ms self 0.383ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 5.272ms self 5.272ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.222ms self 0.222ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 6.086ms self 6.086ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.051ms self 0.051ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 13.727ms self 0.018ms children 13.709ms %children 99.87%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.023ms self 0.023ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 13.559ms self 13.559ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.128ms self 0.128ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 120.313ms self 0.021ms children 120.292ms %children 99.98%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.038ms self 0.038ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 120.223ms self 28.513ms children 91.710ms %children 76.28%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 91.710ms self 0.190ms children 91.520ms %children 99.79%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 6.739ms self 6.739ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.754ms self 0.754ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 7.408ms self 7.408ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 7.745ms self 7.745ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 31.636ms self 31.636ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 5.311ms self 5.311ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 14.335ms self 14.335ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.689ms self 0.689ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.586ms self 0.586ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 2.279ms self 2.279ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.121ms self 0.121ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 1.934ms self 1.934ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.389ms self 0.389ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.428ms self 0.428ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.378ms self 0.378ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 8.629ms self 8.629ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.127ms self 0.127ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 2.031ms self 2.031ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.030ms self 0.030ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 4.113s self 0.016ms children 4.113s %children 100.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.029ms self 0.029ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 4.113s self 3.976s children 136.429ms %children 3.32%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, initial IR total 59.660ms self 0.027ms children 59.633ms %children 99.95%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, initial IR/Verify total 0.078ms self 0.078ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, initial IR/LoweringTransformation total 59.531ms self 27.784ms children 31.747ms %children 53.33%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, initial IR/LoweringTransformation/Optimize total 31.747ms self 0.116ms children 31.631ms %children 99.64%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 1.044ms self 1.044ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.125ms self 0.125ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.765ms self 0.765ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 27.014ms self 27.014ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.147ms self 0.147ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 2.537ms self 2.537ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, initial IR/Verify total 0.024ms self 0.024ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/InlineApplyIR total 0.647ms self 0.011ms children 0.635ms %children 98.27%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/InlineApplyIR/Verify total 0.250ms self 0.250ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/InlineApplyIR/LoweringTransformation total 0.329ms self 0.329ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/InlineApplyIR/Verify total 0.056ms self 0.056ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, after InlineApplyIR total 28.787ms self 0.019ms children 28.768ms %children 99.93%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, after InlineApplyIR/Verify total 0.017ms self 0.017ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, after InlineApplyIR/LoweringTransformation total 28.680ms self 25.547ms children 3.133ms %children 10.92%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, after InlineApplyIR/LoweringTransformation/Optimize total 3.133ms self 0.053ms children 3.080ms %children 98.32%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, after InlineApplyIR/LoweringTransformation/Optimize/FoldConstants total 0.219ms self 0.219ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, after InlineApplyIR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.112ms self 0.112ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, after InlineApplyIR/LoweringTransformation/Optimize/Simplify total 0.265ms self 0.265ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, after InlineApplyIR/LoweringTransformation/Optimize/ForwardLets total 1.159ms self 1.159ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, after InlineApplyIR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.133ms self 0.133ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, after InlineApplyIR/LoweringTransformation/Optimize/PruneDeadFields total 1.192ms self 1.192ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, after InlineApplyIR/Verify total 0.071ms self 0.071ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/LowerArrayAggsToRunAggs total 3.726ms self 0.012ms children 3.714ms %children 99.68%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/LowerArrayAggsToRunAggs/Verify total 0.043ms self 0.043ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/LowerArrayAggsToRunAggs/LoweringTransformation total 3.425ms self 3.425ms children 0.000ms %children 0.00%
2022-11-09 11:47:04 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/LowerArrayAggsToRunAggs/Verify total 0.247ms self 0.247ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, after LowerArrayAggsToRunAggs total 43.609ms self 0.019ms children 43.590ms %children 99.96%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, after LowerArrayAggsToRunAggs/Verify total 0.018ms self 0.018ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, after LowerArrayAggsToRunAggs/LoweringTransformation total 43.525ms self 7.962ms children 35.563ms %children 81.71%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, after LowerArrayAggsToRunAggs/LoweringTransformation/Optimize total 35.563ms self 0.050ms children 35.513ms %children 99.86%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, after LowerArrayAggsToRunAggs/LoweringTransformation/Optimize/FoldConstants total 0.194ms self 0.194ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, after LowerArrayAggsToRunAggs/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.111ms self 0.111ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, after LowerArrayAggsToRunAggs/LoweringTransformation/Optimize/Simplify total 0.332ms self 0.332ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, after LowerArrayAggsToRunAggs/LoweringTransformation/Optimize/ForwardLets total 33.474ms self 33.474ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, after LowerArrayAggsToRunAggs/LoweringTransformation/Optimize/ForwardRelationalLets total 0.117ms self 0.117ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, after LowerArrayAggsToRunAggs/LoweringTransformation/Optimize/PruneDeadFields total 1.285ms self 1.285ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation/optimize: compileLowerer, after LowerArrayAggsToRunAggs/Verify total 0.047ms self 0.047ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 1.187ms self 0.009ms children 1.178ms %children 99.26%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.004ms self 0.004ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 1.167ms self 0.628ms children 0.539ms %children 46.18%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 0.539ms self 0.057ms children 0.482ms %children 89.45%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.174ms self 0.174ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.012ms self 0.012ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.025ms self 0.025ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.110ms self 0.110ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.017ms self 0.017ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.036ms self 0.036ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.023ms self 0.023ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.004ms self 0.004ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.011ms self 0.011ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.045ms self 0.045ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.007ms self 0.007ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.019ms self 0.019ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.007ms self 0.007ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile total 100.321ms self 64.038ms children 36.282ms %children 36.17%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, initial IR total 33.176ms self 0.016ms children 33.160ms %children 99.95%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, initial IR/Verify total 0.007ms self 0.007ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, initial IR/LoweringTransformation total 33.144ms self 31.799ms children 1.345ms %children 4.06%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, initial IR/LoweringTransformation/Optimize total 1.345ms self 0.041ms children 1.304ms %children 96.97%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.938ms self 0.938ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.012ms self 0.012ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.026ms self 0.026ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.129ms self 0.129ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.016ms self 0.016ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.050ms self 0.050ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.033ms self 0.033ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.006ms self 0.006ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.016ms self 0.016ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.050ms self 0.050ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.008ms self 0.008ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, initial IR/Verify total 0.009ms self 0.009ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/InlineApplyIR total 0.047ms self 0.004ms children 0.043ms %children 90.69%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/InlineApplyIR/Verify total 0.007ms self 0.007ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/InlineApplyIR/LoweringTransformation total 0.031ms self 0.031ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/InlineApplyIR/Verify total 0.004ms self 0.004ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, after InlineApplyIR total 0.670ms self 0.006ms children 0.664ms %children 99.10%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, after InlineApplyIR/Verify total 0.001ms self 0.001ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, after InlineApplyIR/LoweringTransformation total 0.658ms self 0.376ms children 0.282ms %children 42.85%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, after InlineApplyIR/LoweringTransformation/Optimize total 0.282ms self 0.017ms children 0.265ms %children 94.06%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, after InlineApplyIR/LoweringTransformation/Optimize/FoldConstants total 0.049ms self 0.049ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, after InlineApplyIR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.016ms self 0.016ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, after InlineApplyIR/LoweringTransformation/Optimize/Simplify total 0.027ms self 0.027ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, after InlineApplyIR/LoweringTransformation/Optimize/ForwardLets total 0.120ms self 0.120ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, after InlineApplyIR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.015ms self 0.015ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, after InlineApplyIR/LoweringTransformation/Optimize/PruneDeadFields total 0.038ms self 0.038ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, after InlineApplyIR/Verify total 0.005ms self 0.005ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/LowerArrayAggsToRunAggs total 1.611ms self 0.009ms children 1.601ms %children 99.42%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/LowerArrayAggsToRunAggs/Verify total 0.006ms self 0.006ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/LowerArrayAggsToRunAggs/LoweringTransformation total 1.583ms self 1.583ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/LowerArrayAggsToRunAggs/Verify total 0.012ms self 0.012ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, after LowerArrayAggsToRunAggs total 0.779ms self 0.007ms children 0.771ms %children 99.08%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, after LowerArrayAggsToRunAggs/Verify total 0.002ms self 0.002ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, after LowerArrayAggsToRunAggs/LoweringTransformation total 0.765ms self 0.478ms children 0.287ms %children 37.50%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, after LowerArrayAggsToRunAggs/LoweringTransformation/Optimize total 0.287ms self 0.016ms children 0.270ms %children 94.33%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, after LowerArrayAggsToRunAggs/LoweringTransformation/Optimize/FoldConstants total 0.052ms self 0.052ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, after LowerArrayAggsToRunAggs/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.014ms self 0.014ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, after LowerArrayAggsToRunAggs/LoweringTransformation/Optimize/Simplify total 0.029ms self 0.029ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, after LowerArrayAggsToRunAggs/LoweringTransformation/Optimize/ForwardLets total 0.111ms self 0.111ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, after LowerArrayAggsToRunAggs/LoweringTransformation/Optimize/ForwardRelationalLets total 0.015ms self 0.015ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, after LowerArrayAggsToRunAggs/LoweringTransformation/Optimize/PruneDeadFields total 0.050ms self 0.050ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/Compile/optimize: compileLowerer, after LowerArrayAggsToRunAggs/Verify total 0.004ms self 0.004ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/InitializeCompiledFunction total 6.472ms self 6.472ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/RunCompiledFunction total 0.019ms self 0.019ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.327ms self 0.327ms children 0.000ms %children 0.00%
2022-11-09 11:47:05 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 11:47:05 AbstractConnector: INFO: Stopped Spark@3c4fff2d{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 11:47:05 SparkUI: INFO: Stopped Spark web UI at http://compe057.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 11:47:05 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 11:47:05 MemoryStore: INFO: MemoryStore cleared
2022-11-09 11:47:05 BlockManager: INFO: BlockManager stopped
2022-11-09 11:47:05 BlockManagerMaster: INFO: BlockManagerMaster stopped
2022-11-09 11:47:05 OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: INFO: OutputCommitCoordinator stopped!
2022-11-09 11:47:05 SparkContext: INFO: Successfully stopped SparkContext
2022-11-09 11:47:05 ShutdownHookManager: INFO: Shutdown hook called
2022-11-09 11:47:05 ShutdownHookManager: INFO: Deleting directory /tmp/spark-fb1ff286-f2f6-4aab-aa14-483150bf3a00
2022-11-09 11:47:05 ShutdownHookManager: INFO: Deleting directory /tmp/spark-57e15c4f-9582-4f3f-80da-af7839b510d2/pyspark-a63e704f-c2f9-4856-9ea5-6b657f1686f6
2022-11-09 11:47:05 ShutdownHookManager: INFO: Deleting directory /tmp/spark-57e15c4f-9582-4f3f-80da-af7839b510d2
2022-11-09 11:48:59 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 11:49:00 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 11:49:01 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 11:49:02 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 11:49:02 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 11:49:02 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compf012.hpc.in.bmrc.ox.ac.uk:46633 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 11:49:02 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 11:49:02 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr21.vcf.bgz returned 1 files: ukb_wes_450k.qced.chr21.vcf.bgz
2022-11-09 11:49:02 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.chr21.vcf.bgz returned 1 files: ukb_wes_450k.qced.chr21.vcf.bgz
2022-11-09 11:49:02 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 11:49:02 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 11:49:02 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compf012.hpc.in.bmrc.ox.ac.uk:46633 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 11:49:02 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 11:49:02 root: INFO: timing SparkBackend.parse_matrix_ir total 1.332s self 1.332s children 0.000ms %children 0.00%
2022-11-09 11:49:02 root: INFO: timing SparkBackend.parse_value_ir total 75.923ms self 75.923ms children 0.000ms %children 0.00%
2022-11-09 11:49:02 root: INFO: starting execution of query hail_query_1 of initial size 8
2022-11-09 11:49:03 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 8: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr21.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (MatrixRowsTable
      (MatrixRead None False False
        "{\"files\":[\"data/vcf/ukb_wes_450k.qced.chr21.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
    (InsertFields
      (SelectFields (locus alleles)
        (SelectFields 
          (locus alleles rsid qual filters info)
          (Ref row)))
      None)))
2022-11-09 11:49:03 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 3:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr21.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead
      Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String]},entry:Struct{}}
      True False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.chr21.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-09 11:49:03 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 16: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr21.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (TableMapGlobals
      (TableMapGlobals
        (TableMapRows
          (TableRead
            Table{global:Struct{__cols:Array[Struct{s:String}]},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{}]}}
            False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.chr21.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
          (InsertFields
            (Ref row)
            None
            (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
              (MakeArray Array[Struct{}]))))
        (InsertFields
          (Ref global)
          None
          (__cols (MakeArray Array[Struct{s:String}]))))
      (SelectFields () (Ref global)))
    (SelectFields (locus alleles) (Ref row))))
2022-11-09 11:49:03 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-09 11:49:03 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 2:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr21.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableRead
    Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String]}}
    False
    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.chr21.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
2022-11-09 11:49:03 root: INFO: interpreting non compilable node: TableWrite
2022-11-09 11:49:03 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-09 11:49:03 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-09 11:49:03 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-09 11:49:03 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 11:49:03 DAGScheduler: INFO: Missing parents: List()
2022-11-09 11:49:03 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-09 11:49:03 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-09 11:49:03 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-09 11:49:03 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compf012.hpc.in.bmrc.ox.ac.uk:46633 (size: 7.4 KB, free: 413.8 MB)
2022-11-09 11:49:03 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-09 11:49:03 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-09 11:49:03 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-09 11:49:03 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8042 bytes)
2022-11-09 11:49:03 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-09 11:49:03 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-09 11:49:03 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 11:49:03 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 11:49:03 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 11:49:05 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1461 bytes result sent to driver
2022-11-09 11:49:05 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 1675 ms on localhost (executor driver) (1/1)
2022-11-09 11:49:05 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 1.780 s
2022-11-09 11:49:05 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-09 11:49:05 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 1.860105 s
2022-11-09 11:49:05 Hail: INFO: Coerced sorted dataset
2022-11-09 11:49:05 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-09 11:49:05 root: INFO: instruction count: 3: __C1etypeEncode.<init>
2022-11-09 11:49:05 root: INFO: instruction count: 5: __C1etypeEncode.apply
2022-11-09 11:49:05 root: INFO: instruction count: 3: __C1etypeEncode.__m2ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 11:49:05 root: INFO: instruction count: 3: __C3indexwriter.<init>
2022-11-09 11:49:05 root: INFO: instruction count: 234: __C3indexwriter.apply
2022-11-09 11:49:05 root: INFO: instruction count: 445: __C3indexwriter.__m12writeInternalNode
2022-11-09 11:49:06 root: INFO: instruction count: 13: __C3indexwriter.__m13ENCODE_o_tuple_of_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 11:49:06 root: INFO: instruction count: 49: __C3indexwriter.__m14ENCODE_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 11:49:06 root: INFO: instruction count: 45: __C3indexwriter.__m15ENCODE_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 11:49:06 root: INFO: instruction count: 4: __C3indexwriter.__m16ENCODE_r_int64_TO_r_int64
2022-11-09 11:49:06 root: INFO: instruction count: 19: __C3indexwriter.__m17ENCODE_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 11:49:06 root: INFO: instruction count: 23: __C3indexwriter.__m18ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 11:49:06 root: INFO: instruction count: 16: __C3indexwriter.__m19ENCODE_r_binary_TO_r_binary
2022-11-09 11:49:06 root: INFO: instruction count: 4: __C3indexwriter.__m20ENCODE_r_int32_TO_r_int32
2022-11-09 11:49:06 root: INFO: instruction count: 53: __C3indexwriter.__m21ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 11:49:06 root: INFO: instruction count: 3: __C3indexwriter.__m22ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 11:49:06 root: INFO: instruction count: 379: __C3indexwriter.__m23writeLeafNode
2022-11-09 11:49:06 root: INFO: instruction count: 23: __C3indexwriter.__m24ENCODE_o_tuple_of_r_int64ANDr_array_of_r_tuple_of_r_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_int64ANDr_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 11:49:06 root: INFO: instruction count: 49: __C3indexwriter.__m25ENCODE_r_array_of_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 11:49:06 root: INFO: instruction count: 25: __C3indexwriter.__m26ENCODE_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 11:49:06 root: INFO: instruction count: 52: __C3indexwriter.__m27flush
2022-11-09 11:49:06 root: INFO: instruction count: 150: __C3indexwriter.init
2022-11-09 11:49:06 root: INFO: instruction count: 4: __C3indexwriter.setObjects
2022-11-09 11:49:06 root: INFO: instruction count: 28: __C3indexwriter.close
2022-11-09 11:49:06 root: INFO: instruction count: 7: __C3indexwriter.trackedOS
2022-11-09 11:49:06 root: INFO: instruction count: 9: __C3indexwriter.setPartitionIndex
2022-11-09 11:49:06 root: INFO: instruction count: 4: __C3indexwriter.addPartitionRegion
2022-11-09 11:49:06 root: INFO: instruction count: 3: __C29FSContainer.<init>
2022-11-09 11:49:06 root: INFO: instruction count: 28: __C29FSContainer.init_filesystem
2022-11-09 11:49:06 root: INFO: instruction count: 3: __C29FSContainer.<clinit>
2022-11-09 11:49:06 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-09 11:49:06 root: INFO: instruction count: 3: __C32etypeEncode.<init>
2022-11-09 11:49:06 root: INFO: instruction count: 5: __C32etypeEncode.apply
2022-11-09 11:49:06 root: INFO: instruction count: 19: __C32etypeEncode.__m33ENCODE_r_tuple_of_r_locusANDr_array_of_r_stringEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 11:49:06 root: INFO: instruction count: 23: __C32etypeEncode.__m34ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 11:49:06 root: INFO: instruction count: 16: __C32etypeEncode.__m35ENCODE_r_binary_TO_r_binary
2022-11-09 11:49:06 root: INFO: instruction count: 4: __C32etypeEncode.__m36ENCODE_r_int32_TO_r_int32
2022-11-09 11:49:06 root: INFO: instruction count: 53: __C32etypeEncode.__m37ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 11:49:06 SparkContext: INFO: Starting job: collect at ContextRDD.scala:166
2022-11-09 11:49:06 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:166) with 1 output partitions
2022-11-09 11:49:06 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:166)
2022-11-09 11:49:06 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 11:49:06 DAGScheduler: INFO: Missing parents: List()
2022-11-09 11:49:06 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-09 11:49:06 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 312.3 KB, free 411.6 MB)
2022-11-09 11:49:06 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 114.5 KB, free 411.5 MB)
2022-11-09 11:49:06 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compf012.hpc.in.bmrc.ox.ac.uk:46633 (size: 114.5 KB, free: 413.7 MB)
2022-11-09 11:49:06 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compf012.hpc.in.bmrc.ox.ac.uk:46633 in memory (size: 7.4 KB, free: 413.7 MB)
2022-11-09 11:49:06 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-09 11:49:06 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-09 11:49:06 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-09 11:49:06 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8047 bytes)
2022-11-09 11:49:06 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-09 11:49:06 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-09 11:49:06 root: INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 11:49:07 root: INFO: RegionPool: REPORT_THRESHOLD: 4.0M allocated (3.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 11:49:07 root: INFO: RegionPool: REPORT_THRESHOLD: 8.0M allocated (7.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 11:49:07 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 916 bytes result sent to driver
2022-11-09 11:49:08 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 1619 ms on localhost (executor driver) (1/1)
2022-11-09 11:49:08 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:166) finished in 1.675 s
2022-11-09 11:49:08 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:166, took 1.683923 s
2022-11-09 11:49:08 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-09 11:49:08 Hail: INFO: wrote table with 190854 rows in 1 partition to data/ht/ukb_wes_450k.qced.chr21.ht
    Total size: 2.33 MiB
    * Rows: 2.33 MiB
    * Globals: 11.00 B
    * Smallest partition: 190854 rows (2.33 MiB)
    * Largest partition:  190854 rows (2.33 MiB)
2022-11-09 11:49:08 root: INFO: took 5.010s
2022-11-09 11:49:08 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 1: 
(Begin)
2022-11-09 11:49:08 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Begin)
2022-11-09 11:49:08 root: INFO: finished execution of query hail_query_1
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON total 5.193s self 37.519ms children 5.155s %children 99.28%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 106.350ms self 0.447ms children 105.903ms %children 99.58%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.277ms self 0.277ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 105.605ms self 44.751ms children 60.854ms %children 57.62%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 60.854ms self 1.064ms children 59.790ms %children 98.25%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 2.848ms self 2.848ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 3.803ms self 3.803ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 11.730ms self 11.730ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 7.993ms self 7.993ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 1.190ms self 1.190ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 30.702ms self 30.702ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.129ms self 0.129ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.060ms self 0.060ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.126ms self 0.126ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.234ms self 0.234ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.018ms self 0.018ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.326ms self 0.326ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.061ms self 0.061ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.010ms self 0.010ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.033ms self 0.033ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.181ms self 0.181ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.016ms self 0.016ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.328ms self 0.328ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 10.811ms self 0.012ms children 10.799ms %children 99.89%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.004ms self 0.004ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 10.708ms self 10.708ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.087ms self 0.087ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 26.093ms self 0.011ms children 26.082ms %children 99.96%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.015ms self 0.015ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 26.059ms self 3.486ms children 22.573ms %children 86.62%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 22.573ms self 0.074ms children 22.499ms %children 99.67%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 7.239ms self 7.239ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.208ms self 0.208ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 5.666ms self 5.666ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 1.043ms self 1.043ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.066ms self 0.066ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 7.064ms self 7.064ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.161ms self 0.161ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.111ms self 0.111ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.190ms self 0.190ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.177ms self 0.177ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.017ms self 0.017ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.156ms self 0.156ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.047ms self 0.047ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.017ms self 0.017ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.160ms self 0.160ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.013ms self 0.013ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.143ms self 0.143ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.008ms self 0.008ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 5.011s self 0.012ms children 5.011s %children 100.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.006ms self 0.006ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 5.011s self 5.011s children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.208ms self 0.208ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 0.810ms self 0.007ms children 0.803ms %children 99.14%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.004ms self 0.004ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 0.796ms self 0.291ms children 0.505ms %children 63.42%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 0.505ms self 0.034ms children 0.471ms %children 93.36%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.075ms self 0.075ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.187ms self 0.187ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.025ms self 0.025ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.125ms self 0.125ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.014ms self 0.014ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.045ms self 0.045ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.003ms self 0.003ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.010ms self 0.010ms children 0.000ms %children 0.00%
2022-11-09 11:49:08 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 11:49:08 AbstractConnector: INFO: Stopped Spark@3d0e57e3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 11:49:08 SparkUI: INFO: Stopped Spark web UI at http://compf012.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 11:49:08 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 11:49:08 MemoryStore: INFO: MemoryStore cleared
2022-11-09 11:49:08 BlockManager: INFO: BlockManager stopped
2022-11-09 11:49:08 BlockManagerMaster: INFO: BlockManagerMaster stopped
2022-11-09 11:49:08 OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: INFO: OutputCommitCoordinator stopped!
2022-11-09 11:49:08 SparkContext: INFO: Successfully stopped SparkContext
2022-11-09 11:49:08 ShutdownHookManager: INFO: Shutdown hook called
2022-11-09 11:49:08 ShutdownHookManager: INFO: Deleting directory /tmp/spark-208c4b73-e972-4f74-b663-c8e4f6e36271
2022-11-09 11:49:08 ShutdownHookManager: INFO: Deleting directory /tmp/spark-27ae2327-7bd8-45d5-821a-9ed40fe608b6
2022-11-09 11:49:08 ShutdownHookManager: INFO: Deleting directory /tmp/spark-27ae2327-7bd8-45d5-821a-9ed40fe608b6/pyspark-6d2b22ba-1653-4330-9526-fbe16c3026e9
2022-11-09 14:16:41 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:16:41 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:16:42 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:16:42 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:16:42 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:16:42 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:16:42 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:16:42 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:16:42 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:16:42 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:16:42 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:16:42 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:16:42 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:16:42 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:16:42 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:16:42 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:16:42 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:16:42 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:16:42 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:16:42 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:16:42 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:16:42 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:16:42 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:16:43 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:16:43 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:16:43 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:16:43 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:16:43 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:16:43 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:16:43 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:16:43 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:16:43 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:16:43 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:16:43 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:16:43 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:16:43 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:16:43 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:16:43 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:16:43 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:16:43 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:16:43 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:16:43 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:16:43 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:16:43 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:16:43 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:16:43 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:16:43 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:16:43 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:16:43 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:16:43 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:16:43 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:16:43 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:16:43 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:16:43 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe050.hpc.in.bmrc.ox.ac.uk:43043 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:16:43 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:16:43 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr19.vcf.bgz returned 0 files: 
2022-11-09 14:16:43 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.chr19.vcf.bgz' refers to no files
2022-11-09 14:16:43 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-09 14:16:43 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-09 14:16:43 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:16:43 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:16:43 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:16:44 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:16:44 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:16:44 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:16:44 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:16:44 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:16:44 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:16:44 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:16:44 AbstractConnector: INFO: Stopped Spark@4cb1453e{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:16:44 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:16:44 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:16:44 SparkUI: INFO: Stopped Spark web UI at http://compe050.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 14:16:44 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:16:44 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:16:44 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:16:44 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:16:44 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:16:44 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:16:44 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:16:44 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:16:44 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:16:44 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:16:44 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:16:44 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:16:44 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:16:44 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:16:44 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe066.hpc.in.bmrc.ox.ac.uk:42259 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:16:44 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:16:44 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr9.vcf.bgz returned 0 files: 
2022-11-09 14:16:44 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.chr9.vcf.bgz' refers to no files
2022-11-09 14:16:44 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-09 14:16:44 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-09 14:16:44 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:16:44 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe089.hpc.in.bmrc.ox.ac.uk:34365 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:16:44 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:16:44 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr22.vcf.bgz returned 0 files: 
2022-11-09 14:16:44 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.chr22.vcf.bgz' refers to no files
2022-11-09 14:16:44 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-09 14:16:44 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-09 14:16:44 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:16:44 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:16:44 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe066.hpc.in.bmrc.ox.ac.uk:41052 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:16:44 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:16:44 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:16:44 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr3.vcf.bgz returned 0 files: 
2022-11-09 14:16:44 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:16:44 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe044.hpc.in.bmrc.ox.ac.uk:43484 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:16:44 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.chr3.vcf.bgz' refers to no files
2022-11-09 14:16:44 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:16:44 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:16:44 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-09 14:16:44 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:16:44 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe075.hpc.in.bmrc.ox.ac.uk:37716 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:16:44 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-09 14:16:44 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:16:44 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr1.vcf.bgz returned 0 files: 
2022-11-09 14:16:44 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.chr1.vcf.bgz' refers to no files
2022-11-09 14:16:44 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:16:44 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-09 14:16:44 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe075.hpc.in.bmrc.ox.ac.uk:35846 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:16:44 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-09 14:16:44 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr4.vcf.bgz returned 0 files: 
2022-11-09 14:16:44 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:16:44 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.chr4.vcf.bgz' refers to no files
2022-11-09 14:16:44 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-09 14:16:44 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:16:44 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-09 14:16:44 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chrX.vcf.bgz returned 0 files: 
2022-11-09 14:16:44 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:16:45 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.chrX.vcf.bgz' refers to no files
2022-11-09 14:16:45 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe036.hpc.in.bmrc.ox.ac.uk:38654 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:16:45 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-09 14:16:45 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:16:45 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:16:45 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:16:45 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-09 14:16:45 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe044.hpc.in.bmrc.ox.ac.uk:41490 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:16:45 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:16:45 AbstractConnector: INFO: Stopped Spark@1505914f{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:16:45 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:16:45 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:16:45 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:16:45 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr5.vcf.bgz returned 0 files: 
2022-11-09 14:16:45 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:16:45 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:16:45 SparkUI: INFO: Stopped Spark web UI at http://compe066.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 14:16:45 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:16:45 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.chr5.vcf.bgz' refers to no files
2022-11-09 14:16:45 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:16:45 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:16:45 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:16:45 AbstractConnector: INFO: Stopped Spark@5bd34680{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:16:45 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe064.hpc.in.bmrc.ox.ac.uk:44166 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:16:45 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:16:45 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-09 14:16:45 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:16:45 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:16:45 SparkUI: INFO: Stopped Spark web UI at http://compe089.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 14:16:45 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:16:45 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:16:45 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe036.hpc.in.bmrc.ox.ac.uk:36178 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:16:45 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr16.vcf.bgz returned 0 files: 
2022-11-09 14:16:45 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:16:45 AbstractConnector: INFO: Stopped Spark@4cb1453e{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2022-11-09 14:16:45 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 14:16:45 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr13.vcf.bgz returned 0 files: 
2022-11-09 14:16:45 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-09 14:16:45 AbstractConnector: INFO: Stopped Spark@6471d677{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:16:45 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:16:45 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe063.hpc.in.bmrc.ox.ac.uk:41160 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:16:45 SparkUI: INFO: Stopped Spark web UI at http://compe066.hpc.in.bmrc.ox.ac.uk:4041
2022-11-09 14:16:45 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.chr13.vcf.bgz' refers to no files
2022-11-09 14:16:45 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:16:45 MemoryStore: INFO: MemoryStore cleared
2022-11-09 14:16:45 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:16:45 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.chr16.vcf.bgz' refers to no files
2022-11-09 14:16:45 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-09 14:16:45 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-09 14:16:45 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:16:45 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:16:45 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr18.vcf.bgz returned 0 files: 
2022-11-09 14:16:45 BlockManager: INFO: BlockManager stopped
2022-11-09 14:16:45 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.chr18.vcf.bgz' refers to no files
2022-11-09 14:16:45 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:16:45 SparkUI: INFO: Stopped Spark web UI at http://compe075.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 14:16:45 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-09 14:16:45 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:16:45 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 14:16:45 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr20.vcf.bgz returned 0 files: 
2022-11-09 14:16:45 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe036.hpc.in.bmrc.ox.ac.uk:44848 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:16:45 AbstractConnector: INFO: Stopped Spark@5bd34680{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2022-11-09 14:16:45 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe093.hpc.in.bmrc.ox.ac.uk:43439 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:16:45 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-09 14:16:45 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe086.hpc.in.bmrc.ox.ac.uk:34564 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:16:45 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.chr20.vcf.bgz' refers to no files
2022-11-09 14:16:45 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:16:45 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-09 14:16:45 SparkUI: INFO: Stopped Spark web UI at http://compe075.hpc.in.bmrc.ox.ac.uk:4041
2022-11-09 14:16:45 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:16:45 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:16:45 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:16:45 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-09 14:16:45 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe043.hpc.in.bmrc.ox.ac.uk:41258 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:16:45 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:16:45 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe093.hpc.in.bmrc.ox.ac.uk:40883 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:16:45 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr14.vcf.bgz returned 0 files: 
2022-11-09 14:16:45 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.chr14.vcf.bgz' refers to no files
2022-11-09 14:16:45 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-09 14:16:45 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:16:45 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:16:45 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-09 14:16:45 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr15.vcf.bgz returned 0 files: 
2022-11-09 14:16:45 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-09 14:16:45 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-09 14:16:45 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe063.hpc.in.bmrc.ox.ac.uk:39544 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:16:45 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr12.vcf.bgz returned 0 files: 
2022-11-09 14:16:45 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:16:45 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.chr15.vcf.bgz' refers to no files
2022-11-09 14:16:45 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:16:45 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr6.vcf.bgz returned 0 files: 
2022-11-09 14:16:45 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:16:45 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:16:45 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:16:45 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:16:45 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-09 14:16:45 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:16:45 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.chr6.vcf.bgz' refers to no files
2022-11-09 14:16:45 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe048.hpc.in.bmrc.ox.ac.uk:34782 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:16:45 AbstractConnector: INFO: Stopped Spark@50a14c42{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:16:45 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:16:45 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr2.vcf.bgz returned 0 files: 
2022-11-09 14:16:45 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.chr2.vcf.bgz' refers to no files
2022-11-09 14:16:45 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.chr12.vcf.bgz' refers to no files
2022-11-09 14:16:45 AbstractConnector: INFO: Stopped Spark@56104b1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2022-11-09 14:16:45 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr10.vcf.bgz returned 0 files: 
2022-11-09 14:16:45 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-09 14:16:45 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe044.hpc.in.bmrc.ox.ac.uk:37963 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:16:45 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-09 14:16:45 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:16:45 SparkUI: INFO: Stopped Spark web UI at http://compe064.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 14:16:45 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-09 14:16:45 SparkUI: INFO: Stopped Spark web UI at http://compe036.hpc.in.bmrc.ox.ac.uk:4041
2022-11-09 14:16:45 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.chr10.vcf.bgz' refers to no files
2022-11-09 14:16:45 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-09 14:16:45 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-09 14:16:45 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr7.vcf.bgz returned 0 files: 
2022-11-09 14:16:45 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe063.hpc.in.bmrc.ox.ac.uk:38314 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:16:45 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-09 14:16:45 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe044.hpc.in.bmrc.ox.ac.uk:35083 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:16:45 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:16:45 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:16:45 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-09 14:16:45 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr17.vcf.bgz returned 0 files: 
2022-11-09 14:16:45 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-09 14:16:45 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 14:16:45 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:16:45 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.chr7.vcf.bgz' refers to no files
2022-11-09 14:16:45 MemoryStore: INFO: MemoryStore cleared
2022-11-09 14:16:45 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 14:16:45 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-09 14:16:45 AbstractConnector: INFO: Stopped Spark@3d0e57e3{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:16:45 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:16:45 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:16:45 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:16:45 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-09 14:16:45 BlockManager: INFO: BlockManager stopped
2022-11-09 14:16:45 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.chr17.vcf.bgz' refers to no files
2022-11-09 14:16:45 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr8.vcf.bgz returned 0 files: 
2022-11-09 14:16:45 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-09 14:16:45 AbstractConnector: INFO: Stopped Spark@56104b1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:16:45 SparkUI: INFO: Stopped Spark web UI at http://compe044.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 14:16:45 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-09 14:16:45 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.chr8.vcf.bgz' refers to no files
2022-11-09 14:16:45 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:16:45 SparkUI: INFO: Stopped Spark web UI at http://compe036.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 14:16:45 AbstractConnector: INFO: Stopped Spark@7bca62be{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:16:45 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-09 14:16:45 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-09 14:16:46 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 14:16:45 AbstractConnector: INFO: Stopped Spark@54907234{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:16:46 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-09 14:16:46 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.chr11.vcf.bgz returned 0 files: 
2022-11-09 14:16:46 SparkUI: INFO: Stopped Spark web UI at http://compe063.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 14:16:46 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:16:46 SparkUI: INFO: Stopped Spark web UI at http://compe086.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 14:16:46 MemoryStore: INFO: MemoryStore cleared
2022-11-09 14:16:46 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.chr11.vcf.bgz' refers to no files
2022-11-09 14:16:46 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:16:46 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 14:16:46 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:16:46 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:16:46 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:16:46 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-09 14:16:46 AbstractConnector: INFO: Stopped Spark@6471d677{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:16:46 AbstractConnector: INFO: Stopped Spark@54907234{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2022-11-09 14:16:46 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:16:46 AbstractConnector: INFO: Stopped Spark@3d0e57e3{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2022-11-09 14:16:46 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-09 14:16:46 SparkUI: INFO: Stopped Spark web UI at http://compe043.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 14:16:46 SparkUI: INFO: Stopped Spark web UI at http://compe063.hpc.in.bmrc.ox.ac.uk:4041
2022-11-09 14:16:46 AbstractConnector: INFO: Stopped Spark@6471d677{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:16:46 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:16:46 SparkUI: INFO: Stopped Spark web UI at http://compe093.hpc.in.bmrc.ox.ac.uk:4041
2022-11-09 14:16:46 AbstractConnector: INFO: Stopped Spark@56104b1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:16:46 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:16:46 SparkUI: INFO: Stopped Spark web UI at http://compe048.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 14:16:46 AbstractConnector: INFO: Stopped Spark@6471d677{HTTP/1.1,[http/1.1]}{0.0.0.0:4043}
2022-11-09 14:16:46 AbstractConnector: INFO: Stopped Spark@1d26a1ec{HTTP/1.1,[http/1.1]}{0.0.0.0:4042}
2022-11-09 14:16:46 SparkUI: INFO: Stopped Spark web UI at http://compe044.hpc.in.bmrc.ox.ac.uk:4043
2022-11-09 14:16:46 SparkUI: INFO: Stopped Spark web UI at http://compe063.hpc.in.bmrc.ox.ac.uk:4042
2022-11-09 14:16:46 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 14:16:46 MemoryStore: INFO: MemoryStore cleared
2022-11-09 14:16:46 BlockManager: INFO: BlockManager stopped
2022-11-09 14:16:46 BlockManagerMaster: INFO: BlockManagerMaster stopped
2022-11-09 14:16:46 OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: INFO: OutputCommitCoordinator stopped!
2022-11-09 14:16:46 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:16:46 SparkContext: INFO: Successfully stopped SparkContext
2022-11-09 14:16:46 ShutdownHookManager: INFO: Shutdown hook called
2022-11-09 14:16:46 ShutdownHookManager: INFO: Deleting directory /tmp/spark-65d85e1e-e07c-4fa5-86db-8a9bf3d9df1a
2022-11-09 14:16:46 AbstractConnector: INFO: Stopped Spark@6471d677{HTTP/1.1,[http/1.1]}{0.0.0.0:4042}
2022-11-09 14:16:46 SparkUI: INFO: Stopped Spark web UI at http://compe044.hpc.in.bmrc.ox.ac.uk:4042
2022-11-09 14:16:46 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 14:16:46 MemoryStore: INFO: MemoryStore cleared
2022-11-09 14:16:46 BlockManager: INFO: BlockManager stopped
2022-11-09 14:16:46 BlockManagerMaster: INFO: BlockManagerMaster stopped
2022-11-09 14:16:46 OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: INFO: OutputCommitCoordinator stopped!
2022-11-09 14:16:46 SparkContext: INFO: Successfully stopped SparkContext
2022-11-09 14:16:46 ShutdownHookManager: INFO: Shutdown hook called
2022-11-09 14:16:46 ShutdownHookManager: INFO: Deleting directory /tmp/spark-2f1668dc-5e03-4880-a6b3-5b3e51599e52/pyspark-c3b27275-1380-4258-81c8-2ceeffa10d39
2022-11-09 14:16:46 ShutdownHookManager: INFO: Deleting directory /tmp/spark-2f1668dc-5e03-4880-a6b3-5b3e51599e52
2022-11-09 14:16:46 ShutdownHookManager: INFO: Deleting directory /tmp/spark-37fa5ba6-9e73-483d-9dcd-fe97af2fcf54
2022-11-09 14:19:10 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:19:10 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:19:10 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:19:11 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:19:11 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:19:11 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:19:12 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:19:12 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:19:12 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:19:12 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:19:12 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:19:12 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:19:12 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe065.hpc.in.bmrc.ox.ac.uk:37201 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:19:12 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:12 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.sites_only.chr3.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr3.vcf.bgz
2022-11-09 14:19:12 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.sites_only.chr3.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr3.vcf.bgz
2022-11-09 14:19:13 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:19:13 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe041.hpc.in.bmrc.ox.ac.uk:34367 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:19:13 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:13 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.sites_only.chr1.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr1.vcf.bgz
2022-11-09 14:19:13 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.sites_only.chr1.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr1.vcf.bgz
2022-11-09 14:19:13 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 14:19:13 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:19:13 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 14:19:13 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compe065.hpc.in.bmrc.ox.ac.uk:37201 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 14:19:13 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:13 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 14:19:13 root: INFO: timing SparkBackend.parse_matrix_ir total 1.540s self 1.540s children 0.000ms %children 0.00%
2022-11-09 14:19:13 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 14:19:13 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compe041.hpc.in.bmrc.ox.ac.uk:34367 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 14:19:13 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:13 root: INFO: timing SparkBackend.parse_value_ir total 81.401ms self 81.401ms children 0.000ms %children 0.00%
2022-11-09 14:19:13 root: INFO: starting execution of query hail_query_1 of initial size 8
2022-11-09 14:19:13 root: INFO: timing SparkBackend.parse_matrix_ir total 1.919s self 1.919s children 0.000ms %children 0.00%
2022-11-09 14:19:13 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:19:13 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe061.hpc.in.bmrc.ox.ac.uk:38723 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:19:13 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:13 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 8: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr3.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (MatrixRowsTable
      (MatrixRead None False False
        "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr3.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
    (InsertFields
      (SelectFields (locus alleles)
        (SelectFields 
          (locus alleles rsid qual filters info)
          (Ref row)))
      None)))
2022-11-09 14:19:13 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.sites_only.chr2.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr2.vcf.bgz
2022-11-09 14:19:13 root: INFO: timing SparkBackend.parse_value_ir total 59.443ms self 59.443ms children 0.000ms %children 0.00%
2022-11-09 14:19:13 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.sites_only.chr2.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr2.vcf.bgz
2022-11-09 14:19:13 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 3:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr3.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead
      Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String]},entry:Struct{}}
      True False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr3.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-09 14:19:13 root: INFO: starting execution of query hail_query_1 of initial size 8
2022-11-09 14:19:13 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 16: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr3.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (TableMapGlobals
      (TableMapGlobals
        (TableMapRows
          (TableRead
            Table{global:Struct{__cols:Array[Struct{s:String}]},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{}]}}
            False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr3.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
          (InsertFields
            (Ref row)
            None
            (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
              (MakeArray Array[Struct{}]))))
        (InsertFields
          (Ref global)
          None
          (__cols (MakeArray Array[Struct{s:String}]))))
      (SelectFields () (Ref global)))
    (SelectFields (locus alleles) (Ref row))))
2022-11-09 14:19:14 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-09 14:19:14 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 2:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr3.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableRead
    Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String]}}
    False
    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr3.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
2022-11-09 14:19:14 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 8: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr1.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (MatrixRowsTable
      (MatrixRead None False False
        "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr1.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
    (InsertFields
      (SelectFields (locus alleles)
        (SelectFields 
          (locus alleles rsid qual filters info)
          (Ref row)))
      None)))
2022-11-09 14:19:14 root: INFO: interpreting non compilable node: TableWrite
2022-11-09 14:19:14 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 3:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr1.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead
      Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String]},entry:Struct{}}
      True False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr1.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-09 14:19:14 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 16: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr1.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (TableMapGlobals
      (TableMapGlobals
        (TableMapRows
          (TableRead
            Table{global:Struct{__cols:Array[Struct{s:String}]},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{}]}}
            False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr1.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
          (InsertFields
            (Ref row)
            None
            (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
              (MakeArray Array[Struct{}]))))
        (InsertFields
          (Ref global)
          None
          (__cols (MakeArray Array[Struct{s:String}]))))
      (SelectFields () (Ref global)))
    (SelectFields (locus alleles) (Ref row))))
2022-11-09 14:19:14 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-09 14:19:14 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 2:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr1.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableRead
    Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String]}}
    False
    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr1.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
2022-11-09 14:19:14 root: INFO: interpreting non compilable node: TableWrite
2022-11-09 14:19:14 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 14:19:14 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-09 14:19:14 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-09 14:19:14 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-09 14:19:14 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:14 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:14 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 14:19:14 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-09 14:19:14 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compe061.hpc.in.bmrc.ox.ac.uk:38723 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 14:19:14 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:14 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-09 14:19:14 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-09 14:19:14 root: INFO: timing SparkBackend.parse_matrix_ir total 1.944s self 1.944s children 0.000ms %children 0.00%
2022-11-09 14:19:14 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-09 14:19:14 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-09 14:19:14 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-09 14:19:14 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:14 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:14 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compe065.hpc.in.bmrc.ox.ac.uk:37201 (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:14 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-09 14:19:14 root: INFO: timing SparkBackend.parse_value_ir total 72.261ms self 72.261ms children 0.000ms %children 0.00%
2022-11-09 14:19:14 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:14 root: INFO: starting execution of query hail_query_1 of initial size 8
2022-11-09 14:19:14 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:14 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-09 14:19:15 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-09 14:19:15 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-09 14:19:15 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compe041.hpc.in.bmrc.ox.ac.uk:34367 (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:15 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:15 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 8: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr2.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (MatrixRowsTable
      (MatrixRead None False False
        "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr2.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
    (InsertFields
      (SelectFields (locus alleles)
        (SelectFields 
          (locus alleles rsid qual filters info)
          (Ref row)))
      None)))
2022-11-09 14:19:15 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:15 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-09 14:19:15 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes)
2022-11-09 14:19:15 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 3:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr2.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead
      Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String]},entry:Struct{}}
      True False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr2.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-09 14:19:15 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes)
2022-11-09 14:19:15 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-09 14:19:15 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 16: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr2.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (TableMapGlobals
      (TableMapGlobals
        (TableMapRows
          (TableRead
            Table{global:Struct{__cols:Array[Struct{s:String}]},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{}]}}
            False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr2.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
          (InsertFields
            (Ref row)
            None
            (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
              (MakeArray Array[Struct{}]))))
        (InsertFields
          (Ref global)
          None
          (__cols (MakeArray Array[Struct{s:String}]))))
      (SelectFields () (Ref global)))
    (SelectFields (locus alleles) (Ref row))))
2022-11-09 14:19:15 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-09 14:19:15 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-09 14:19:15 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 2:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr2.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableRead
    Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String]}}
    False
    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr2.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
2022-11-09 14:19:15 root: INFO: interpreting non compilable node: TableWrite
2022-11-09 14:19:15 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-09 14:19:15 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-09 14:19:15 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:15 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:15 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:15 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:15 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:15 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:15 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-09 14:19:15 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-09 14:19:15 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-09 14:19:15 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:15 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:15 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-09 14:19:15 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-09 14:19:15 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-09 14:19:15 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compe061.hpc.in.bmrc.ox.ac.uk:38723 (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:15 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:15 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:15 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-09 14:19:16 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes)
2022-11-09 14:19:16 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-09 14:19:16 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-09 14:19:16 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:16 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:16 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:16 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:19:16 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:19:17 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:19:17 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:19:17 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:19:17 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:19:18 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:19:18 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1542 bytes result sent to driver
2022-11-09 14:19:18 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 3308 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:18 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 3.815 s
2022-11-09 14:19:18 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-09 14:19:18 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 3.949854 s
2022-11-09 14:19:18 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:19:18 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:19:18 Hail: INFO: Coerced sorted dataset
2022-11-09 14:19:18 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:19:18 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe065.hpc.in.bmrc.ox.ac.uk:35806 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:19:18 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:18 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.sites_only.chr17.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr17.vcf.bgz
2022-11-09 14:19:18 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.sites_only.chr17.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr17.vcf.bgz
2022-11-09 14:19:18 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-09 14:19:18 root: INFO: instruction count: 3: __C1etypeEncode.<init>
2022-11-09 14:19:18 root: INFO: instruction count: 5: __C1etypeEncode.apply
2022-11-09 14:19:18 root: INFO: instruction count: 3: __C1etypeEncode.__m2ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:18 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:19:18 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe065.hpc.in.bmrc.ox.ac.uk:39361 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:19:18 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:18 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.sites_only.chr11.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr11.vcf.bgz
2022-11-09 14:19:19 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.sites_only.chr11.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr11.vcf.bgz
2022-11-09 14:19:19 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:19:19 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:19:19 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 14:19:19 root: INFO: instruction count: 3: __C3indexwriter.<init>
2022-11-09 14:19:19 root: INFO: instruction count: 234: __C3indexwriter.apply
2022-11-09 14:19:19 root: INFO: instruction count: 445: __C3indexwriter.__m12writeInternalNode
2022-11-09 14:19:19 root: INFO: instruction count: 13: __C3indexwriter.__m13ENCODE_o_tuple_of_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:19 root: INFO: instruction count: 49: __C3indexwriter.__m14ENCODE_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:19 root: INFO: instruction count: 45: __C3indexwriter.__m15ENCODE_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:19 root: INFO: instruction count: 4: __C3indexwriter.__m16ENCODE_r_int64_TO_r_int64
2022-11-09 14:19:19 root: INFO: instruction count: 19: __C3indexwriter.__m17ENCODE_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:19 root: INFO: instruction count: 23: __C3indexwriter.__m18ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:19 root: INFO: instruction count: 16: __C3indexwriter.__m19ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:19 root: INFO: instruction count: 4: __C3indexwriter.__m20ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:19 root: INFO: instruction count: 53: __C3indexwriter.__m21ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:19 root: INFO: instruction count: 3: __C3indexwriter.__m22ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:19 root: INFO: instruction count: 379: __C3indexwriter.__m23writeLeafNode
2022-11-09 14:19:19 root: INFO: instruction count: 23: __C3indexwriter.__m24ENCODE_o_tuple_of_r_int64ANDr_array_of_r_tuple_of_r_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_int64ANDr_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:19 root: INFO: instruction count: 49: __C3indexwriter.__m25ENCODE_r_array_of_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:19 root: INFO: instruction count: 25: __C3indexwriter.__m26ENCODE_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:19 root: INFO: instruction count: 52: __C3indexwriter.__m27flush
2022-11-09 14:19:19 root: INFO: instruction count: 150: __C3indexwriter.init
2022-11-09 14:19:19 root: INFO: instruction count: 4: __C3indexwriter.setObjects
2022-11-09 14:19:19 root: INFO: instruction count: 28: __C3indexwriter.close
2022-11-09 14:19:19 root: INFO: instruction count: 7: __C3indexwriter.trackedOS
2022-11-09 14:19:19 root: INFO: instruction count: 9: __C3indexwriter.setPartitionIndex
2022-11-09 14:19:19 root: INFO: instruction count: 4: __C3indexwriter.addPartitionRegion
2022-11-09 14:19:19 root: INFO: instruction count: 3: __C29FSContainer.<init>
2022-11-09 14:19:19 root: INFO: instruction count: 28: __C29FSContainer.init_filesystem
2022-11-09 14:19:19 root: INFO: instruction count: 3: __C29FSContainer.<clinit>
2022-11-09 14:19:19 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-09 14:19:19 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 14:19:19 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compe065.hpc.in.bmrc.ox.ac.uk:35806 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 14:19:19 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:19 root: INFO: instruction count: 3: __C32etypeEncode.<init>
2022-11-09 14:19:19 root: INFO: instruction count: 5: __C32etypeEncode.apply
2022-11-09 14:19:19 root: INFO: instruction count: 19: __C32etypeEncode.__m33ENCODE_r_tuple_of_r_locusANDr_array_of_r_stringEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:19 root: INFO: instruction count: 23: __C32etypeEncode.__m34ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:19 root: INFO: instruction count: 16: __C32etypeEncode.__m35ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:19 root: INFO: instruction count: 4: __C32etypeEncode.__m36ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:19 root: INFO: instruction count: 53: __C32etypeEncode.__m37ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:19 root: INFO: timing SparkBackend.parse_matrix_ir total 1.605s self 1.605s children 0.000ms %children 0.00%
2022-11-09 14:19:19 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 14:19:19 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:19:19 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 14:19:19 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compe065.hpc.in.bmrc.ox.ac.uk:39361 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 14:19:19 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:19 root: INFO: timing SparkBackend.parse_value_ir total 84.966ms self 84.966ms children 0.000ms %children 0.00%
2022-11-09 14:19:19 root: INFO: starting execution of query hail_query_1 of initial size 8
2022-11-09 14:19:19 root: INFO: timing SparkBackend.parse_matrix_ir total 1.753s self 1.753s children 0.000ms %children 0.00%
2022-11-09 14:19:19 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:19:19 SparkContext: INFO: Starting job: collect at ContextRDD.scala:166
2022-11-09 14:19:19 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:166) with 1 output partitions
2022-11-09 14:19:19 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:166)
2022-11-09 14:19:19 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:19 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:19 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-09 14:19:19 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 8: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr17.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (MatrixRowsTable
      (MatrixRead None False False
        "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr17.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
    (InsertFields
      (SelectFields (locus alleles)
        (SelectFields 
          (locus alleles rsid qual filters info)
          (Ref row)))
      None)))
2022-11-09 14:19:19 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 312.3 KB, free 411.6 MB)
2022-11-09 14:19:19 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 114.5 KB, free 411.5 MB)
2022-11-09 14:19:19 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compe065.hpc.in.bmrc.ox.ac.uk:37201 (size: 114.5 KB, free: 413.7 MB)
2022-11-09 14:19:19 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:19 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:19 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-09 14:19:19 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8057 bytes)
2022-11-09 14:19:19 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-09 14:19:19 root: INFO: timing SparkBackend.parse_value_ir total 88.930ms self 88.930ms children 0.000ms %children 0.00%
2022-11-09 14:19:19 root: INFO: starting execution of query hail_query_1 of initial size 8
2022-11-09 14:19:19 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 3:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr17.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead
      Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String]},entry:Struct{}}
      True False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr17.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-09 14:19:19 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 16: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr17.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (TableMapGlobals
      (TableMapGlobals
        (TableMapRows
          (TableRead
            Table{global:Struct{__cols:Array[Struct{s:String}]},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{}]}}
            False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr17.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
          (InsertFields
            (Ref row)
            None
            (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
              (MakeArray Array[Struct{}]))))
        (InsertFields
          (Ref global)
          None
          (__cols (MakeArray Array[Struct{s:String}]))))
      (SelectFields () (Ref global)))
    (SelectFields (locus alleles) (Ref row))))
2022-11-09 14:19:19 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:19:19 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-09 14:19:19 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 2:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr17.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableRead
    Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String]}}
    False
    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr17.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
2022-11-09 14:19:19 root: INFO: interpreting non compilable node: TableWrite
2022-11-09 14:19:19 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 8: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr11.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (MatrixRowsTable
      (MatrixRead None False False
        "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr11.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
    (InsertFields
      (SelectFields (locus alleles)
        (SelectFields 
          (locus alleles rsid qual filters info)
          (Ref row)))
      None)))
2022-11-09 14:19:19 root: INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:19 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1536 bytes result sent to driver
2022-11-09 14:19:19 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:19:19 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:19:19 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 3:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr11.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead
      Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String]},entry:Struct{}}
      True False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr11.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-09 14:19:19 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1539 bytes result sent to driver
2022-11-09 14:19:19 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 4768 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:20 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 16: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr11.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (TableMapGlobals
      (TableMapGlobals
        (TableMapRows
          (TableRead
            Table{global:Struct{__cols:Array[Struct{s:String}]},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{}]}}
            False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr11.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
          (InsertFields
            (Ref row)
            None
            (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
              (MakeArray Array[Struct{}]))))
        (InsertFields
          (Ref global)
          None
          (__cols (MakeArray Array[Struct{s:String}]))))
      (SelectFields () (Ref global)))
    (SelectFields (locus alleles) (Ref row))))
2022-11-09 14:19:20 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:19:20 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 5.136 s
2022-11-09 14:19:20 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 4073 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:20 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 5.349217 s
2022-11-09 14:19:20 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-09 14:19:20 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 4.276 s
2022-11-09 14:19:20 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-09 14:19:20 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 2:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr11.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableRead
    Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String]}}
    False
    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr11.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
2022-11-09 14:19:20 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:19:20 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:19:20 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 4.424867 s
2022-11-09 14:19:20 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-09 14:19:20 Hail: INFO: Coerced sorted dataset
2022-11-09 14:19:20 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-09 14:19:20 root: INFO: interpreting non compilable node: TableWrite
2022-11-09 14:19:20 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-09 14:19:20 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-09 14:19:20 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:19:20 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-09 14:19:20 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe077.hpc.in.bmrc.ox.ac.uk:41191 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:19:20 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-09 14:19:20 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:20 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:20 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:20 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:19:20 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-09 14:19:20 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-09 14:19:20 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compe065.hpc.in.bmrc.ox.ac.uk:37201 in memory (size: 7.4 KB, free: 413.7 MB)
2022-11-09 14:19:20 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.sites_only.chr8.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr8.vcf.bgz
2022-11-09 14:19:20 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.sites_only.chr8.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr8.vcf.bgz
2022-11-09 14:19:20 Hail: INFO: Coerced sorted dataset
2022-11-09 14:19:20 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:19:20 root: INFO: RegionPool: REPORT_THRESHOLD: 4.0M allocated (3.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:20 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-09 14:19:20 root: INFO: instruction count: 3: __C1etypeEncode.<init>
2022-11-09 14:19:20 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-09 14:19:20 root: INFO: instruction count: 5: __C1etypeEncode.apply
2022-11-09 14:19:20 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compe065.hpc.in.bmrc.ox.ac.uk:35806 (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:20 root: INFO: instruction count: 3: __C1etypeEncode.__m2ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:20 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:20 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:19:20 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:20 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-09 14:19:20 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-09 14:19:20 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-09 14:19:20 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8053 bytes)
2022-11-09 14:19:20 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-09 14:19:20 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-09 14:19:20 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:20 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:20 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-09 14:19:20 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-09 14:19:20 root: INFO: instruction count: 3: __C1etypeEncode.<init>
2022-11-09 14:19:20 root: INFO: instruction count: 5: __C1etypeEncode.apply
2022-11-09 14:19:20 root: INFO: instruction count: 3: __C1etypeEncode.__m2ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:20 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:19:20 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-09 14:19:20 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:19:20 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-09 14:19:20 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:19:20 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-09 14:19:20 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compe065.hpc.in.bmrc.ox.ac.uk:39361 (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:20 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:20 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 14:19:20 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:21 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-09 14:19:21 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:21 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:21 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:21 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8053 bytes)
2022-11-09 14:19:21 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 14:19:21 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-09 14:19:21 root: INFO: instruction count: 3: __C3indexwriter.<init>
2022-11-09 14:19:21 root: INFO: instruction count: 234: __C3indexwriter.apply
2022-11-09 14:19:21 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compe077.hpc.in.bmrc.ox.ac.uk:41191 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 14:19:21 root: INFO: RegionPool: REPORT_THRESHOLD: 8.0M allocated (7.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:21 root: INFO: instruction count: 445: __C3indexwriter.__m12writeInternalNode
2022-11-09 14:19:21 root: INFO: instruction count: 13: __C3indexwriter.__m13ENCODE_o_tuple_of_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:21 root: INFO: instruction count: 49: __C3indexwriter.__m14ENCODE_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:21 root: INFO: instruction count: 45: __C3indexwriter.__m15ENCODE_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:21 root: INFO: instruction count: 4: __C3indexwriter.__m16ENCODE_r_int64_TO_r_int64
2022-11-09 14:19:21 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:21 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-09 14:19:21 root: INFO: instruction count: 19: __C3indexwriter.__m17ENCODE_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:21 root: INFO: instruction count: 23: __C3indexwriter.__m18ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:21 root: INFO: instruction count: 3: __C3indexwriter.<init>
2022-11-09 14:19:21 root: INFO: instruction count: 234: __C3indexwriter.apply
2022-11-09 14:19:21 root: INFO: instruction count: 445: __C3indexwriter.__m12writeInternalNode
2022-11-09 14:19:21 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:19:21 root: INFO: timing SparkBackend.parse_matrix_ir total 1.698s self 1.698s children 0.000ms %children 0.00%
2022-11-09 14:19:21 root: INFO: instruction count: 16: __C3indexwriter.__m19ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:21 root: INFO: instruction count: 4: __C3indexwriter.__m20ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:21 root: INFO: instruction count: 53: __C3indexwriter.__m21ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:21 root: INFO: instruction count: 3: __C3indexwriter.__m22ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:21 root: INFO: instruction count: 379: __C3indexwriter.__m23writeLeafNode
2022-11-09 14:19:21 root: INFO: instruction count: 23: __C3indexwriter.__m24ENCODE_o_tuple_of_r_int64ANDr_array_of_r_tuple_of_r_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_int64ANDr_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:21 root: INFO: instruction count: 49: __C3indexwriter.__m25ENCODE_r_array_of_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:21 root: INFO: instruction count: 25: __C3indexwriter.__m26ENCODE_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:21 root: INFO: instruction count: 52: __C3indexwriter.__m27flush
2022-11-09 14:19:21 root: INFO: instruction count: 150: __C3indexwriter.init
2022-11-09 14:19:21 root: INFO: instruction count: 4: __C3indexwriter.setObjects
2022-11-09 14:19:21 root: INFO: instruction count: 28: __C3indexwriter.close
2022-11-09 14:19:21 root: INFO: instruction count: 7: __C3indexwriter.trackedOS
2022-11-09 14:19:21 root: INFO: instruction count: 9: __C3indexwriter.setPartitionIndex
2022-11-09 14:19:21 root: INFO: instruction count: 13: __C3indexwriter.__m13ENCODE_o_tuple_of_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:21 root: INFO: instruction count: 49: __C3indexwriter.__m14ENCODE_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:21 root: INFO: instruction count: 45: __C3indexwriter.__m15ENCODE_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:21 root: INFO: instruction count: 4: __C3indexwriter.__m16ENCODE_r_int64_TO_r_int64
2022-11-09 14:19:21 root: INFO: instruction count: 19: __C3indexwriter.__m17ENCODE_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:21 root: INFO: instruction count: 23: __C3indexwriter.__m18ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:21 root: INFO: instruction count: 16: __C3indexwriter.__m19ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:21 root: INFO: instruction count: 4: __C3indexwriter.__m20ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:21 root: INFO: instruction count: 53: __C3indexwriter.__m21ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:21 root: INFO: instruction count: 3: __C3indexwriter.__m22ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:21 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:21 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:19:21 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:19:21 root: INFO: instruction count: 4: __C3indexwriter.addPartitionRegion
2022-11-09 14:19:21 root: INFO: instruction count: 3: __C29FSContainer.<init>
2022-11-09 14:19:21 root: INFO: instruction count: 379: __C3indexwriter.__m23writeLeafNode
2022-11-09 14:19:21 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:21 root: INFO: timing SparkBackend.parse_value_ir total 72.168ms self 72.168ms children 0.000ms %children 0.00%
2022-11-09 14:19:21 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:19:21 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:19:21 root: INFO: instruction count: 28: __C29FSContainer.init_filesystem
2022-11-09 14:19:21 root: INFO: instruction count: 3: __C29FSContainer.<clinit>
2022-11-09 14:19:21 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-09 14:19:21 root: INFO: instruction count: 23: __C3indexwriter.__m24ENCODE_o_tuple_of_r_int64ANDr_array_of_r_tuple_of_r_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_int64ANDr_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:21 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:21 root: INFO: starting execution of query hail_query_1 of initial size 8
2022-11-09 14:19:21 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:19:21 root: INFO: instruction count: 3: __C32etypeEncode.<init>
2022-11-09 14:19:21 root: INFO: instruction count: 5: __C32etypeEncode.apply
2022-11-09 14:19:21 root: INFO: instruction count: 19: __C32etypeEncode.__m33ENCODE_r_tuple_of_r_locusANDr_array_of_r_stringEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:21 root: INFO: instruction count: 23: __C32etypeEncode.__m34ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:21 root: INFO: instruction count: 16: __C32etypeEncode.__m35ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:21 root: INFO: instruction count: 4: __C32etypeEncode.__m36ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:21 root: INFO: instruction count: 53: __C32etypeEncode.__m37ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:21 root: INFO: instruction count: 49: __C3indexwriter.__m25ENCODE_r_array_of_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:21 root: INFO: RegionPool: REPORT_THRESHOLD: 16.0M allocated (15.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:21 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:19:21 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 8: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr8.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (MatrixRowsTable
      (MatrixRead None False False
        "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr8.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
    (InsertFields
      (SelectFields (locus alleles)
        (SelectFields 
          (locus alleles rsid qual filters info)
          (Ref row)))
      None)))
2022-11-09 14:19:21 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:19:21 root: INFO: instruction count: 25: __C3indexwriter.__m26ENCODE_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:21 root: INFO: instruction count: 52: __C3indexwriter.__m27flush
2022-11-09 14:19:21 root: INFO: instruction count: 150: __C3indexwriter.init
2022-11-09 14:19:21 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe039.hpc.in.bmrc.ox.ac.uk:44800 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:19:21 root: INFO: instruction count: 4: __C3indexwriter.setObjects
2022-11-09 14:19:21 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 3:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr8.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead
      Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String]},entry:Struct{}}
      True False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr8.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-09 14:19:22 root: INFO: instruction count: 28: __C3indexwriter.close
2022-11-09 14:19:22 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:22 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:19:21 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:19:22 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 16: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr8.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (TableMapGlobals
      (TableMapGlobals
        (TableMapRows
          (TableRead
            Table{global:Struct{__cols:Array[Struct{s:String}]},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{}]}}
            False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr8.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
          (InsertFields
            (Ref row)
            None
            (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
              (MakeArray Array[Struct{}]))))
        (InsertFields
          (Ref global)
          None
          (__cols (MakeArray Array[Struct{s:String}]))))
      (SelectFields () (Ref global)))
    (SelectFields (locus alleles) (Ref row))))
2022-11-09 14:19:22 root: INFO: instruction count: 7: __C3indexwriter.trackedOS
2022-11-09 14:19:22 root: INFO: instruction count: 9: __C3indexwriter.setPartitionIndex
2022-11-09 14:19:22 root: INFO: instruction count: 4: __C3indexwriter.addPartitionRegion
2022-11-09 14:19:22 root: INFO: instruction count: 3: __C29FSContainer.<init>
2022-11-09 14:19:22 SparkContext: INFO: Starting job: collect at ContextRDD.scala:166
2022-11-09 14:19:22 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.sites_only.chr5.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr5.vcf.bgz
2022-11-09 14:19:22 root: INFO: instruction count: 28: __C29FSContainer.init_filesystem
2022-11-09 14:19:22 root: INFO: instruction count: 3: __C29FSContainer.<clinit>
2022-11-09 14:19:22 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-09 14:19:22 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.sites_only.chr5.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr5.vcf.bgz
2022-11-09 14:19:22 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:166) with 1 output partitions
2022-11-09 14:19:22 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-09 14:19:22 root: INFO: instruction count: 3: __C32etypeEncode.<init>
2022-11-09 14:19:22 root: INFO: instruction count: 5: __C32etypeEncode.apply
2022-11-09 14:19:22 root: INFO: instruction count: 19: __C32etypeEncode.__m33ENCODE_r_tuple_of_r_locusANDr_array_of_r_stringEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:22 root: INFO: instruction count: 23: __C32etypeEncode.__m34ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:22 root: INFO: instruction count: 16: __C32etypeEncode.__m35ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:22 root: INFO: instruction count: 4: __C32etypeEncode.__m36ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:22 root: INFO: instruction count: 53: __C32etypeEncode.__m37ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:22 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:166)
2022-11-09 14:19:22 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 2:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr8.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableRead
    Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String]}}
    False
    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr8.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
2022-11-09 14:19:22 root: INFO: interpreting non compilable node: TableWrite
2022-11-09 14:19:22 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:22 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:22 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-09 14:19:22 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:19:22 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:19:22 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:19:22 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 312.3 KB, free 411.6 MB)
2022-11-09 14:19:22 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:19:22 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:19:22 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 114.5 KB, free 411.5 MB)
2022-11-09 14:19:22 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:19:22 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compe041.hpc.in.bmrc.ox.ac.uk:34367 (size: 114.5 KB, free: 413.7 MB)
2022-11-09 14:19:22 root: INFO: RegionPool: REPORT_THRESHOLD: 32.0M allocated (31.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:22 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:22 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:22 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-09 14:19:22 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8057 bytes)
2022-11-09 14:19:22 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-09 14:19:22 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-09 14:19:22 SparkContext: INFO: Starting job: collect at ContextRDD.scala:166
2022-11-09 14:19:22 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-09 14:19:22 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:19:22 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 14:19:22 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:166) with 1 output partitions
2022-11-09 14:19:22 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-09 14:19:22 root: INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:22 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:19:22 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:19:22 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:19:22 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:166)
2022-11-09 14:19:22 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:22 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:22 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-09 14:19:22 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:22 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:19:22 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 14:19:22 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe078.hpc.in.bmrc.ox.ac.uk:34810 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:19:22 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 312.3 KB, free 411.6 MB)
2022-11-09 14:19:22 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:19:22 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:19:23 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compa023.hpc.in.bmrc.ox.ac.uk:38669 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:19:23 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compa043.hpc.in.bmrc.ox.ac.uk:41694 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:19:23 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:19:23 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compe039.hpc.in.bmrc.ox.ac.uk:44800 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 14:19:22 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:19:23 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:19:23 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 114.5 KB, free 411.5 MB)
2022-11-09 14:19:23 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compe061.hpc.in.bmrc.ox.ac.uk:38723 (size: 114.5 KB, free: 413.7 MB)
2022-11-09 14:19:23 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:23 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:23 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-09 14:19:23 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8057 bytes)
2022-11-09 14:19:23 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-09 14:19:23 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:23 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:23 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-09 14:19:23 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:22 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe078.hpc.in.bmrc.ox.ac.uk:41045 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:19:23 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:19:23 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:23 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:19:23 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.sites_only.chr10.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr10.vcf.bgz
2022-11-09 14:19:23 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:23 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-09 14:19:23 root: INFO: timing SparkBackend.parse_matrix_ir total 2.945s self 2.945s children 0.000ms %children 0.00%
2022-11-09 14:19:23 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.sites_only.chr7.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr7.vcf.bgz
2022-11-09 14:19:23 root: INFO: RegionPool: REPORT_THRESHOLD: 4.0M allocated (3.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:23 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.sites_only.chr7.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr7.vcf.bgz
2022-11-09 14:19:23 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.sites_only.chr10.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr10.vcf.bgz
2022-11-09 14:19:23 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:23 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.sites_only.chr20.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr20.vcf.bgz
2022-11-09 14:19:23 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-09 14:19:23 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:19:23 root: INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:23 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.sites_only.chr20.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr20.vcf.bgz
2022-11-09 14:19:23 root: INFO: timing SparkBackend.parse_value_ir total 101.382ms self 101.382ms children 0.000ms %children 0.00%
2022-11-09 14:19:23 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compe077.hpc.in.bmrc.ox.ac.uk:41191 (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:23 root: INFO: starting execution of query hail_query_1 of initial size 8
2022-11-09 14:19:24 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:23 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.sites_only.chr12.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr12.vcf.bgz
2022-11-09 14:19:23 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:19:24 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.sites_only.chr12.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr12.vcf.bgz
2022-11-09 14:19:23 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:19:24 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe078.hpc.in.bmrc.ox.ac.uk:39195 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:19:23 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-09 14:19:24 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:24 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-09 14:19:24 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes)
2022-11-09 14:19:24 root: INFO: RegionPool: REPORT_THRESHOLD: 64.0M allocated (63.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:24 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:19:24 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:19:24 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:24 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 8: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr5.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (MatrixRowsTable
      (MatrixRead None False False
        "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr5.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
    (InsertFields
      (SelectFields (locus alleles)
        (SelectFields 
          (locus alleles rsid qual filters info)
          (Ref row)))
      None)))
2022-11-09 14:19:24 root: INFO: RegionPool: REPORT_THRESHOLD: 8.0M allocated (7.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:24 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-09 14:19:24 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1548 bytes result sent to driver
2022-11-09 14:19:24 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.sites_only.chr9.vcf.bgz returned 0 files: 
2022-11-09 14:19:24 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 14:19:24 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:19:24 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:19:24 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compa042.hpc.in.bmrc.ox.ac.uk:35350 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:19:24 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 14:19:24 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compe041.hpc.in.bmrc.ox.ac.uk:34367 in memory (size: 7.4 KB, free: 413.7 MB)
2022-11-09 14:19:24 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:19:24 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 3:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr5.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead
      Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String]},entry:Struct{}}
      True False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr5.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-09 14:19:24 Hail: WARN: 'data/vcf/ukb_wes_450k.qced.sites_only.chr9.vcf.bgz' refers to no files
2022-11-09 14:19:24 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-09 14:19:24 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:24 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 3548 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:24 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 3.875 s
2022-11-09 14:19:24 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-09 14:19:24 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 3.995431 s
2022-11-09 14:19:24 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 14:19:24 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 16: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr5.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (TableMapGlobals
      (TableMapGlobals
        (TableMapRows
          (TableRead
            Table{global:Struct{__cols:Array[Struct{s:String}]},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{}]}}
            False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr5.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
          (InsertFields
            (Ref row)
            None
            (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
              (MakeArray Array[Struct{}]))))
        (InsertFields
          (Ref global)
          None
          (__cols (MakeArray Array[Struct{s:String}]))))
      (SelectFields () (Ref global)))
    (SelectFields (locus alleles) (Ref row))))
2022-11-09 14:19:24 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 14:19:24 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compa043.hpc.in.bmrc.ox.ac.uk:41694 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 14:19:24 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-09 14:19:24 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.sites_only.chr6.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr6.vcf.bgz
2022-11-09 14:19:24 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.sites_only.chr6.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr6.vcf.bgz
2022-11-09 14:19:24 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 14:19:24 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:24 root: INFO: The exact same exception object, is.hail.utils.HailException: arguments refer to no files, was thrown by both
the consumer and the close method. I will throw the original.
2022-11-09 14:19:24 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 14:19:24 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 14:19:24 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-09 14:19:24 root: INFO: RegionPool: REPORT_THRESHOLD: 4.0M allocated (3.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:24 root: INFO: timing SparkBackend.parse_matrix_ir total 3.084s self 3.084s children 0.000ms %children 0.00%
2022-11-09 14:19:24 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:19:24 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compa023.hpc.in.bmrc.ox.ac.uk:38669 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 14:19:24 Hail: INFO: Coerced sorted dataset
2022-11-09 14:19:24 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:24 root: ERROR: HailException: arguments refer to no files
From is.hail.utils.HailException: arguments refer to no files
	at is.hail.utils.ErrorHandling$class.fatal(ErrorHandling.scala:11)
	at is.hail.utils.package$.fatal(package.scala:77)
	at is.hail.io.vcf.LoadVCF$.globAllVCFs(LoadVCF.scala:1132)
	at is.hail.io.vcf.MatrixVCFReader$.apply(LoadVCF.scala:1557)
	at is.hail.io.vcf.MatrixVCFReader$.fromJValue(LoadVCF.scala:1652)
	at is.hail.expr.ir.MatrixReader$.fromJson(MatrixIR.scala:91)
	at is.hail.expr.ir.IRParser$.matrix_ir_1(Parser.scala:1693)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.expr.ir.IRParser$$anonfun$matrix_ir$1.apply(Parser.scala:1619)
	at is.hail.utils.StackSafe$More.advance(StackSafe.scala:64)
	at is.hail.utils.StackSafe$.run(StackSafe.scala:16)
	at is.hail.utils.StackSafe$StackFrame.run(StackSafe.scala:32)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$$anonfun$parse_matrix_ir$1.apply(Parser.scala:1959)
	at is.hail.expr.ir.IRParser$.parse(Parser.scala:1946)
	at is.hail.expr.ir.IRParser$.parse_matrix_ir(Parser.scala:1959)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:604)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1$$anonfun$apply$22.apply(SparkBackend.scala:603)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:25)
	at is.hail.expr.ir.ExecuteContext$$anonfun$scoped$1.apply(ExecuteContext.scala:23)
	at is.hail.utils.package$.using(package.scala:618)
	at is.hail.annotations.Region$.scoped(Region.scala:18)
	at is.hail.expr.ir.ExecuteContext$.scoped(ExecuteContext.scala:23)
	at is.hail.backend.spark.SparkBackend.withExecuteContext(SparkBackend.scala:247)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:603)
	at is.hail.backend.spark.SparkBackend$$anonfun$parse_matrix_ir$1.apply(SparkBackend.scala:602)
	at is.hail.utils.ExecutionTimer$.time(ExecutionTimer.scala:52)
	at is.hail.utils.ExecutionTimer$.logTime(ExecutionTimer.scala:59)
	at is.hail.backend.spark.SparkBackend.parse_matrix_ir(SparkBackend.scala:602)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:282)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:238)
	at java.lang.Thread.run(Thread.java:748)



2022-11-09 14:19:24 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compe078.hpc.in.bmrc.ox.ac.uk:41045 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 14:19:24 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:24 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 2:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr5.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableRead
    Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String]}}
    False
    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr5.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
2022-11-09 14:19:24 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:24 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compa040.hpc.in.bmrc.ox.ac.uk:37984 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:19:24 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 916 bytes result sent to driver
2022-11-09 14:19:24 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:24 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:19:24 root: INFO: interpreting non compilable node: TableWrite
2022-11-09 14:19:24 root: INFO: RegionPool: REPORT_THRESHOLD: 16.0M allocated (15.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:24 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:24 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 4984 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:24 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.sites_only.chr4.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr4.vcf.bgz
2022-11-09 14:19:24 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-09 14:19:24 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 14:19:24 root: INFO: timing SparkBackend.parse_matrix_ir total 3.230s self 3.230s children 0.000ms %children 0.00%
2022-11-09 14:19:24 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compe078.hpc.in.bmrc.ox.ac.uk:34810 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 14:19:24 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:24 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.sites_only.chr4.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr4.vcf.bgz
2022-11-09 14:19:24 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:166) finished in 5.070 s
2022-11-09 14:19:24 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-09 14:19:24 root: INFO: timing SparkBackend.parse_matrix_ir total 3.370s self 3.370s children 0.000ms %children 0.00%
2022-11-09 14:19:24 root: INFO: timing SparkBackend.parse_value_ir total 96.832ms self 96.832ms children 0.000ms %children 0.00%
2022-11-09 14:19:24 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:19:24 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:166, took 5.141562 s
2022-11-09 14:19:24 root: INFO: starting execution of query hail_query_1 of initial size 8
2022-11-09 14:19:24 root: INFO: timing SparkBackend.parse_matrix_ir total 3.349s self 3.349s children 0.000ms %children 0.00%
2022-11-09 14:19:24 root: INFO: timing SparkBackend.parse_value_ir total 81.153ms self 81.153ms children 0.000ms %children 0.00%
2022-11-09 14:19:24 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:19:24 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-09 14:19:24 root: INFO: timing SparkBackend.parse_value_ir total 68.311ms self 68.311ms children 0.000ms %children 0.00%
2022-11-09 14:19:24 root: INFO: starting execution of query hail_query_1 of initial size 8
2022-11-09 14:19:24 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:19:24 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1553 bytes result sent to driver
2022-11-09 14:19:25 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 8: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr7.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (MatrixRowsTable
      (MatrixRead None False False
        "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr7.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
    (InsertFields
      (SelectFields (locus alleles)
        (SelectFields 
          (locus alleles rsid qual filters info)
          (Ref row)))
      None)))
2022-11-09 14:19:25 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-09 14:19:25 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-09 14:19:25 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-09 14:19:25 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-09 14:19:25 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-09 14:19:25 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-09 14:19:25 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-09 14:19:25 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-09 14:19:25 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-09 14:19:25 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-09 14:19:25 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-09 14:19:25 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-09 14:19:25 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-09 14:19:25 root: INFO: starting execution of query hail_query_1 of initial size 8
2022-11-09 14:19:25 root: INFO: timing SparkBackend.parse_value_ir total 91.370ms self 91.370ms children 0.000ms %children 0.00%
2022-11-09 14:19:25 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-09 14:19:25 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 14:19:25 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:19:25 Hail: INFO: wrote table with 1029836 rows in 1 partition to data/ht/ukb_wes_450k.qced.chr3.ht
    Total size: 12.62 MiB
    * Rows: 12.62 MiB
    * Globals: 11.00 B
    * Smallest partition: 1029836 rows (12.62 MiB)
    * Largest partition:  1029836 rows (12.62 MiB)
2022-11-09 14:19:25 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compe061.hpc.in.bmrc.ox.ac.uk:38723 in memory (size: 7.4 KB, free: 413.7 MB)
2022-11-09 14:19:25 root: INFO: RegionPool: REPORT_THRESHOLD: 8.0M allocated (7.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:25 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 3:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr7.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead
      Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String]},entry:Struct{}}
      True False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr7.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-09 14:19:25 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:19:25 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 8: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr20.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (MatrixRowsTable
      (MatrixRead None False False
        "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr20.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
    (InsertFields
      (SelectFields (locus alleles)
        (SelectFields 
          (locus alleles rsid qual filters info)
          (Ref row)))
      None)))
2022-11-09 14:19:25 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 8: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr10.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (MatrixRowsTable
      (MatrixRead None False False
        "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr10.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
    (InsertFields
      (SelectFields (locus alleles)
        (SelectFields 
          (locus alleles rsid qual filters info)
          (Ref row)))
      None)))
2022-11-09 14:19:25 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 14:19:25 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-09 14:19:25 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe070.hpc.in.bmrc.ox.ac.uk:46576 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:19:25 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:19:25 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 4081 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:25 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 14:19:25 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compa042.hpc.in.bmrc.ox.ac.uk:35350 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 14:19:25 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:25 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 16: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr7.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (TableMapGlobals
      (TableMapGlobals
        (TableMapRows
          (TableRead
            Table{global:Struct{__cols:Array[Struct{s:String}]},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{}]}}
            False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr7.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
          (InsertFields
            (Ref row)
            None
            (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
              (MakeArray Array[Struct{}]))))
        (InsertFields
          (Ref global)
          None
          (__cols (MakeArray Array[Struct{s:String}]))))
      (SelectFields () (Ref global)))
    (SelectFields (locus alleles) (Ref row))))
2022-11-09 14:19:25 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compf004.hpc.in.bmrc.ox.ac.uk:39715 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:19:25 root: INFO: starting execution of query hail_query_1 of initial size 8
2022-11-09 14:19:25 root: INFO: RegionPool: REPORT_THRESHOLD: 32.0M allocated (31.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:25 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 3:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr20.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead
      Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String]},entry:Struct{}}
      True False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr20.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-09 14:19:25 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:19:25 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-09 14:19:25 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:25 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.sites_only.chr18.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr18.vcf.bgz
2022-11-09 14:19:25 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.sites_only.chr18.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr18.vcf.bgz
2022-11-09 14:19:25 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 3:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr10.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead
      Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String]},entry:Struct{}}
      True False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr10.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-09 14:19:25 root: INFO: took 11.315s
2022-11-09 14:19:25 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 14:19:25 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:19:25 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-09 14:19:25 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:25 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:19:25 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-09 14:19:25 root: INFO: timing SparkBackend.parse_matrix_ir total 3.135s self 3.135s children 0.000ms %children 0.00%
2022-11-09 14:19:25 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 16: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr20.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (TableMapGlobals
      (TableMapGlobals
        (TableMapRows
          (TableRead
            Table{global:Struct{__cols:Array[Struct{s:String}]},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{}]}}
            False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr20.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
          (InsertFields
            (Ref row)
            None
            (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
              (MakeArray Array[Struct{}]))))
        (InsertFields
          (Ref global)
          None
          (__cols (MakeArray Array[Struct{s:String}]))))
      (SelectFields () (Ref global)))
    (SelectFields (locus alleles) (Ref row))))
2022-11-09 14:19:25 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:25 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:19:25 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 4.824 s
2022-11-09 14:19:25 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 1: 
(Begin)
2022-11-09 14:19:25 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compa040.hpc.in.bmrc.ox.ac.uk:37984 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 14:19:26 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 16: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr10.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (TableMapGlobals
      (TableMapGlobals
        (TableMapRows
          (TableRead
            Table{global:Struct{__cols:Array[Struct{s:String}]},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{}]}}
            False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr10.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
          (InsertFields
            (Ref row)
            None
            (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
              (MakeArray Array[Struct{}]))))
        (InsertFields
          (Ref global)
          None
          (__cols (MakeArray Array[Struct{s:String}]))))
      (SelectFields () (Ref global)))
    (SelectFields (locus alleles) (Ref row))))
2022-11-09 14:19:26 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 2:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr7.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableRead
    Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String]}}
    False
    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr7.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
2022-11-09 14:19:26 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.sites_only.chr22.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr22.vcf.bgz
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-09 14:19:24 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:19:26 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-09 14:19:26 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:26 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Begin)
2022-11-09 14:19:26 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:26 root: INFO: interpreting non compilable node: TableWrite
2022-11-09 14:19:26 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.sites_only.chr22.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr22.vcf.bgz
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-09 14:19:26 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-09 14:19:26 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 2:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr20.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableRead
    Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String]}}
    False
    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr20.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
2022-11-09 14:19:26 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 5.308216 s
2022-11-09 14:19:26 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-09 14:19:26 root: INFO: timing SparkBackend.parse_value_ir total 85.928ms self 85.928ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-09 14:19:26 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-09 14:19:26 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 2:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr10.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableRead
    Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String]}}
    False
    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr10.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
2022-11-09 14:19:26 root: INFO: interpreting non compilable node: TableWrite
2022-11-09 14:19:26 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:19:26 root: INFO: timing SparkBackend.parse_matrix_ir total 3.416s self 3.416s children 0.000ms %children 0.00%
2022-11-09 14:19:26 root: INFO: finished execution of query hail_query_1
2022-11-09 14:19:25 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-09 14:19:26 root: INFO: starting execution of query hail_query_1 of initial size 8
2022-11-09 14:19:25 root: INFO: RegionPool: REPORT_THRESHOLD: 16.0M allocated (15.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:26 root: INFO: interpreting non compilable node: TableWrite
2022-11-09 14:19:25 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 8: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr12.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (MatrixRowsTable
      (MatrixRead None False False
        "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr12.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
    (InsertFields
      (SelectFields (locus alleles)
        (SelectFields 
          (locus alleles rsid qual filters info)
          (Ref row)))
      None)))
2022-11-09 14:19:26 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-09 14:19:26 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe094.hpc.in.bmrc.ox.ac.uk:33393 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:19:26 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON total 12.627s self 217.022ms children 12.410s %children 98.28%
2022-11-09 14:19:26 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 195.526ms self 0.642ms children 194.884ms %children 99.67%
2022-11-09 14:19:24 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-09 14:19:26 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compe039.hpc.in.bmrc.ox.ac.uk:44800 (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.325ms self 0.325ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 194.509ms self 139.979ms children 54.531ms %children 28.03%
2022-11-09 14:19:26 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:26 Hail: INFO: Coerced sorted dataset
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 54.531ms self 1.243ms children 53.288ms %children 97.72%
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 3.190ms self 3.190ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 4.356ms self 4.356ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 13.584ms self 13.584ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 8.524ms self 8.524ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 1.698ms self 1.698ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 20.156ms self 20.156ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.144ms self 0.144ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.079ms self 0.079ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.139ms self 0.139ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.269ms self 0.269ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.452ms self 0.452ms children 0.000ms %children 0.00%
2022-11-09 14:19:24 root: INFO: instruction count: 3: __C1etypeEncode.<init>
2022-11-09 14:19:26 root: INFO: instruction count: 5: __C1etypeEncode.apply
2022-11-09 14:19:26 root: INFO: instruction count: 3: __C1etypeEncode.__m2ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:26 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compa036.hpc.in.bmrc.ox.ac.uk:35064 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.074ms self 0.074ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.sites_only.chrX.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chrX.vcf.bgz
2022-11-09 14:19:26 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.012ms self 0.012ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-09 14:19:26 root: INFO: timing SparkBackend.parse_value_ir total 69.960ms self 69.960ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.041ms self 0.041ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-09 14:19:26 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.sites_only.chrX.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chrX.vcf.bgz
2022-11-09 14:19:26 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 8: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr6.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (MatrixRowsTable
      (MatrixRead None False False
        "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr6.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
    (InsertFields
      (SelectFields (locus alleles)
        (SelectFields 
          (locus alleles rsid qual filters info)
          (Ref row)))
      None)))
2022-11-09 14:19:26 root: INFO: starting execution of query hail_query_1 of initial size 8
2022-11-09 14:19:26 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compe065.hpc.in.bmrc.ox.ac.uk:35806 in memory (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:26 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.sites_only.chr13.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr13.vcf.bgz
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-09 14:19:26 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 3:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr12.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead
      Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String]},entry:Struct{}}
      True False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr12.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-09 14:19:26 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes)
2022-11-09 14:19:26 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 14:19:26 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.215ms self 0.215ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.sites_only.chr13.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr13.vcf.bgz
2022-11-09 14:19:26 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compe070.hpc.in.bmrc.ox.ac.uk:46576 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 14:19:26 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 16: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr12.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (TableMapGlobals
      (TableMapGlobals
        (TableMapRows
          (TableRead
            Table{global:Struct{__cols:Array[Struct{s:String}]},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{}]}}
            False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr12.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
          (InsertFields
            (Ref row)
            None
            (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
              (MakeArray Array[Struct{}]))))
        (InsertFields
          (Ref global)
          None
          (__cols (MakeArray Array[Struct{s:String}]))))
      (SelectFields () (Ref global)))
    (SelectFields (locus alleles) (Ref row))))
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.017ms self 0.017ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-09 14:19:26 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-09 14:19:26 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 3:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr6.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead
      Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String]},entry:Struct{}}
      True False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr6.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.316ms self 0.316ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-09 14:19:26 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 16: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr6.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (TableMapGlobals
      (TableMapGlobals
        (TableMapRows
          (TableRead
            Table{global:Struct{__cols:Array[Struct{s:String}]},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{}]}}
            False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr6.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
          (InsertFields
            (Ref row)
            None
            (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
              (MakeArray Array[Struct{}]))))
        (InsertFields
          (Ref global)
          None
          (__cols (MakeArray Array[Struct{s:String}]))))
      (SelectFields () (Ref global)))
    (SelectFields (locus alleles) (Ref row))))
2022-11-09 14:19:26 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 14:19:26 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 8: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr4.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (MatrixRowsTable
      (MatrixRead None False False
        "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr4.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
    (InsertFields
      (SelectFields (locus alleles)
        (SelectFields 
          (locus alleles rsid qual filters info)
          (Ref row)))
      None)))
2022-11-09 14:19:26 root: INFO: timing SparkBackend.parse_matrix_ir total 2.501s self 2.501s children 0.000ms %children 0.00%
2022-11-09 14:19:26 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-09 14:19:26 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-09 14:19:26 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.050ms self 0.050ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-09 14:19:26 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-09 14:19:26 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-09 14:19:26 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 2:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr6.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableRead
    Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String]}}
    False
    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr6.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
2022-11-09 14:19:26 root: INFO: interpreting non compilable node: TableWrite
2022-11-09 14:19:26 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 2:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr12.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableRead
    Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String]}}
    False
    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr12.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-09 14:19:26 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-09 14:19:26 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 7.132ms self 0.016ms children 7.116ms %children 99.78%
2022-11-09 14:19:26 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:26 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1532 bytes result sent to driver
2022-11-09 14:19:26 root: INFO: interpreting non compilable node: TableWrite
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.005ms self 0.005ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:26 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 14:19:26 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-09 14:19:26 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-09 14:19:26 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:26 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:26 root: INFO: timing SparkBackend.parse_value_ir total 57.352ms self 57.352ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-09 14:19:26 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 3:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr4.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead
      Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String]},entry:Struct{}}
      True False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr4.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-09 14:19:26 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compf004.hpc.in.bmrc.ox.ac.uk:39715 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 14:19:26 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 7.015ms self 7.015ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-09 14:19:26 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:26 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:26 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 2631 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:26 root: INFO: starting execution of query hail_query_1 of initial size 8
2022-11-09 14:19:26 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:26 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 16: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr4.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (TableMapGlobals
      (TableMapGlobals
        (TableMapRows
          (TableRead
            Table{global:Struct{__cols:Array[Struct{s:String}]},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{}]}}
            False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr4.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
          (InsertFields
            (Ref row)
            None
            (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
              (MakeArray Array[Struct{}]))))
        (InsertFields
          (Ref global)
          None
          (__cols (MakeArray Array[Struct{s:String}]))))
      (SelectFields () (Ref global)))
    (SelectFields (locus alleles) (Ref row))))
2022-11-09 14:19:26 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.095ms self 0.095ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-09 14:19:26 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:19:26 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-09 14:19:26 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:26 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 3.345 s
2022-11-09 14:19:26 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 14:19:26 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-09 14:19:26 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:26 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-09 14:19:26 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 4.245691 s
2022-11-09 14:19:26 root: INFO: timing SparkBackend.parse_matrix_ir total 2.766s self 2.766s children 0.000ms %children 0.00%
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 147.944ms self 0.027ms children 147.917ms %children 99.98%
2022-11-09 14:19:26 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:26 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 2:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr4.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableRead
    Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String]}}
    False
    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr4.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.020ms self 0.020ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 8: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr18.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (MatrixRowsTable
      (MatrixRead None False False
        "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr18.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
    (InsertFields
      (SelectFields (locus alleles)
        (SelectFields 
          (locus alleles rsid qual filters info)
          (Ref row)))
      None)))
2022-11-09 14:19:26 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-09 14:19:26 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-09 14:19:26 root: INFO: interpreting non compilable node: TableWrite
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 147.878ms self 92.855ms children 55.024ms %children 37.21%
2022-11-09 14:19:26 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-09 14:19:26 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-09 14:19:26 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:19:26 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-09 14:19:26 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 3:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr18.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead
      Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String]},entry:Struct{}}
      True False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr18.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-09 14:19:26 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-09 14:19:26 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compe094.hpc.in.bmrc.ox.ac.uk:33393 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 14:19:26 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 55.024ms self 0.110ms children 54.914ms %children 99.80%
2022-11-09 14:19:27 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:26 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-09 14:19:27 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 6.530ms self 6.530ms children 0.000ms %children 0.00%
2022-11-09 14:19:26 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compa037.hpc.in.bmrc.ox.ac.uk:40682 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:19:27 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compa043.hpc.in.bmrc.ox.ac.uk:41694 (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:27 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 16: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr18.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (TableMapGlobals
      (TableMapGlobals
        (TableMapRows
          (TableRead
            Table{global:Struct{__cols:Array[Struct{s:String}]},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{}]}}
            False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr18.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
          (InsertFields
            (Ref row)
            None
            (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
              (MakeArray Array[Struct{}]))))
        (InsertFields
          (Ref global)
          None
          (__cols (MakeArray Array[Struct{s:String}]))))
      (SelectFields () (Ref global)))
    (SelectFields (locus alleles) (Ref row))))
2022-11-09 14:19:27 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-09 14:19:27 root: INFO: timing SparkBackend.parse_value_ir total 63.154ms self 63.154ms children 0.000ms %children 0.00%
2022-11-09 14:19:27 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-09 14:19:27 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compe078.hpc.in.bmrc.ox.ac.uk:41045 (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:27 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:27 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:27 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 14:19:27 Hail: INFO: Coerced sorted dataset
2022-11-09 14:19:27 root: INFO: timing SparkBackend.parse_matrix_ir total 2.210s self 2.210s children 0.000ms %children 0.00%
2022-11-09 14:19:27 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-09 14:19:27 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-09 14:19:27 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-09 14:19:27 root: INFO: starting execution of query hail_query_1 of initial size 8
2022-11-09 14:19:27 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:27 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.sites_only.chr14.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr14.vcf.bgz
2022-11-09 14:19:27 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:19:27 root: INFO: RegionPool: REPORT_THRESHOLD: 32.0M allocated (31.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:27 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:27 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-09 14:19:27 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-09 14:19:27 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 14:19:27 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 2:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr18.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableRead
    Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String]}}
    False
    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr18.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
2022-11-09 14:19:27 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-09 14:19:27 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.215ms self 0.215ms children 0.000ms %children 0.00%
2022-11-09 14:19:27 root: INFO: timing SparkBackend.parse_value_ir total 85.186ms self 85.186ms children 0.000ms %children 0.00%
2022-11-09 14:19:27 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-09 14:19:27 root: INFO: RegionPool: REPORT_THRESHOLD: 64.0M allocated (63.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:27 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.sites_only.chr14.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr14.vcf.bgz
2022-11-09 14:19:27 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-09 14:19:27 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-09 14:19:27 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compa036.hpc.in.bmrc.ox.ac.uk:35064 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 14:19:27 root: INFO: interpreting non compilable node: TableWrite
2022-11-09 14:19:27 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:27 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 8: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr22.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (MatrixRowsTable
      (MatrixRead None False False
        "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr22.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
    (InsertFields
      (SelectFields (locus alleles)
        (SelectFields 
          (locus alleles rsid qual filters info)
          (Ref row)))
      None)))
2022-11-09 14:19:27 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-09 14:19:27 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-09 14:19:27 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:27 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-09 14:19:27 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-09 14:19:27 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-09 14:19:27 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:27 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:27 root: INFO: starting execution of query hail_query_1 of initial size 8
2022-11-09 14:19:27 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:19:27 root: INFO: instruction count: 3: __C1etypeEncode.<init>
2022-11-09 14:19:27 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compa023.hpc.in.bmrc.ox.ac.uk:38669 (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:27 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-09 14:19:27 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes)
2022-11-09 14:19:27 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-09 14:19:27 root: INFO: timing SparkBackend.parse_matrix_ir total 2.665s self 2.665s children 0.000ms %children 0.00%
2022-11-09 14:19:27 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-09 14:19:27 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-09 14:19:27 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 3:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr22.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead
      Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String]},entry:Struct{}}
      True False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr22.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-09 14:19:27 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-09 14:19:27 root: INFO: instruction count: 5: __C1etypeEncode.apply
2022-11-09 14:19:27 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8053 bytes)
2022-11-09 14:19:28 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-09 14:19:27 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 8: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chrX.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (MatrixRowsTable
      (MatrixRead None False False
        "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chrX.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
    (InsertFields
      (SelectFields (locus alleles)
        (SelectFields 
          (locus alleles rsid qual filters info)
          (Ref row)))
      None)))
2022-11-09 14:19:27 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 38.228ms self 38.228ms children 0.000ms %children 0.00%
2022-11-09 14:19:27 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-09 14:19:27 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-09 14:19:28 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-09 14:19:27 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-09 14:19:27 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:28 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:28 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-09 14:19:27 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 16: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr22.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (TableMapGlobals
      (TableMapGlobals
        (TableMapRows
          (TableRead
            Table{global:Struct{__cols:Array[Struct{s:String}]},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{}]}}
            False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr22.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
          (InsertFields
            (Ref row)
            None
            (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
              (MakeArray Array[Struct{}]))))
        (InsertFields
          (Ref global)
          None
          (__cols (MakeArray Array[Struct{s:String}]))))
      (SelectFields () (Ref global)))
    (SelectFields (locus alleles) (Ref row))))
2022-11-09 14:19:28 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 14:19:27 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:28 root: INFO: timing SparkBackend.parse_value_ir total 125.492ms self 125.492ms children 0.000ms %children 0.00%
2022-11-09 14:19:28 root: INFO: instruction count: 3: __C1etypeEncode.__m2ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:28 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-09 14:19:28 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-09 14:19:28 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:19:27 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:26 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compe065.hpc.in.bmrc.ox.ac.uk:39361 in memory (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:28 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-09 14:19:28 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-09 14:19:28 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-09 14:19:28 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 3:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chrX.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead
      Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String]},entry:Struct{}}
      True False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chrX.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-09 14:19:28 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-09 14:19:28 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:19:28 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:28 root: INFO: starting execution of query hail_query_1 of initial size 8
2022-11-09 14:19:28 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-09 14:19:28 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compe078.hpc.in.bmrc.ox.ac.uk:34810 (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:28 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-09 14:19:28 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:28 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:28 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-09 14:19:28 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 2:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr22.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableRead
    Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String]}}
    False
    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr22.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
2022-11-09 14:19:28 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:28 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:28 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 16: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chrX.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (TableMapGlobals
      (TableMapGlobals
        (TableMapRows
          (TableRead
            Table{global:Struct{__cols:Array[Struct{s:String}]},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{}]}}
            False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chrX.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
          (InsertFields
            (Ref row)
            None
            (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
              (MakeArray Array[Struct{}]))))
        (InsertFields
          (Ref global)
          None
          (__cols (MakeArray Array[Struct{s:String}]))))
      (SelectFields () (Ref global)))
    (SelectFields (locus alleles) (Ref row))))
2022-11-09 14:19:28 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-09 14:19:28 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 14:19:28 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compa042.hpc.in.bmrc.ox.ac.uk:35350 (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:28 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:28 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-09 14:19:28 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8053 bytes)
2022-11-09 14:19:28 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 1.125ms self 1.125ms children 0.000ms %children 0.00%
2022-11-09 14:19:28 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-09 14:19:28 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:28 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 8: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr13.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (MatrixRowsTable
      (MatrixRead None False False
        "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr13.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
    (InsertFields
      (SelectFields (locus alleles)
        (SelectFields 
          (locus alleles rsid qual filters info)
          (Ref row)))
      None)))
2022-11-09 14:19:29 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-09 14:19:28 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:28 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:28 root: INFO: instruction count: 3: __C3indexwriter.<init>
2022-11-09 14:19:28 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compa037.hpc.in.bmrc.ox.ac.uk:40682 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 14:19:29 root: INFO: instruction count: 234: __C3indexwriter.apply
2022-11-09 14:19:28 root: INFO: RegionPool: REPORT_THRESHOLD: 64.0M allocated (63.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:29 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:19:29 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:29 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-09 14:19:28 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-09 14:19:29 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-09 14:19:29 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.075ms self 0.075ms children 0.000ms %children 0.00%
2022-11-09 14:19:29 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-09 14:19:28 root: INFO: interpreting non compilable node: TableWrite
2022-11-09 14:19:28 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:29 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8053 bytes)
2022-11-09 14:19:29 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-09 14:19:29 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:28 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-09 14:19:29 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 3:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr13.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead
      Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String]},entry:Struct{}}
      True False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr13.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-09 14:19:29 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:29 root: INFO: instruction count: 445: __C3indexwriter.__m12writeInternalNode
2022-11-09 14:19:29 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe074.hpc.in.bmrc.ox.ac.uk:33207 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:19:29 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:19:29 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes)
2022-11-09 14:19:29 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 7.272ms self 7.272ms children 0.000ms %children 0.00%
2022-11-09 14:19:29 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:29 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-09 14:19:29 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-09 14:19:29 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-09 14:19:29 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.193ms self 0.193ms children 0.000ms %children 0.00%
2022-11-09 14:19:29 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 16: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr13.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (TableMapGlobals
      (TableMapGlobals
        (TableMapRows
          (TableRead
            Table{global:Struct{__cols:Array[Struct{s:String}]},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{}]}}
            False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr13.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
          (InsertFields
            (Ref row)
            None
            (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
              (MakeArray Array[Struct{}]))))
        (InsertFields
          (Ref global)
          None
          (__cols (MakeArray Array[Struct{s:String}]))))
      (SelectFields () (Ref global)))
    (SelectFields (locus alleles) (Ref row))))
2022-11-09 14:19:29 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-09 14:19:29 root: INFO: instruction count: 13: __C3indexwriter.__m13ENCODE_o_tuple_of_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:29 root: INFO: timing SparkBackend.parse_matrix_ir total 4.172s self 4.172s children 0.000ms %children 0.00%
2022-11-09 14:19:29 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:29 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-09 14:19:29 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-09 14:19:29 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:29 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 2:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chrX.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableRead
    Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String]}}
    False
    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chrX.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
2022-11-09 14:19:29 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-09 14:19:29 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1533 bytes result sent to driver
2022-11-09 14:19:26 root: INFO: instruction count: 3: __C1etypeEncode.<init>
2022-11-09 14:19:29 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:29 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.129ms self 0.129ms children 0.000ms %children 0.00%
2022-11-09 14:19:29 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-09 14:19:30 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compe070.hpc.in.bmrc.ox.ac.uk:46576 (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:30 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:29 root: INFO: instruction count: 49: __C3indexwriter.__m14ENCODE_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:29 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-09 14:19:29 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.sites_only.chr19.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr19.vcf.bgz
2022-11-09 14:19:29 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-09 14:19:30 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.sites_only.chr19.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr19.vcf.bgz
2022-11-09 14:19:30 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-09 14:19:30 root: INFO: interpreting non compilable node: TableWrite
2022-11-09 14:19:30 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-09 14:19:30 root: INFO: timing SparkBackend.parse_value_ir total 121.483ms self 121.483ms children 0.000ms %children 0.00%
2022-11-09 14:19:30 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-09 14:19:30 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:30 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 3597 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:29 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-09 14:19:30 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:30 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-09 14:19:30 root: INFO: instruction count: 45: __C3indexwriter.__m15ENCODE_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:29 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-09 14:19:30 root: INFO: instruction count: 4: __C3indexwriter.__m16ENCODE_r_int64_TO_r_int64
2022-11-09 14:19:30 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:19:29 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-09 14:19:30 root: INFO: starting execution of query hail_query_1 of initial size 8
2022-11-09 14:19:30 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:30 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:30 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 917 bytes result sent to driver
2022-11-09 14:19:30 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 4.166 s
2022-11-09 14:19:30 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:30 root: INFO: instruction count: 5: __C1etypeEncode.apply
2022-11-09 14:19:30 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compa040.hpc.in.bmrc.ox.ac.uk:37984 (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:30 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8053 bytes)
2022-11-09 14:19:30 root: INFO: instruction count: 19: __C3indexwriter.__m17ENCODE_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:30 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compa026.hpc.in.bmrc.ox.ac.uk:45825 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:19:30 root: INFO: instruction count: 23: __C3indexwriter.__m18ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:30 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:30 root: INFO: instruction count: 16: __C3indexwriter.__m19ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:30 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 7989 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:30 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-09 14:19:30 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:166) finished in 8.294 s
2022-11-09 14:19:30 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:166, took 8.450408 s
2022-11-09 14:19:30 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 5.263587 s
2022-11-09 14:19:30 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 917 bytes result sent to driver
2022-11-09 14:19:30 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:30 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-09 14:19:30 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:30 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.217ms self 0.217ms children 0.000ms %children 0.00%
2022-11-09 14:19:30 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-09 14:19:30 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 2:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr13.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableRead
    Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String]}}
    False
    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr13.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
2022-11-09 14:19:30 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 8: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr14.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (MatrixRowsTable
      (MatrixRead None False False
        "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr14.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
    (InsertFields
      (SelectFields (locus alleles)
        (SelectFields 
          (locus alleles rsid qual filters info)
          (Ref row)))
      None)))
2022-11-09 14:19:30 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:30 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-09 14:19:31 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compa030.hpc.in.bmrc.ox.ac.uk:36769 (size: 23.0 KB, free: 413.9 MB)
2022-11-09 14:19:30 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-09 14:19:30 root: INFO: instruction count: 4: __C3indexwriter.__m20ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:30 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-09 14:19:30 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 14:19:30 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-09 14:19:30 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 7340 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:31 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-09 14:19:31 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:166) finished in 8.125 s
2022-11-09 14:19:31 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:166, took 8.387441 s
2022-11-09 14:19:30 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:30 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:30 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:31 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:30 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-09 14:19:30 root: INFO: instruction count: 3: __C1etypeEncode.__m2ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:30 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.269ms self 0.269ms children 0.000ms %children 0.00%
2022-11-09 14:19:30 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-09 14:19:30 Hail: INFO: wrote table with 1764971 rows in 1 partition to data/ht/ukb_wes_450k.qced.chr1.ht
    Total size: 21.61 MiB
    * Rows: 21.61 MiB
    * Globals: 11.00 B
    * Smallest partition: 1764971 rows (21.61 MiB)
    * Largest partition:  1764971 rows (21.61 MiB)
2022-11-09 14:19:31 root: INFO: took 16.862s
2022-11-09 14:19:31 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 1: 
(Begin)
2022-11-09 14:19:31 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Begin)
2022-11-09 14:19:31 root: INFO: finished execution of query hail_query_1
2022-11-09 14:19:30 root: INFO: interpreting non compilable node: TableWrite
2022-11-09 14:19:31 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.sites_only.chr15.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr15.vcf.bgz
2022-11-09 14:19:31 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:31 root: INFO: instruction count: 53: __C3indexwriter.__m21ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:30 Hail: INFO: Coerced sorted dataset
2022-11-09 14:19:31 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-09 14:19:31 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 3:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr14.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead
      Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String]},entry:Struct{}}
      True False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr14.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-09 14:19:31 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-09 14:19:31 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:31 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-09 14:19:31 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 14:19:31 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compe074.hpc.in.bmrc.ox.ac.uk:33207 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON total 17.253s self 102.967ms children 17.150s %children 99.40%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 231.044ms self 0.789ms children 230.255ms %children 99.66%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.373ms self 0.373ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 229.837ms self 155.083ms children 74.753ms %children 32.52%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 74.753ms self 1.377ms children 73.376ms %children 98.16%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 3.598ms self 3.598ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 5.715ms self 5.715ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 14.892ms self 14.892ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 12.387ms self 12.387ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 1.569ms self 1.569ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 33.212ms self 33.212ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.180ms self 0.180ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.091ms self 0.091ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.155ms self 0.155ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.299ms self 0.299ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.023ms self 0.023ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.450ms self 0.450ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.095ms self 0.095ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.013ms self 0.013ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.052ms self 0.052ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.243ms self 0.243ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.019ms self 0.019ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.383ms self 0.383ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.046ms self 0.046ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 12.272ms self 0.018ms children 12.254ms %children 99.85%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.005ms self 0.005ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 12.121ms self 12.121ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.128ms self 0.128ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 40.242ms self 0.029ms children 40.213ms %children 99.93%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 40.170ms self 11.042ms children 29.129ms %children 72.51%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 29.129ms self 0.111ms children 29.018ms %children 99.62%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 8.866ms self 8.866ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.233ms self 0.233ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 9.048ms self 9.048ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 1.287ms self 1.287ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.072ms self 0.072ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 7.855ms self 7.855ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.214ms self 0.214ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.140ms self 0.140ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.248ms self 0.248ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.301ms self 0.301ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.020ms self 0.020ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.223ms self 0.223ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.070ms self 0.070ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.020ms self 0.020ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.032ms self 0.032ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.205ms self 0.205ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.017ms self 0.017ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.166ms self 0.166ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 16.865s self 0.021ms children 16.865s %children 100.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.010ms self 0.010ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 16.865s self 16.865s children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.395ms self 0.395ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 1.511ms self 0.011ms children 1.500ms %children 99.25%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.005ms self 0.005ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 1.488ms self 0.659ms children 0.829ms %children 55.72%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 0.829ms self 0.047ms children 0.781ms %children 94.27%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.112ms self 0.112ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.304ms self 0.304ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.063ms self 0.063ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:31 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.sites_only.chr16.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr16.vcf.bgz
2022-11-09 14:19:31 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.sites_only.chr16.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr16.vcf.bgz
2022-11-09 14:19:31 root: INFO: instruction count: 3: __C3indexwriter.__m22ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:31 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-09 14:19:31 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:31 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-09 14:19:31 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 16: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr14.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (TableMapGlobals
      (TableMapGlobals
        (TableMapRows
          (TableRead
            Table{global:Struct{__cols:Array[Struct{s:String}]},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{}]}}
            False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr14.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
          (InsertFields
            (Ref row)
            None
            (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
              (MakeArray Array[Struct{}]))))
        (InsertFields
          (Ref global)
          None
          (__cols (MakeArray Array[Struct{s:String}]))))
      (SelectFields () (Ref global)))
    (SelectFields (locus alleles) (Ref row))))
2022-11-09 14:19:31 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-09 14:19:28 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-09 14:19:31 Hail: INFO: wrote table with 1260208 rows in 1 partition to data/ht/ukb_wes_450k.qced.chr2.ht
    Total size: 15.43 MiB
    * Rows: 15.43 MiB
    * Globals: 11.00 B
    * Smallest partition: 1260208 rows (15.43 MiB)
    * Largest partition:  1260208 rows (15.43 MiB)
2022-11-09 14:19:31 root: INFO: took 16.254s
2022-11-09 14:19:31 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 1: 
(Begin)
2022-11-09 14:19:31 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Begin)
2022-11-09 14:19:31 root: INFO: finished execution of query hail_query_1
2022-11-09 14:19:31 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.sites_only.chr15.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr15.vcf.bgz
2022-11-09 14:19:31 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.186ms self 0.186ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.020ms self 0.020ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.097ms self 0.097ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.007ms self 0.007ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.017ms self 0.017ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: instruction count: 379: __C3indexwriter.__m23writeLeafNode
2022-11-09 14:19:31 root: INFO: timing SparkBackend.parse_matrix_ir total 3.992s self 3.992s children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: instruction count: 23: __C3indexwriter.__m24ENCODE_o_tuple_of_r_int64ANDr_array_of_r_tuple_of_r_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_int64ANDr_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:31 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:31 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compf004.hpc.in.bmrc.ox.ac.uk:39715 (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:31 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-09 14:19:31 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-09 14:19:31 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.019ms self 0.019ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON total 16.726s self 139.699ms children 16.586s %children 99.16%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 205.945ms self 0.735ms children 205.210ms %children 99.64%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.392ms self 0.392ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 204.779ms self 133.045ms children 71.734ms %children 35.03%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 71.734ms self 1.539ms children 70.196ms %children 97.86%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 4.230ms self 4.230ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 4.921ms self 4.921ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes)
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 16.029ms self 16.029ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 10.868ms self 10.868ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 1.567ms self 1.567ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 18.547ms self 18.547ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.177ms self 0.177ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.091ms self 0.091ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.154ms self 0.154ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 12.218ms self 12.218ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.031ms self 0.031ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.517ms self 0.517ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.106ms self 0.106ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.014ms self 0.014ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.058ms self 0.058ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.276ms self 0.276ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.020ms self 0.020ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.372ms self 0.372ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.039ms self 0.039ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 9.575ms self 0.020ms children 9.555ms %children 99.79%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.005ms self 0.005ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 9.424ms self 9.424ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.126ms self 0.126ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 112.255ms self 0.030ms children 112.225ms %children 99.97%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.022ms self 0.022ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 112.184ms self 68.634ms children 43.550ms %children 38.82%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 43.550ms self 0.150ms children 43.400ms %children 99.66%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 8.020ms self 8.020ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.228ms self 0.228ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 11.294ms self 11.294ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 1.262ms self 1.262ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.064ms self 0.064ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 20.851ms self 20.851ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.224ms self 0.224ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.149ms self 0.149ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.225ms self 0.225ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.307ms self 0.307ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.022ms self 0.022ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.241ms self 0.241ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.083ms self 0.083ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.023ms self 0.023ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.036ms self 0.036ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: instruction count: 3: __C1etypeEncode.<init>
2022-11-09 14:19:31 ContextCleaner: INFO: Cleaned accumulator 29
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 36
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 45
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 48
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 46
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 28
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 39
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 30
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 31
2022-11-09 14:19:31 root: INFO: instruction count: 49: __C3indexwriter.__m25ENCODE_r_array_of_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:31 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:31 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:31 root: INFO: timing SparkBackend.parse_value_ir total 74.790ms self 74.790ms children 0.000ms %children 0.00%
2022-11-09 14:19:31 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 2:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr14.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableRead
    Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String]}}
    False
    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr14.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
2022-11-09 14:19:32 root: INFO: interpreting non compilable node: TableWrite
2022-11-09 14:19:31 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-09 14:19:31 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-09 14:19:26 root: INFO: instruction count: 3: __C3indexwriter.<init>
2022-11-09 14:19:31 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:31 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-09 14:19:32 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.194ms self 0.194ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.016ms self 0.016ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.160ms self 0.160ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.020ms self 0.020ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 16.257s self 0.020ms children 16.257s %children 100.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.009ms self 0.009ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 16.256s self 16.256s children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.436ms self 0.436ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 1.630ms self 0.012ms children 1.618ms %children 99.25%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.006ms self 0.006ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 1.604ms self 0.699ms children 0.905ms %children 56.41%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 0.905ms self 0.063ms children 0.842ms %children 93.06%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.131ms self 0.131ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.321ms self 0.321ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.066ms self 0.066ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.193ms self 0.193ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.034ms self 0.034ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.097ms self 0.097ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.007ms self 0.007ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.016ms self 0.016ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: instruction count: 5: __C1etypeEncode.apply
2022-11-09 14:19:32 root: INFO: instruction count: 25: __C3indexwriter.__m26ENCODE_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:32 root: INFO: instruction count: 3: __C1etypeEncode.__m2ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:32 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:32 root: INFO: starting execution of query hail_query_1 of initial size 8
2022-11-09 14:19:32 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 14:19:32 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-09 14:19:31 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.186ms self 0.186ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: instruction count: 234: __C3indexwriter.apply
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.062ms self 0.062ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-09 14:19:31 root: INFO: instruction count: 3: __C3indexwriter.<init>
2022-11-09 14:19:32 root: INFO: instruction count: 445: __C3indexwriter.__m12writeInternalNode
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.023ms self 0.023ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: instruction count: 13: __C3indexwriter.__m13ENCODE_o_tuple_of_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.031ms self 0.031ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.171ms self 0.171ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.015ms self 0.015ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: instruction count: 234: __C3indexwriter.apply
2022-11-09 14:19:32 root: INFO: instruction count: 49: __C3indexwriter.__m14ENCODE_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.153ms self 0.153ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.019ms self 0.019ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 11.865s self 0.023ms children 11.865s %children 100.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.008ms self 0.008ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 11.865s self 11.865s children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: instruction count: 45: __C3indexwriter.__m15ENCODE_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.363ms self 0.363ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: instruction count: 4: __C3indexwriter.__m16ENCODE_r_int64_TO_r_int64
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 194.317ms self 0.018ms children 194.298ms %children 99.99%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.005ms self 0.005ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: instruction count: 19: __C3indexwriter.__m17ENCODE_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 194.282ms self 193.406ms children 0.876ms %children 0.45%
2022-11-09 14:19:32 root: INFO: instruction count: 445: __C3indexwriter.__m12writeInternalNode
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 0.876ms self 0.051ms children 0.825ms %children 94.19%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.111ms self 0.111ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.413ms self 0.413ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.056ms self 0.056ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: instruction count: 13: __C3indexwriter.__m13ENCODE_o_tuple_of_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.150ms self 0.150ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: instruction count: 23: __C3indexwriter.__m18ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.018ms self 0.018ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.078ms self 0.078ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.011ms self 0.011ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.019ms self 0.019ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: instruction count: 16: __C3indexwriter.__m19ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:32 root: INFO: instruction count: 49: __C3indexwriter.__m14ENCODE_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:32 root: INFO: instruction count: 4: __C3indexwriter.__m20ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:32 root: INFO: instruction count: 45: __C3indexwriter.__m15ENCODE_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:32 root: INFO: instruction count: 4: __C3indexwriter.__m16ENCODE_r_int64_TO_r_int64
2022-11-09 14:19:32 root: INFO: instruction count: 53: __C3indexwriter.__m21ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:32 root: INFO: instruction count: 3: __C3indexwriter.__m22ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:32 root: INFO: instruction count: 379: __C3indexwriter.__m23writeLeafNode
2022-11-09 14:19:32 root: INFO: instruction count: 23: __C3indexwriter.__m24ENCODE_o_tuple_of_r_int64ANDr_array_of_r_tuple_of_r_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_int64ANDr_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:32 root: INFO: instruction count: 49: __C3indexwriter.__m25ENCODE_r_array_of_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:32 root: INFO: instruction count: 25: __C3indexwriter.__m26ENCODE_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:32 root: INFO: instruction count: 52: __C3indexwriter.__m27flush
2022-11-09 14:19:32 root: INFO: instruction count: 150: __C3indexwriter.init
2022-11-09 14:19:32 root: INFO: instruction count: 4: __C3indexwriter.setObjects
2022-11-09 14:19:32 root: INFO: instruction count: 28: __C3indexwriter.close
2022-11-09 14:19:32 root: INFO: instruction count: 7: __C3indexwriter.trackedOS
2022-11-09 14:19:32 root: INFO: instruction count: 9: __C3indexwriter.setPartitionIndex
2022-11-09 14:19:32 root: INFO: instruction count: 4: __C3indexwriter.addPartitionRegion
2022-11-09 14:19:32 root: INFO: instruction count: 3: __C29FSContainer.<init>
2022-11-09 14:19:32 root: INFO: instruction count: 19: __C3indexwriter.__m17ENCODE_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:32 root: INFO: instruction count: 23: __C3indexwriter.__m18ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:32 root: INFO: instruction count: 16: __C3indexwriter.__m19ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:32 root: INFO: instruction count: 4: __C3indexwriter.__m20ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:32 root: INFO: instruction count: 53: __C3indexwriter.__m21ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:32 root: INFO: instruction count: 3: __C3indexwriter.__m22ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:32 root: INFO: instruction count: 379: __C3indexwriter.__m23writeLeafNode
2022-11-09 14:19:32 root: INFO: instruction count: 23: __C3indexwriter.__m24ENCODE_o_tuple_of_r_int64ANDr_array_of_r_tuple_of_r_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_int64ANDr_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:32 root: INFO: instruction count: 28: __C29FSContainer.init_filesystem
2022-11-09 14:19:32 root: INFO: instruction count: 3: __C29FSContainer.<clinit>
2022-11-09 14:19:32 root: INFO: instruction count: 49: __C3indexwriter.__m25ENCODE_r_array_of_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:32 root: INFO: instruction count: 25: __C3indexwriter.__m26ENCODE_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:32 root: INFO: instruction count: 52: __C3indexwriter.__m27flush
2022-11-09 14:19:32 root: INFO: instruction count: 150: __C3indexwriter.init
2022-11-09 14:19:32 root: INFO: instruction count: 4: __C3indexwriter.setObjects
2022-11-09 14:19:32 root: INFO: instruction count: 28: __C3indexwriter.close
2022-11-09 14:19:32 root: INFO: instruction count: 7: __C3indexwriter.trackedOS
2022-11-09 14:19:32 root: INFO: instruction count: 9: __C3indexwriter.setPartitionIndex
2022-11-09 14:19:32 root: INFO: instruction count: 4: __C3indexwriter.addPartitionRegion
2022-11-09 14:19:32 root: INFO: instruction count: 3: __C29FSContainer.<init>
2022-11-09 14:19:32 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-09 14:19:32 root: INFO: instruction count: 28: __C29FSContainer.init_filesystem
2022-11-09 14:19:32 root: INFO: instruction count: 3: __C29FSContainer.<clinit>
2022-11-09 14:19:32 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-09 14:19:32 root: INFO: instruction count: 3: __C32etypeEncode.<init>
2022-11-09 14:19:32 root: INFO: instruction count: 5: __C32etypeEncode.apply
2022-11-09 14:19:32 root: INFO: instruction count: 19: __C32etypeEncode.__m33ENCODE_r_tuple_of_r_locusANDr_array_of_r_stringEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:32 root: INFO: instruction count: 23: __C32etypeEncode.__m34ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:32 root: INFO: instruction count: 16: __C32etypeEncode.__m35ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:32 root: INFO: instruction count: 4: __C32etypeEncode.__m36ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:32 root: INFO: instruction count: 53: __C32etypeEncode.__m37ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:32 root: INFO: instruction count: 3: __C32etypeEncode.<init>
2022-11-09 14:19:32 root: INFO: instruction count: 5: __C32etypeEncode.apply
2022-11-09 14:19:32 root: INFO: instruction count: 19: __C32etypeEncode.__m33ENCODE_r_tuple_of_r_locusANDr_array_of_r_stringEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:32 root: INFO: instruction count: 23: __C32etypeEncode.__m34ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:32 root: INFO: instruction count: 16: __C32etypeEncode.__m35ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:32 root: INFO: instruction count: 4: __C32etypeEncode.__m36ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:32 root: INFO: instruction count: 53: __C32etypeEncode.__m37ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:31 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-09 14:19:32 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:19:32 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-09 14:19:32 root: INFO: instruction count: 52: __C3indexwriter.__m27flush
2022-11-09 14:19:32 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-09 14:19:32 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-09 14:19:32 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:32 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 8: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr19.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (MatrixRowsTable
      (MatrixRead None False False
        "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr19.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
    (InsertFields
      (SelectFields (locus alleles)
        (SelectFields 
          (locus alleles rsid qual filters info)
          (Ref row)))
      None)))
2022-11-09 14:19:32 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1505 bytes result sent to driver
2022-11-09 14:19:32 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 14:19:32 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:19:32 root: INFO: instruction count: 150: __C3indexwriter.init
2022-11-09 14:19:32 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:32 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compa026.hpc.in.bmrc.ox.ac.uk:45825 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 14:19:32 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:19:32 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8053 bytes)
2022-11-09 14:19:32 root: INFO: instruction count: 4: __C3indexwriter.setObjects
2022-11-09 14:19:32 AbstractConnector: INFO: Stopped Spark@20032fa7{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:19:32 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:32 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-09 14:19:32 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 4903 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:32 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-09 14:19:32 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-09 14:19:32 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 3:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr19.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead
      Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String]},entry:Struct{}}
      True False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr19.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-09 14:19:32 root: INFO: instruction count: 28: __C3indexwriter.close
2022-11-09 14:19:32 SparkUI: INFO: Stopped Spark web UI at http://compe061.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 14:19:32 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-09 14:19:32 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:32 root: INFO: instruction count: 3: __C3indexwriter.<init>
2022-11-09 14:19:32 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 5.763 s
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 46
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 41
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 37
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 26
2022-11-09 14:19:32 ContextCleaner: INFO: Cleaned accumulator 45
2022-11-09 14:19:32 AbstractConnector: INFO: Stopped Spark@2c6a01d8{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:19:32 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-09 14:19:32 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compa030.hpc.in.bmrc.ox.ac.uk:36769 (size: 123.7 KB, free: 413.8 MB)
2022-11-09 14:19:32 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-09 14:19:32 root: INFO: instruction count: 7: __C3indexwriter.trackedOS
2022-11-09 14:19:32 root: INFO: instruction count: 234: __C3indexwriter.apply
2022-11-09 14:19:32 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:32 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 14:19:32 MemoryStore: INFO: MemoryStore cleared
2022-11-09 14:19:32 BlockManager: INFO: BlockManager stopped
2022-11-09 14:19:32 BlockManagerMaster: INFO: BlockManagerMaster stopped
2022-11-09 14:19:32 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-09 14:19:32 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 16: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr19.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (TableMapGlobals
      (TableMapGlobals
        (TableMapRows
          (TableRead
            Table{global:Struct{__cols:Array[Struct{s:String}]},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{}]}}
            False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr19.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
          (InsertFields
            (Ref row)
            None
            (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
              (MakeArray Array[Struct{}]))))
        (InsertFields
          (Ref global)
          None
          (__cols (MakeArray Array[Struct{s:String}]))))
      (SelectFields () (Ref global)))
    (SelectFields (locus alleles) (Ref row))))
2022-11-09 14:19:32 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 6.032035 s
2022-11-09 14:19:32 root: INFO: timing SparkBackend.parse_matrix_ir total 4.632s self 4.632s children 0.000ms %children 0.00%
2022-11-09 14:19:32 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-09 14:19:32 BlockManagerInfo: INFO: Removed broadcast_3_piece0 on compe065.hpc.in.bmrc.ox.ac.uk:37201 in memory (size: 114.5 KB, free: 413.8 MB)
2022-11-09 14:19:32 SparkContext: INFO: Starting job: collect at ContextRDD.scala:166
2022-11-09 14:19:32 SparkContext: INFO: Starting job: collect at ContextRDD.scala:166
2022-11-09 14:19:32 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-09 14:19:32 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-09 14:19:32 root: INFO: instruction count: 9: __C3indexwriter.setPartitionIndex
2022-11-09 14:19:32 root: INFO: instruction count: 445: __C3indexwriter.__m12writeInternalNode
2022-11-09 14:19:32 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:32 OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: INFO: OutputCommitCoordinator stopped!
2022-11-09 14:19:32 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-09 14:19:32 root: INFO: timing SparkBackend.parse_matrix_ir total 4.208s self 4.208s children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-09 14:19:32 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-09 14:19:32 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:166) with 1 output partitions
2022-11-09 14:19:32 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-09 14:19:32 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compe094.hpc.in.bmrc.ox.ac.uk:33393 (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:32 root: INFO: instruction count: 4: __C3indexwriter.addPartitionRegion
2022-11-09 14:19:32 root: INFO: instruction count: 13: __C3indexwriter.__m13ENCODE_o_tuple_of_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:32 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:32 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1528 bytes result sent to driver
2022-11-09 14:19:32 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:32 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 2:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr19.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableRead
    Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String]}}
    False
    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr19.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
2022-11-09 14:19:32 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:166) with 1 output partitions
2022-11-09 14:19:32 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:166)
2022-11-09 14:19:32 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compa036.hpc.in.bmrc.ox.ac.uk:35064 (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:32 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:32 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:32 root: INFO: instruction count: 3: __C29FSContainer.<init>
2022-11-09 14:19:32 root: INFO: instruction count: 49: __C3indexwriter.__m14ENCODE_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:32 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:32 root: INFO: timing SparkBackend.parse_value_ir total 87.547ms self 87.547ms children 0.000ms %children 0.00%
2022-11-09 14:19:32 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:32 root: INFO: interpreting non compilable node: TableWrite
2022-11-09 14:19:32 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:166)
2022-11-09 14:19:33 Hail: INFO: Coerced sorted dataset
2022-11-09 14:19:33 root: INFO: instruction count: 28: __C29FSContainer.init_filesystem
2022-11-09 14:19:33 root: INFO: instruction count: 45: __C3indexwriter.__m15ENCODE_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:33 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:33 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:33 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-09 14:19:33 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:32 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:33 root: INFO: starting execution of query hail_query_1 of initial size 8
2022-11-09 14:19:33 root: INFO: instruction count: 3: __C29FSContainer.<clinit>
2022-11-09 14:19:33 root: INFO: instruction count: 4: __C3indexwriter.__m16ENCODE_r_int64_TO_r_int64
2022-11-09 14:19:33 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 5497 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:33 root: INFO: instruction count: 19: __C3indexwriter.__m17ENCODE_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:33 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-09 14:19:33 root: INFO: timing SparkBackend.parse_value_ir total 116.619ms self 116.619ms children 0.000ms %children 0.00%
2022-11-09 14:19:33 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:33 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:33 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-09 14:19:33 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-09 14:19:33 root: INFO: instruction count: 23: __C3indexwriter.__m18ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:33 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 6.277 s
2022-11-09 14:19:33 root: INFO: instruction count: 16: __C3indexwriter.__m19ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:33 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:33 root: INFO: instruction count: 3: __C32etypeEncode.<init>
2022-11-09 14:19:33 root: INFO: starting execution of query hail_query_1 of initial size 8
2022-11-09 14:19:33 root: INFO: instruction count: 4: __C3indexwriter.__m20ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:33 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-09 14:19:33 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-09 14:19:33 root: INFO: instruction count: 5: __C32etypeEncode.apply
2022-11-09 14:19:33 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-09 14:19:33 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 6.502235 s
2022-11-09 14:19:33 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-09 14:19:33 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8053 bytes)
2022-11-09 14:19:33 root: INFO: instruction count: 53: __C3indexwriter.__m21ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:33 root: INFO: instruction count: 19: __C32etypeEncode.__m33ENCODE_r_tuple_of_r_locusANDr_array_of_r_stringEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:33 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 312.3 KB, free 411.6 MB)
2022-11-09 14:19:33 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 312.3 KB, free 411.6 MB)
2022-11-09 14:19:33 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-09 14:19:33 root: INFO: instruction count: 3: __C3indexwriter.__m22ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:33 root: INFO: instruction count: 23: __C32etypeEncode.__m34ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:33 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes)
2022-11-09 14:19:33 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-09 14:19:33 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-09 14:19:33 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compa037.hpc.in.bmrc.ox.ac.uk:40682 (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:33 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 8: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr15.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (MatrixRowsTable
      (MatrixRead None False False
        "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr15.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
    (InsertFields
      (SelectFields (locus alleles)
        (SelectFields 
          (locus alleles rsid qual filters info)
          (Ref row)))
      None)))
2022-11-09 14:19:33 root: INFO: instruction count: 379: __C3indexwriter.__m23writeLeafNode
2022-11-09 14:19:33 root: INFO: instruction count: 16: __C32etypeEncode.__m35ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:33 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 114.5 KB, free 411.5 MB)
2022-11-09 14:19:33 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:33 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-09 14:19:33 root: INFO: instruction count: 3: __C1etypeEncode.<init>
2022-11-09 14:19:33 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 8: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr16.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (MatrixRowsTable
      (MatrixRead None False False
        "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr16.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
    (InsertFields
      (SelectFields (locus alleles)
        (SelectFields 
          (locus alleles rsid qual filters info)
          (Ref row)))
      None)))
2022-11-09 14:19:33 root: INFO: instruction count: 23: __C3indexwriter.__m24ENCODE_o_tuple_of_r_int64ANDr_array_of_r_tuple_of_r_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_int64ANDr_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:33 root: INFO: instruction count: 4: __C32etypeEncode.__m36ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:33 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 114.5 KB, free 411.5 MB)
2022-11-09 14:19:33 root: INFO: instruction count: 5: __C1etypeEncode.apply
2022-11-09 14:19:33 root: INFO: instruction count: 3: __C1etypeEncode.__m2ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:33 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:33 root: INFO: instruction count: 49: __C3indexwriter.__m25ENCODE_r_array_of_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:33 root: INFO: instruction count: 53: __C32etypeEncode.__m37ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:33 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compe065.hpc.in.bmrc.ox.ac.uk:39361 (size: 114.5 KB, free: 413.7 MB)
2022-11-09 14:19:33 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-09 14:19:33 root: INFO: instruction count: 25: __C3indexwriter.__m26ENCODE_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:33 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compe065.hpc.in.bmrc.ox.ac.uk:35806 (size: 114.5 KB, free: 413.7 MB)
2022-11-09 14:19:33 root: INFO: instruction count: 52: __C3indexwriter.__m27flush
2022-11-09 14:19:33 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:33 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-09 14:19:33 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 3:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr15.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead
      Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String]},entry:Struct{}}
      True False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr15.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-09 14:19:33 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-09 14:19:33 root: INFO: instruction count: 150: __C3indexwriter.init
2022-11-09 14:19:33 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:33 Hail: INFO: Coerced sorted dataset
2022-11-09 14:19:33 root: INFO: instruction count: 4: __C3indexwriter.setObjects
2022-11-09 14:19:33 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:33 root: INFO: instruction count: 28: __C3indexwriter.close
2022-11-09 14:19:33 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:33 root: INFO: instruction count: 7: __C3indexwriter.trackedOS
2022-11-09 14:19:33 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-09 14:19:33 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 16: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr15.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (TableMapGlobals
      (TableMapGlobals
        (TableMapRows
          (TableRead
            Table{global:Struct{__cols:Array[Struct{s:String}]},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{}]}}
            False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr15.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
          (InsertFields
            (Ref row)
            None
            (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
              (MakeArray Array[Struct{}]))))
        (InsertFields
          (Ref global)
          None
          (__cols (MakeArray Array[Struct{s:String}]))))
      (SelectFields () (Ref global)))
    (SelectFields (locus alleles) (Ref row))))
2022-11-09 14:19:33 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-09 14:19:33 root: INFO: instruction count: 9: __C3indexwriter.setPartitionIndex
2022-11-09 14:19:33 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8053 bytes)
2022-11-09 14:19:33 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:33 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-09 14:19:33 root: INFO: instruction count: 4: __C3indexwriter.addPartitionRegion
2022-11-09 14:19:33 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 3:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr16.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead
      Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String]},entry:Struct{}}
      True False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr16.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-09 14:19:33 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-09 14:19:33 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-09 14:19:33 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-09 14:19:33 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:33 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8058 bytes)
2022-11-09 14:19:33 root: INFO: instruction count: 3: __C29FSContainer.<init>
2022-11-09 14:19:33 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:33 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-09 14:19:33 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-09 14:19:33 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:33 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 16: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr16.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (TableMapGlobals
      (TableMapGlobals
        (TableMapRows
          (TableRead
            Table{global:Struct{__cols:Array[Struct{s:String}]},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{}]}}
            False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr16.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
          (InsertFields
            (Ref row)
            None
            (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
              (MakeArray Array[Struct{}]))))
        (InsertFields
          (Ref global)
          None
          (__cols (MakeArray Array[Struct{s:String}]))))
      (SelectFields () (Ref global)))
    (SelectFields (locus alleles) (Ref row))))
2022-11-09 14:19:33 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-09 14:19:33 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-09 14:19:33 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:33 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8058 bytes)
2022-11-09 14:19:33 root: INFO: instruction count: 28: __C29FSContainer.init_filesystem
2022-11-09 14:19:33 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:33 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 2:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr15.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableRead
    Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String]}}
    False
    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr15.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
2022-11-09 14:19:33 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:33 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-09 14:19:33 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 2:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr16.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableRead
    Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String]}}
    False
    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr16.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
2022-11-09 14:19:33 root: INFO: interpreting non compilable node: TableWrite
2022-11-09 14:19:33 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-09 14:19:33 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-09 14:19:33 root: INFO: instruction count: 3: __C3indexwriter.<init>
2022-11-09 14:19:33 root: INFO: instruction count: 234: __C3indexwriter.apply
2022-11-09 14:19:33 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-09 14:19:33 root: INFO: instruction count: 3: __C29FSContainer.<clinit>
2022-11-09 14:19:33 root: INFO: interpreting non compilable node: TableWrite
2022-11-09 14:19:33 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-09 14:19:33 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:33 root: INFO: instruction count: 3: __C1etypeEncode.<init>
2022-11-09 14:19:33 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-09 14:19:33 root: INFO: instruction count: 445: __C3indexwriter.__m12writeInternalNode
2022-11-09 14:19:33 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-09 14:19:33 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-09 14:19:33 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1546 bytes result sent to driver
2022-11-09 14:19:33 root: INFO: instruction count: 5: __C1etypeEncode.apply
2022-11-09 14:19:33 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:33 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-09 14:19:33 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-09 14:19:33 root: INFO: instruction count: 13: __C3indexwriter.__m13ENCODE_o_tuple_of_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:34 root: INFO: instruction count: 49: __C3indexwriter.__m14ENCODE_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:34 root: INFO: instruction count: 45: __C3indexwriter.__m15ENCODE_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:34 root: INFO: instruction count: 4: __C3indexwriter.__m16ENCODE_r_int64_TO_r_int64
2022-11-09 14:19:34 root: INFO: instruction count: 19: __C3indexwriter.__m17ENCODE_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:34 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1459 bytes result sent to driver
2022-11-09 14:19:34 root: INFO: instruction count: 3: __C32etypeEncode.<init>
2022-11-09 14:19:34 root: INFO: instruction count: 3: __C1etypeEncode.__m2ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:34 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:34 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-09 14:19:34 root: INFO: instruction count: 23: __C3indexwriter.__m18ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:34 root: INFO: instruction count: 16: __C3indexwriter.__m19ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:34 root: INFO: instruction count: 4: __C3indexwriter.__m20ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:34 root: INFO: instruction count: 53: __C3indexwriter.__m21ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:34 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-09 14:19:34 root: INFO: instruction count: 5: __C32etypeEncode.apply
2022-11-09 14:19:34 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-09 14:19:34 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compe074.hpc.in.bmrc.ox.ac.uk:33207 (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:34 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:34 root: INFO: instruction count: 3: __C3indexwriter.__m22ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:34 root: INFO: instruction count: 379: __C3indexwriter.__m23writeLeafNode
2022-11-09 14:19:34 root: INFO: instruction count: 23: __C3indexwriter.__m24ENCODE_o_tuple_of_r_int64ANDr_array_of_r_tuple_of_r_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_int64ANDr_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:34 root: INFO: instruction count: 49: __C3indexwriter.__m25ENCODE_r_array_of_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:34 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 5291 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:34 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-09 14:19:34 root: INFO: instruction count: 19: __C32etypeEncode.__m33ENCODE_r_tuple_of_r_locusANDr_array_of_r_stringEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:34 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:34 root: INFO: instruction count: 25: __C3indexwriter.__m26ENCODE_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:34 root: INFO: instruction count: 52: __C3indexwriter.__m27flush
2022-11-09 14:19:34 root: INFO: instruction count: 150: __C3indexwriter.init
2022-11-09 14:19:34 root: INFO: instruction count: 4: __C3indexwriter.setObjects
2022-11-09 14:19:34 root: INFO: instruction count: 28: __C3indexwriter.close
2022-11-09 14:19:34 root: INFO: instruction count: 7: __C3indexwriter.trackedOS
2022-11-09 14:19:34 root: INFO: instruction count: 9: __C3indexwriter.setPartitionIndex
2022-11-09 14:19:34 root: INFO: instruction count: 4: __C3indexwriter.addPartitionRegion
2022-11-09 14:19:34 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 3607 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:34 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-09 14:19:34 root: INFO: instruction count: 23: __C32etypeEncode.__m34ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:34 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 7.130 s
2022-11-09 14:19:34 root: INFO: instruction count: 16: __C32etypeEncode.__m35ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:34 root: INFO: instruction count: 3: __C29FSContainer.<init>
2022-11-09 14:19:34 root: INFO: instruction count: 28: __C29FSContainer.init_filesystem
2022-11-09 14:19:34 root: INFO: instruction count: 3: __C29FSContainer.<clinit>
2022-11-09 14:19:34 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:34 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 4.679 s
2022-11-09 14:19:34 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-09 14:19:34 root: INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:34 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 7.394174 s
2022-11-09 14:19:34 root: INFO: instruction count: 4: __C32etypeEncode.__m36ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:34 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-09 14:19:34 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-09 14:19:34 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-09 14:19:34 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 6.056392 s
2022-11-09 14:19:34 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-09 14:19:34 root: INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:34 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-09 14:19:34 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-09 14:19:34 root: INFO: instruction count: 3: __C32etypeEncode.<init>
2022-11-09 14:19:34 root: INFO: instruction count: 5: __C32etypeEncode.apply
2022-11-09 14:19:34 root: INFO: instruction count: 19: __C32etypeEncode.__m33ENCODE_r_tuple_of_r_locusANDr_array_of_r_stringEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:34 root: INFO: instruction count: 23: __C32etypeEncode.__m34ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:34 root: INFO: instruction count: 16: __C32etypeEncode.__m35ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:34 root: INFO: instruction count: 4: __C32etypeEncode.__m36ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:34 root: INFO: instruction count: 53: __C32etypeEncode.__m37ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:34 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-09 14:19:34 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-09 14:19:34 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8053 bytes)
2022-11-09 14:19:34 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-09 14:19:34 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-09 14:19:34 root: INFO: instruction count: 53: __C32etypeEncode.__m37ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:34 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-09 14:19:34 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-09 14:19:34 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:34 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:34 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-09 14:19:34 root: INFO: instruction count: 3: __C3indexwriter.<init>
2022-11-09 14:19:34 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-09 14:19:34 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1549 bytes result sent to driver
2022-11-09 14:19:34 SparkContext: INFO: Starting job: collect at ContextRDD.scala:166
2022-11-09 14:19:34 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-09 14:19:34 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-09 14:19:34 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-09 14:19:33 SparkContext: INFO: Starting job: collect at ContextRDD.scala:166
2022-11-09 14:19:34 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-09 14:19:34 root: INFO: instruction count: 234: __C3indexwriter.apply
2022-11-09 14:19:34 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-09 14:19:34 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-09 14:19:34 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:166) with 1 output partitions
2022-11-09 14:19:34 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 5632 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:34 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-09 14:19:34 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1605 bytes result sent to driver
2022-11-09 14:19:34 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-09 14:19:34 SparkContext: INFO: Starting job: collect at ContextRDD.scala:166
2022-11-09 14:19:34 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:166) with 1 output partitions
2022-11-09 14:19:34 root: INFO: RegionPool: REPORT_THRESHOLD: 4.0M allocated (3.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:35 root: INFO: RegionPool: REPORT_THRESHOLD: 4.0M allocated (3.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:34 root: INFO: instruction count: 445: __C3indexwriter.__m12writeInternalNode
2022-11-09 14:19:34 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-09 14:19:34 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-09 14:19:34 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:166)
2022-11-09 14:19:35 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 7.004 s
2022-11-09 14:19:35 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-09 14:19:35 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:35 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 5671 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:35 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1549 bytes result sent to driver
2022-11-09 14:19:35 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-09 14:19:35 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:166) with 1 output partitions
2022-11-09 14:19:35 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:166)
2022-11-09 14:19:35 root: INFO: instruction count: 13: __C3indexwriter.__m13ENCODE_o_tuple_of_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:35 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:35 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-09 14:19:35 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compa030.hpc.in.bmrc.ox.ac.uk:36769 (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:35 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 7.793083 s
2022-11-09 14:19:35 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-09 14:19:35 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:35 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 7.043 s
2022-11-09 14:19:35 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-09 14:19:35 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:166)
2022-11-09 14:19:35 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:35 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:35 root: INFO: instruction count: 49: __C3indexwriter.__m14ENCODE_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:35 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:35 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:35 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:35 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-09 14:19:35 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:35 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-09 14:19:35 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-09 14:19:35 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-09 14:19:35 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:35 root: INFO: RegionPool: REPORT_THRESHOLD: 8.0M allocated (7.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:35 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:35 root: INFO: instruction count: 45: __C3indexwriter.__m15ENCODE_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:35 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-09 14:19:35 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:35 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:35 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 8.065593 s
2022-11-09 14:19:35 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 2833 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:35 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-09 14:19:35 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 4.921 s
2022-11-09 14:19:35 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-09 14:19:35 root: INFO: RegionPool: REPORT_THRESHOLD: 8.0M allocated (7.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:35 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-09 14:19:35 root: INFO: instruction count: 4: __C3indexwriter.__m16ENCODE_r_int64_TO_r_int64
2022-11-09 14:19:35 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 312.3 KB, free 411.6 MB)
2022-11-09 14:19:35 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-09 14:19:35 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-09 14:19:35 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-09 14:19:35 Hail: INFO: Coerced sorted dataset
2022-11-09 14:19:35 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1529 bytes result sent to driver
2022-11-09 14:19:35 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1562 bytes result sent to driver
2022-11-09 14:19:35 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-09 14:19:35 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-09 14:19:36 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-09 14:19:36 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 6.002357 s
2022-11-09 14:19:36 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 312.3 KB, free 411.6 MB)
2022-11-09 14:19:36 root: INFO: instruction count: 19: __C3indexwriter.__m17ENCODE_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:36 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 114.5 KB, free 411.5 MB)
2022-11-09 14:19:36 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-09 14:19:34 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compe077.hpc.in.bmrc.ox.ac.uk:41191 in memory (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:36 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 312.3 KB, free 411.6 MB)
2022-11-09 14:19:36 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 3095 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:36 Hail: INFO: Coerced sorted dataset
2022-11-09 14:19:36 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-09 14:19:36 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-09 14:19:36 root: INFO: RegionPool: REPORT_THRESHOLD: 16.0M allocated (15.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:36 root: INFO: RegionPool: REPORT_THRESHOLD: 16.0M allocated (15.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:36 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 4636 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:36 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 114.5 KB, free 411.5 MB)
2022-11-09 14:19:36 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 7.199 s
2022-11-09 14:19:36 root: INFO: instruction count: 23: __C3indexwriter.__m18ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:36 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 9.161579 s
2022-11-09 14:19:36 root: INFO: instruction count: 16: __C3indexwriter.__m19ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:36 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compe077.hpc.in.bmrc.ox.ac.uk:41191 (size: 114.5 KB, free: 413.7 MB)
2022-11-09 14:19:36 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1504 bytes result sent to driver
2022-11-09 14:19:36 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:36 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 3.969 s
2022-11-09 14:19:36 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-09 14:19:36 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-09 14:19:35 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-09 14:19:36 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compe039.hpc.in.bmrc.ox.ac.uk:44800 (size: 114.5 KB, free: 413.7 MB)
2022-11-09 14:19:36 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8053 bytes)
2022-11-09 14:19:36 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-09 14:19:36 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-09 14:19:36 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compa026.hpc.in.bmrc.ox.ac.uk:45825 (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:36 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-09 14:19:36 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 114.5 KB, free 411.5 MB)
2022-11-09 14:19:36 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compe078.hpc.in.bmrc.ox.ac.uk:41045 (size: 114.5 KB, free: 413.7 MB)
2022-11-09 14:19:36 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:36 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:36 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-09 14:19:36 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8058 bytes)
2022-11-09 14:19:36 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-09 14:19:36 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-09 14:19:36 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:36 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-09 14:19:37 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-09 14:19:36 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-09 14:19:36 Hail: INFO: Coerced sorted dataset
2022-11-09 14:19:36 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:36 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 3668 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:36 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-09 14:19:36 root: INFO: instruction count: 4: __C3indexwriter.__m20ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:36 Hail: INFO: Coerced sorted dataset
2022-11-09 14:19:36 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:36 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-09 14:19:37 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-09 14:19:36 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 5.674874 s
2022-11-09 14:19:37 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1547 bytes result sent to driver
2022-11-09 14:19:37 root: INFO: instruction count: 3: __C1etypeEncode.<init>
2022-11-09 14:19:37 root: INFO: instruction count: 5: __C1etypeEncode.apply
2022-11-09 14:19:37 root: INFO: instruction count: 3: __C1etypeEncode.__m2ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:37 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8057 bytes)
2022-11-09 14:19:37 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-09 14:19:37 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:37 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 4.543 s
2022-11-09 14:19:37 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-09 14:19:37 root: INFO: instruction count: 53: __C3indexwriter.__m21ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:37 root: INFO: RegionPool: REPORT_THRESHOLD: 32.0M allocated (31.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:37 root: INFO: instruction count: 3: __C1etypeEncode.<init>
2022-11-09 14:19:37 root: INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:37 root: INFO: instruction count: 5: __C1etypeEncode.apply
2022-11-09 14:19:37 root: INFO: instruction count: 3: __C1etypeEncode.__m2ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:37 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:37 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-09 14:19:37 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:37 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-09 14:19:37 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:37 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:37 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-09 14:19:37 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-09 14:19:36 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-09 14:19:37 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-09 14:19:37 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 5.635298 s
2022-11-09 14:19:37 root: INFO: instruction count: 3: __C3indexwriter.__m22ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:37 root: INFO: RegionPool: REPORT_THRESHOLD: 32.0M allocated (31.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:37 Hail: INFO: Coerced sorted dataset
2022-11-09 14:19:37 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-09 14:19:37 root: INFO: instruction count: 3: __C1etypeEncode.<init>
2022-11-09 14:19:37 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-09 14:19:37 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-09 14:19:37 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-09 14:19:37 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-09 14:19:37 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-09 14:19:37 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-09 14:19:37 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-09 14:19:37 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-09 14:19:37 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-09 14:19:37 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-09 14:19:37 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-09 14:19:37 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-09 14:19:37 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 4029 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:37 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-09 14:19:37 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-09 14:19:37 root: INFO: instruction count: 3: __C1etypeEncode.<init>
2022-11-09 14:19:37 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-09 14:19:37 root: INFO: instruction count: 379: __C3indexwriter.__m23writeLeafNode
2022-11-09 14:19:37 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-09 14:19:37 root: INFO: instruction count: 5: __C1etypeEncode.apply
2022-11-09 14:19:34 Hail: INFO: Coerced sorted dataset
2022-11-09 14:19:37 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8057 bytes)
2022-11-09 14:19:37 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 4.777 s
2022-11-09 14:19:37 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8053 bytes)
2022-11-09 14:19:37 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-09 14:19:37 root: INFO: instruction count: 5: __C1etypeEncode.apply
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-09 14:19:37 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-09 14:19:37 root: INFO: instruction count: 23: __C3indexwriter.__m24ENCODE_o_tuple_of_r_int64ANDr_array_of_r_tuple_of_r_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_int64ANDr_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:37 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-09 14:19:38 root: INFO: instruction count: 49: __C3indexwriter.__m25ENCODE_r_array_of_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:37 root: INFO: instruction count: 3: __C1etypeEncode.__m2ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:38 root: INFO: instruction count: 3: __C3indexwriter.<init>
2022-11-09 14:19:38 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-09 14:19:38 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 5.380918 s
2022-11-09 14:19:38 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-09 14:19:37 root: INFO: instruction count: 3: __C3indexwriter.<init>
2022-11-09 14:19:38 root: INFO: instruction count: 3: __C1etypeEncode.__m2ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-09 14:19:38 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-09 14:19:37 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-09 14:19:38 root: INFO: instruction count: 25: __C3indexwriter.__m26ENCODE_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:38 root: INFO: instruction count: 234: __C3indexwriter.apply
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-09 14:19:38 root: INFO: instruction count: 234: __C3indexwriter.apply
2022-11-09 14:19:38 root: INFO: instruction count: 445: __C3indexwriter.__m12writeInternalNode
2022-11-09 14:19:38 root: INFO: instruction count: 13: __C3indexwriter.__m13ENCODE_o_tuple_of_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:38 root: INFO: instruction count: 49: __C3indexwriter.__m14ENCODE_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:38 root: INFO: instruction count: 45: __C3indexwriter.__m15ENCODE_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:38 root: INFO: instruction count: 4: __C3indexwriter.__m16ENCODE_r_int64_TO_r_int64
2022-11-09 14:19:38 root: INFO: instruction count: 19: __C3indexwriter.__m17ENCODE_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:38 root: INFO: instruction count: 23: __C3indexwriter.__m18ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:38 root: INFO: instruction count: 16: __C3indexwriter.__m19ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:38 root: INFO: instruction count: 4: __C3indexwriter.__m20ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:38 root: INFO: instruction count: 53: __C3indexwriter.__m21ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-09 14:19:37 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-09 14:19:38 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-09 14:19:38 root: INFO: instruction count: 52: __C3indexwriter.__m27flush
2022-11-09 14:19:38 root: INFO: instruction count: 3: __C1etypeEncode.<init>
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-09 14:19:38 root: INFO: instruction count: 3: __C3indexwriter.__m22ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:38 root: INFO: instruction count: 379: __C3indexwriter.__m23writeLeafNode
2022-11-09 14:19:38 root: INFO: instruction count: 23: __C3indexwriter.__m24ENCODE_o_tuple_of_r_int64ANDr_array_of_r_tuple_of_r_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_int64ANDr_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:38 root: INFO: instruction count: 49: __C3indexwriter.__m25ENCODE_r_array_of_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-09 14:19:38 root: INFO: instruction count: 3: __C1etypeEncode.<init>
2022-11-09 14:19:38 Hail: INFO: Coerced sorted dataset
2022-11-09 14:19:38 root: INFO: instruction count: 5: __C1etypeEncode.apply
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-09 14:19:38 root: INFO: instruction count: 150: __C3indexwriter.init
2022-11-09 14:19:38 root: INFO: instruction count: 5: __C1etypeEncode.apply
2022-11-09 14:19:38 root: INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-09 14:19:38 root: INFO: instruction count: 3: __C3indexwriter.<init>
2022-11-09 14:19:38 root: INFO: instruction count: 25: __C3indexwriter.__m26ENCODE_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:38 root: INFO: instruction count: 52: __C3indexwriter.__m27flush
2022-11-09 14:19:38 root: INFO: instruction count: 150: __C3indexwriter.init
2022-11-09 14:19:38 root: INFO: instruction count: 4: __C3indexwriter.setObjects
2022-11-09 14:19:38 root: INFO: instruction count: 28: __C3indexwriter.close
2022-11-09 14:19:38 root: INFO: instruction count: 7: __C3indexwriter.trackedOS
2022-11-09 14:19:38 root: INFO: instruction count: 9: __C3indexwriter.setPartitionIndex
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-09 14:19:38 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-09 14:19:38 root: INFO: instruction count: 3: __C1etypeEncode.__m2ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-09 14:19:38 root: INFO: instruction count: 4: __C3indexwriter.setObjects
2022-11-09 14:19:38 root: INFO: instruction count: 3: __C1etypeEncode.__m2ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-09 14:19:38 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-09 14:19:38 root: INFO: instruction count: 234: __C3indexwriter.apply
2022-11-09 14:19:38 root: INFO: instruction count: 4: __C3indexwriter.addPartitionRegion
2022-11-09 14:19:38 root: INFO: instruction count: 3: __C29FSContainer.<init>
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-09 14:19:38 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-09 14:19:39 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-09 14:19:38 root: INFO: RegionPool: REPORT_THRESHOLD: 64.0M allocated (63.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:38 root: INFO: instruction count: 28: __C3indexwriter.close
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-09 14:19:38 root: INFO: instruction count: 445: __C3indexwriter.__m12writeInternalNode
2022-11-09 14:19:38 root: INFO: instruction count: 28: __C29FSContainer.init_filesystem
2022-11-09 14:19:39 root: INFO: instruction count: 3: __C29FSContainer.<clinit>
2022-11-09 14:19:39 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-09 14:19:39 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-09 14:19:39 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:39 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-09 14:19:38 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-09 14:19:39 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-09 14:19:39 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-09 14:19:39 root: INFO: instruction count: 7: __C3indexwriter.trackedOS
2022-11-09 14:19:39 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-09 14:19:39 root: INFO: instruction count: 13: __C3indexwriter.__m13ENCODE_o_tuple_of_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:39 root: INFO: RegionPool: REPORT_THRESHOLD: 64.0M allocated (63.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:39 root: INFO: instruction count: 49: __C3indexwriter.__m14ENCODE_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:39 root: INFO: instruction count: 3: __C1etypeEncode.<init>
2022-11-09 14:19:39 root: INFO: instruction count: 45: __C3indexwriter.__m15ENCODE_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:39 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-09 14:19:39 root: INFO: instruction count: 3: __C3indexwriter.<init>
2022-11-09 14:19:39 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-09 14:19:39 root: INFO: instruction count: 3: __C3indexwriter.<init>
2022-11-09 14:19:39 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-09 14:19:39 root: INFO: instruction count: 9: __C3indexwriter.setPartitionIndex
2022-11-09 14:19:39 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-09 14:19:39 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-09 14:19:39 root: INFO: instruction count: 3: __C32etypeEncode.<init>
2022-11-09 14:19:39 root: INFO: instruction count: 5: __C32etypeEncode.apply
2022-11-09 14:19:39 root: INFO: instruction count: 19: __C32etypeEncode.__m33ENCODE_r_tuple_of_r_locusANDr_array_of_r_stringEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:39 root: INFO: instruction count: 23: __C32etypeEncode.__m34ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:39 root: INFO: instruction count: 16: __C32etypeEncode.__m35ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:39 root: INFO: instruction count: 4: __C32etypeEncode.__m36ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:39 root: INFO: instruction count: 53: __C32etypeEncode.__m37ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:39 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-09 14:19:39 root: INFO: instruction count: 5: __C1etypeEncode.apply
2022-11-09 14:19:39 root: INFO: instruction count: 3: __C1etypeEncode.__m2ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:39 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-09 14:19:39 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-09 14:19:39 root: INFO: instruction count: 234: __C3indexwriter.apply
2022-11-09 14:19:39 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-09 14:19:39 root: INFO: instruction count: 234: __C3indexwriter.apply
2022-11-09 14:19:39 root: INFO: RegionPool: REPORT_THRESHOLD: 4.0M allocated (3.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:39 root: INFO: instruction count: 4: __C3indexwriter.addPartitionRegion
2022-11-09 14:19:39 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-09 14:19:38 root: INFO: instruction count: 445: __C3indexwriter.__m12writeInternalNode
2022-11-09 14:19:39 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-09 14:19:39 root: INFO: instruction count: 4: __C3indexwriter.__m16ENCODE_r_int64_TO_r_int64
2022-11-09 14:19:39 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1547 bytes result sent to driver
2022-11-09 14:19:34 Hail: INFO: Coerced sorted dataset
2022-11-09 14:19:37 root: INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:39 root: INFO: instruction count: 445: __C3indexwriter.__m12writeInternalNode
2022-11-09 14:19:39 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-09 14:19:39 root: INFO: instruction count: 445: __C3indexwriter.__m12writeInternalNode
2022-11-09 14:19:39 root: INFO: instruction count: 3: __C29FSContainer.<init>
2022-11-09 14:19:39 root: INFO: instruction count: 13: __C3indexwriter.__m13ENCODE_o_tuple_of_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:39 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-09 14:19:39 root: INFO: instruction count: 49: __C3indexwriter.__m14ENCODE_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:39 root: INFO: instruction count: 13: __C3indexwriter.__m13ENCODE_o_tuple_of_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:39 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-09 14:19:39 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-09 14:19:39 root: INFO: instruction count: 28: __C29FSContainer.init_filesystem
2022-11-09 14:19:39 root: INFO: instruction count: 13: __C3indexwriter.__m13ENCODE_o_tuple_of_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:39 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 5629 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:38 root: INFO: instruction count: 3: __C3indexwriter.<init>
2022-11-09 14:19:39 root: INFO: instruction count: 45: __C3indexwriter.__m15ENCODE_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:39 root: INFO: instruction count: 49: __C3indexwriter.__m14ENCODE_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:39 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-09 14:19:39 root: INFO: instruction count: 19: __C3indexwriter.__m17ENCODE_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:39 root: INFO: instruction count: 3: __C29FSContainer.<clinit>
2022-11-09 14:19:39 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-09 14:19:40 root: INFO: instruction count: 234: __C3indexwriter.apply
2022-11-09 14:19:39 root: INFO: instruction count: 49: __C3indexwriter.__m14ENCODE_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:40 root: INFO: instruction count: 45: __C3indexwriter.__m15ENCODE_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:40 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-09 14:19:40 root: INFO: instruction count: 4: __C3indexwriter.__m16ENCODE_r_int64_TO_r_int64
2022-11-09 14:19:40 root: INFO: instruction count: 23: __C3indexwriter.__m18ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:40 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-09 14:19:40 root: INFO: instruction count: 4: __C3indexwriter.__m16ENCODE_r_int64_TO_r_int64
2022-11-09 14:19:40 root: INFO: instruction count: 445: __C3indexwriter.__m12writeInternalNode
2022-11-09 14:19:40 root: INFO: instruction count: 45: __C3indexwriter.__m15ENCODE_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:40 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-09 14:19:40 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 6.127 s
2022-11-09 14:19:40 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-09 14:19:40 root: INFO: instruction count: 19: __C3indexwriter.__m17ENCODE_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:40 root: INFO: instruction count: 16: __C3indexwriter.__m19ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:40 root: INFO: instruction count: 19: __C3indexwriter.__m17ENCODE_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:40 root: INFO: instruction count: 3: __C32etypeEncode.<init>
2022-11-09 14:19:40 root: INFO: instruction count: 13: __C3indexwriter.__m13ENCODE_o_tuple_of_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:40 root: INFO: instruction count: 5: __C32etypeEncode.apply
2022-11-09 14:19:40 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-09 14:19:40 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-09 14:19:40 root: INFO: instruction count: 23: __C3indexwriter.__m18ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:40 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 6.661954 s
2022-11-09 14:19:40 root: INFO: instruction count: 4: __C3indexwriter.__m20ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:40 SparkContext: INFO: Starting job: collect at ContextRDD.scala:166
2022-11-09 14:19:40 root: INFO: instruction count: 23: __C3indexwriter.__m18ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:40 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-09 14:19:40 root: INFO: instruction count: 4: __C3indexwriter.__m16ENCODE_r_int64_TO_r_int64
2022-11-09 14:19:40 root: INFO: instruction count: 49: __C3indexwriter.__m14ENCODE_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:40 root: INFO: instruction count: 19: __C32etypeEncode.__m33ENCODE_r_tuple_of_r_locusANDr_array_of_r_stringEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:40 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-09 14:19:40 root: INFO: instruction count: 23: __C32etypeEncode.__m34ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:40 root: INFO: instruction count: 53: __C3indexwriter.__m21ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:40 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 917 bytes result sent to driver
2022-11-09 14:19:40 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-09 14:19:40 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:166) with 1 output partitions
2022-11-09 14:19:40 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:166)
2022-11-09 14:19:40 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:40 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:40 root: INFO: instruction count: 16: __C3indexwriter.__m19ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:40 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-09 14:19:40 root: INFO: instruction count: 45: __C3indexwriter.__m15ENCODE_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:40 root: INFO: instruction count: 16: __C3indexwriter.__m19ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:40 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-09 14:19:40 root: INFO: instruction count: 4: __C3indexwriter.__m20ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:40 root: INFO: instruction count: 3: __C3indexwriter.__m22ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:40 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 6742 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:40 root: INFO: instruction count: 3: __C1etypeEncode.<init>
2022-11-09 14:19:40 root: INFO: instruction count: 3: __C3indexwriter.<init>
2022-11-09 14:19:40 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-09 14:19:40 root: INFO: instruction count: 4: __C3indexwriter.__m20ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:40 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-09 14:19:40 root: INFO: instruction count: 4: __C3indexwriter.__m16ENCODE_r_int64_TO_r_int64
2022-11-09 14:19:40 root: INFO: instruction count: 16: __C32etypeEncode.__m35ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:40 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-09 14:19:40 root: INFO: instruction count: 4: __C32etypeEncode.__m36ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:40 root: INFO: instruction count: 379: __C3indexwriter.__m23writeLeafNode
2022-11-09 14:19:40 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-09 14:19:40 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 917 bytes result sent to driver
2022-11-09 14:19:40 root: INFO: instruction count: 5: __C1etypeEncode.apply
2022-11-09 14:19:40 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:166) finished in 7.119 s
2022-11-09 14:19:40 Hail: INFO: Coerced sorted dataset
2022-11-09 14:19:40 root: INFO: RegionPool: REPORT_THRESHOLD: 8.0M allocated (7.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:40 root: INFO: instruction count: 53: __C3indexwriter.__m21ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:40 root: INFO: instruction count: 3: __C3indexwriter.__m22ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:40 root: INFO: instruction count: 379: __C3indexwriter.__m23writeLeafNode
2022-11-09 14:19:40 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 312.3 KB, free 411.6 MB)
2022-11-09 14:19:40 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-09 14:19:40 root: INFO: instruction count: 19: __C3indexwriter.__m17ENCODE_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:40 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-09 14:19:40 root: INFO: instruction count: 23: __C3indexwriter.__m18ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:40 root: INFO: instruction count: 16: __C3indexwriter.__m19ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:40 root: INFO: instruction count: 4: __C3indexwriter.__m20ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:40 root: INFO: instruction count: 53: __C3indexwriter.__m21ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:40 root: INFO: instruction count: 3: __C3indexwriter.__m22ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:40 root: INFO: instruction count: 379: __C3indexwriter.__m23writeLeafNode
2022-11-09 14:19:40 root: INFO: instruction count: 23: __C3indexwriter.__m24ENCODE_o_tuple_of_r_int64ANDr_array_of_r_tuple_of_r_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_int64ANDr_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:40 root: INFO: instruction count: 49: __C3indexwriter.__m25ENCODE_r_array_of_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:40 root: INFO: instruction count: 25: __C3indexwriter.__m26ENCODE_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:40 root: INFO: instruction count: 52: __C3indexwriter.__m27flush
2022-11-09 14:19:40 root: INFO: instruction count: 19: __C3indexwriter.__m17ENCODE_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:40 root: INFO: instruction count: 53: __C3indexwriter.__m21ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:40 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-09 14:19:40 root: INFO: instruction count: 53: __C32etypeEncode.__m37ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:40 root: INFO: instruction count: 23: __C3indexwriter.__m24ENCODE_o_tuple_of_r_int64ANDr_array_of_r_tuple_of_r_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_int64ANDr_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:40 root: INFO: instruction count: 234: __C3indexwriter.apply
2022-11-09 14:19:40 root: INFO: instruction count: 445: __C3indexwriter.__m12writeInternalNode
2022-11-09 14:19:40 root: INFO: instruction count: 3: __C1etypeEncode.__m2ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:40 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 6940 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:40 root: INFO: instruction count: 23: __C3indexwriter.__m24ENCODE_o_tuple_of_r_int64ANDr_array_of_r_tuple_of_r_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_int64ANDr_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:40 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-09 14:19:40 root: INFO: instruction count: 49: __C3indexwriter.__m25ENCODE_r_array_of_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:40 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-09 14:19:40 root: INFO: instruction count: 25: __C3indexwriter.__m26ENCODE_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:38 root: INFO: RegionPool: REPORT_THRESHOLD: 4.0M allocated (3.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:40 root: INFO: instruction count: 150: __C3indexwriter.init
2022-11-09 14:19:40 root: INFO: instruction count: 4: __C3indexwriter.setObjects
2022-11-09 14:19:40 root: INFO: instruction count: 28: __C3indexwriter.close
2022-11-09 14:19:40 root: INFO: instruction count: 7: __C3indexwriter.trackedOS
2022-11-09 14:19:40 root: INFO: instruction count: 9: __C3indexwriter.setPartitionIndex
2022-11-09 14:19:40 root: INFO: instruction count: 4: __C3indexwriter.addPartitionRegion
2022-11-09 14:19:40 root: INFO: instruction count: 3: __C29FSContainer.<init>
2022-11-09 14:19:40 root: INFO: instruction count: 23: __C3indexwriter.__m18ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:40 root: INFO: instruction count: 3: __C3indexwriter.__m22ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:40 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-09 14:19:40 root: INFO: instruction count: 49: __C3indexwriter.__m25ENCODE_r_array_of_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:40 root: INFO: instruction count: 13: __C3indexwriter.__m13ENCODE_o_tuple_of_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:40 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-09 14:19:40 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 114.5 KB, free 411.5 MB)
2022-11-09 14:19:40 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-09 14:19:40 root: INFO: RegionPool: REPORT_THRESHOLD: 16.0M allocated (15.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:41 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compe039.hpc.in.bmrc.ox.ac.uk:44800 in memory (size: 7.4 KB, free: 413.7 MB)
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-09 14:19:40 root: INFO: RegionPool: REPORT_THRESHOLD: 4.0M allocated (3.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:40 root: INFO: instruction count: 52: __C3indexwriter.__m27flush
2022-11-09 14:19:40 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compe078.hpc.in.bmrc.ox.ac.uk:41045 in memory (size: 7.4 KB, free: 413.7 MB)
2022-11-09 14:19:41 root: INFO: instruction count: 16: __C3indexwriter.__m19ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:41 root: INFO: instruction count: 379: __C3indexwriter.__m23writeLeafNode
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-09 14:19:41 SparkContext: INFO: Starting job: collect at ContextRDD.scala:166
2022-11-09 14:19:41 root: INFO: instruction count: 3: __C1etypeEncode.<init>
2022-11-09 14:19:41 root: INFO: instruction count: 25: __C3indexwriter.__m26ENCODE_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:41 root: INFO: instruction count: 5: __C1etypeEncode.apply
2022-11-09 14:19:41 root: INFO: instruction count: 52: __C3indexwriter.__m27flush
2022-11-09 14:19:40 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:166) finished in 7.640 s
2022-11-09 14:19:41 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compa042.hpc.in.bmrc.ox.ac.uk:35350 (size: 114.5 KB, free: 413.7 MB)
2022-11-09 14:19:41 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:41 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:41 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-09 14:19:41 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8057 bytes)
2022-11-09 14:19:41 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-09 14:19:41 root: INFO: instruction count: 3: __C3indexwriter.<init>
2022-11-09 14:19:41 root: INFO: instruction count: 150: __C3indexwriter.init
2022-11-09 14:19:40 root: INFO: instruction count: 28: __C29FSContainer.init_filesystem
2022-11-09 14:19:41 root: INFO: instruction count: 4: __C3indexwriter.__m20ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:41 root: INFO: instruction count: 23: __C3indexwriter.__m24ENCODE_o_tuple_of_r_int64ANDr_array_of_r_tuple_of_r_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_int64ANDr_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-09 14:19:41 root: INFO: instruction count: 49: __C3indexwriter.__m25ENCODE_r_array_of_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-09 14:19:41 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1546 bytes result sent to driver
2022-11-09 14:19:41 root: INFO: instruction count: 3: __C1etypeEncode.__m2ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:41 root: INFO: instruction count: 150: __C3indexwriter.init
2022-11-09 14:19:41 root: INFO: instruction count: 4: __C3indexwriter.setObjects
2022-11-09 14:19:41 root: INFO: instruction count: 28: __C3indexwriter.close
2022-11-09 14:19:41 root: INFO: instruction count: 7: __C3indexwriter.trackedOS
2022-11-09 14:19:41 root: INFO: instruction count: 9: __C3indexwriter.setPartitionIndex
2022-11-09 14:19:41 root: INFO: instruction count: 4: __C3indexwriter.addPartitionRegion
2022-11-09 14:19:41 root: INFO: instruction count: 3: __C29FSContainer.<init>
2022-11-09 14:19:41 root: INFO: instruction count: 28: __C29FSContainer.init_filesystem
2022-11-09 14:19:41 root: INFO: instruction count: 3: __C29FSContainer.<clinit>
2022-11-09 14:19:41 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-09 14:19:41 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:166, took 8.468987 s
2022-11-09 14:19:41 root: INFO: instruction count: 234: __C3indexwriter.apply
2022-11-09 14:19:41 root: INFO: instruction count: 4: __C3indexwriter.setObjects
2022-11-09 14:19:41 root: INFO: instruction count: 3: __C29FSContainer.<clinit>
2022-11-09 14:19:41 root: INFO: instruction count: 53: __C3indexwriter.__m21ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:41 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:166) with 1 output partitions
2022-11-09 14:19:41 root: INFO: instruction count: 3: __C3indexwriter.__m22ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:41 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:166)
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-09 14:19:41 root: INFO: instruction count: 3: __C32etypeEncode.<init>
2022-11-09 14:19:41 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 5276 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:40 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:166, took 7.561502 s
2022-11-09 14:19:41 root: INFO: instruction count: 28: __C3indexwriter.close
2022-11-09 14:19:41 root: INFO: instruction count: 445: __C3indexwriter.__m12writeInternalNode
2022-11-09 14:19:41 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-09 14:19:41 root: INFO: instruction count: 13: __C3indexwriter.__m13ENCODE_o_tuple_of_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:41 root: INFO: instruction count: 25: __C3indexwriter.__m26ENCODE_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:41 root: INFO: instruction count: 379: __C3indexwriter.__m23writeLeafNode
2022-11-09 14:19:41 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:41 root: INFO: instruction count: 23: __C3indexwriter.__m24ENCODE_o_tuple_of_r_int64ANDr_array_of_r_tuple_of_r_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_int64ANDr_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:41 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:41 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 6.591 s
2022-11-09 14:19:41 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-09 14:19:41 root: INFO: instruction count: 49: __C3indexwriter.__m14ENCODE_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:41 root: INFO: instruction count: 3: __C32etypeEncode.<init>
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-09 14:19:41 root: INFO: instruction count: 49: __C3indexwriter.__m14ENCODE_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-09 14:19:41 root: INFO: instruction count: 45: __C3indexwriter.__m15ENCODE_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:41 root: INFO: instruction count: 52: __C3indexwriter.__m27flush
2022-11-09 14:19:41 root: INFO: instruction count: 49: __C3indexwriter.__m25ENCODE_r_array_of_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:41 root: INFO: instruction count: 7: __C3indexwriter.trackedOS
2022-11-09 14:19:41 Hail: INFO: wrote table with 1084132 rows in 1 partition to data/ht/ukb_wes_450k.qced.chr17.ht
    Total size: 13.25 MiB
    * Rows: 13.25 MiB
    * Globals: 11.00 B
    * Smallest partition: 1084132 rows (13.25 MiB)
    * Largest partition:  1084132 rows (13.25 MiB)
2022-11-09 14:19:41 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 7.258370 s
2022-11-09 14:19:41 root: INFO: instruction count: 45: __C3indexwriter.__m15ENCODE_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-09 14:19:41 root: INFO: instruction count: 5: __C32etypeEncode.apply
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-09 14:19:41 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-09 14:19:41 root: INFO: instruction count: 19: __C32etypeEncode.__m33ENCODE_r_tuple_of_r_locusANDr_array_of_r_stringEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:41 root: INFO: RegionPool: REPORT_THRESHOLD: 8.0M allocated (7.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:41 root: INFO: instruction count: 23: __C32etypeEncode.__m34ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:41 root: INFO: instruction count: 16: __C32etypeEncode.__m35ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:41 root: INFO: instruction count: 4: __C32etypeEncode.__m36ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:41 root: INFO: instruction count: 53: __C32etypeEncode.__m37ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:41 root: INFO: instruction count: 5: __C32etypeEncode.apply
2022-11-09 14:19:41 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 312.3 KB, free 411.6 MB)
2022-11-09 14:19:41 root: INFO: instruction count: 19: __C32etypeEncode.__m33ENCODE_r_tuple_of_r_locusANDr_array_of_r_stringEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:38 Hail: INFO: Coerced sorted dataset
2022-11-09 14:19:41 root: INFO: instruction count: 25: __C3indexwriter.__m26ENCODE_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:41 root: INFO: instruction count: 150: __C3indexwriter.init
2022-11-09 14:19:41 root: INFO: instruction count: 9: __C3indexwriter.setPartitionIndex
2022-11-09 14:19:41 root: INFO: took 21.745s
2022-11-09 14:19:41 Hail: INFO: wrote table with 1110793 rows in 1 partition to data/ht/ukb_wes_450k.qced.chr11.ht
    Total size: 13.56 MiB
    * Rows: 13.56 MiB
    * Globals: 11.00 B
    * Smallest partition: 1110793 rows (13.56 MiB)
    * Largest partition:  1110793 rows (13.56 MiB)
2022-11-09 14:19:41 root: INFO: instruction count: 4: __C3indexwriter.__m16ENCODE_r_int64_TO_r_int64
2022-11-09 14:19:41 root: INFO: took 21.489s
2022-11-09 14:19:41 root: INFO: instruction count: 19: __C3indexwriter.__m17ENCODE_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:41 root: INFO: instruction count: 4: __C3indexwriter.__m16ENCODE_r_int64_TO_r_int64
2022-11-09 14:19:41 root: INFO: instruction count: 23: __C3indexwriter.__m18ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:41 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 114.5 KB, free 411.5 MB)
2022-11-09 14:19:41 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compa036.hpc.in.bmrc.ox.ac.uk:35064 in memory (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:41 root: INFO: instruction count: 52: __C3indexwriter.__m27flush
2022-11-09 14:19:41 root: INFO: instruction count: 4: __C3indexwriter.setObjects
2022-11-09 14:19:41 root: INFO: RegionPool: REPORT_THRESHOLD: 8.0M allocated (7.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:41 root: INFO: instruction count: 4: __C3indexwriter.addPartitionRegion
2022-11-09 14:19:41 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-09 14:19:41 root: INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:41 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 1: 
(Begin)
2022-11-09 14:19:41 root: INFO: instruction count: 23: __C32etypeEncode.__m34ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:41 root: INFO: instruction count: 19: __C3indexwriter.__m17ENCODE_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:41 root: INFO: instruction count: 16: __C3indexwriter.__m19ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:41 root: INFO: instruction count: 23: __C3indexwriter.__m18ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:41 root: INFO: instruction count: 4: __C3indexwriter.__m20ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:41 root: INFO: instruction count: 150: __C3indexwriter.init
2022-11-09 14:19:41 root: INFO: instruction count: 28: __C3indexwriter.close
2022-11-09 14:19:41 root: INFO: instruction count: 3: __C29FSContainer.<init>
2022-11-09 14:19:41 root: INFO: instruction count: 7: __C3indexwriter.trackedOS
2022-11-09 14:19:41 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-09 14:19:41 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 1: 
(Begin)
2022-11-09 14:19:41 root: INFO: instruction count: 16: __C32etypeEncode.__m35ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:41 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compa043.hpc.in.bmrc.ox.ac.uk:41694 (size: 114.5 KB, free: 413.7 MB)
2022-11-09 14:19:41 root: INFO: instruction count: 4: __C32etypeEncode.__m36ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:41 root: INFO: instruction count: 16: __C3indexwriter.__m19ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:41 root: INFO: instruction count: 53: __C32etypeEncode.__m37ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:41 root: INFO: instruction count: 4: __C3indexwriter.__m20ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:41 Hail: INFO: Coerced sorted dataset
2022-11-09 14:19:41 root: INFO: instruction count: 28: __C29FSContainer.init_filesystem
2022-11-09 14:19:41 root: INFO: instruction count: 9: __C3indexwriter.setPartitionIndex
2022-11-09 14:19:41 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Begin)
2022-11-09 14:19:41 root: INFO: instruction count: 3: __C3indexwriter.<init>
2022-11-09 14:19:41 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:41 root: INFO: instruction count: 53: __C3indexwriter.__m21ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:41 root: INFO: instruction count: 4: __C3indexwriter.setObjects
2022-11-09 14:19:41 root: INFO: instruction count: 53: __C3indexwriter.__m21ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:41 root: INFO: instruction count: 28: __C3indexwriter.close
2022-11-09 14:19:41 root: INFO: instruction count: 3: __C29FSContainer.<clinit>
2022-11-09 14:19:41 root: INFO: instruction count: 4: __C3indexwriter.addPartitionRegion
2022-11-09 14:19:41 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Begin)
2022-11-09 14:19:41 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:41 root: INFO: instruction count: 234: __C3indexwriter.apply
2022-11-09 14:19:41 root: INFO: instruction count: 3: __C3indexwriter.__m22ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:41 root: INFO: RegionPool: REPORT_THRESHOLD: 32.0M allocated (31.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:41 root: INFO: instruction count: 3: __C3indexwriter.__m22ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:41 root: INFO: instruction count: 7: __C3indexwriter.trackedOS
2022-11-09 14:19:41 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-09 14:19:41 root: INFO: finished execution of query hail_query_1
2022-11-09 14:19:41 root: INFO: finished execution of query hail_query_1
2022-11-09 14:19:41 root: INFO: instruction count: 3: __C29FSContainer.<init>
2022-11-09 14:19:41 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-09 14:19:41 root: INFO: instruction count: 379: __C3indexwriter.__m23writeLeafNode
2022-11-09 14:19:41 root: INFO: instruction count: 445: __C3indexwriter.__m12writeInternalNode
2022-11-09 14:19:42 root: INFO: instruction count: 379: __C3indexwriter.__m23writeLeafNode
2022-11-09 14:19:42 root: INFO: instruction count: 9: __C3indexwriter.setPartitionIndex
2022-11-09 14:19:42 root: INFO: instruction count: 3: __C32etypeEncode.<init>
2022-11-09 14:19:42 root: INFO: timing SparkBackend.executeJSON total 22.288s self 96.269ms children 22.191s %children 99.57%
2022-11-09 14:19:42 SparkContext: INFO: Starting job: collect at ContextRDD.scala:166
2022-11-09 14:19:42 root: INFO: instruction count: 28: __C29FSContainer.init_filesystem
2022-11-09 14:19:42 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8057 bytes)
2022-11-09 14:19:42 root: INFO: instruction count: 3: __C29FSContainer.<clinit>
2022-11-09 14:19:42 root: INFO: instruction count: 3: __C1etypeEncode.<init>
2022-11-09 14:19:42 root: INFO: instruction count: 13: __C3indexwriter.__m13ENCODE_o_tuple_of_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:42 root: INFO: instruction count: 23: __C3indexwriter.__m24ENCODE_o_tuple_of_r_int64ANDr_array_of_r_tuple_of_r_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_int64ANDr_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:42 root: INFO: instruction count: 49: __C3indexwriter.__m14ENCODE_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:42 root: INFO: instruction count: 49: __C3indexwriter.__m25ENCODE_r_array_of_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:42 root: INFO: timing SparkBackend.executeJSON total 22.488s self 120.783ms children 22.367s %children 99.46%
2022-11-09 14:19:42 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 210.369ms self 0.653ms children 209.716ms %children 99.69%
2022-11-09 14:19:42 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:166) with 1 output partitions
2022-11-09 14:19:42 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:166)
2022-11-09 14:19:42 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:42 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:42 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-09 14:19:42 root: INFO: instruction count: 23: __C3indexwriter.__m24ENCODE_o_tuple_of_r_int64ANDr_array_of_r_tuple_of_r_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_int64ANDr_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:42 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-09 14:19:42 root: INFO: instruction count: 5: __C1etypeEncode.apply
2022-11-09 14:19:42 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-09 14:19:42 root: INFO: instruction count: 4: __C3indexwriter.addPartitionRegion
2022-11-09 14:19:42 root: INFO: instruction count: 5: __C32etypeEncode.apply
2022-11-09 14:19:42 root: INFO: instruction count: 19: __C32etypeEncode.__m33ENCODE_r_tuple_of_r_locusANDr_array_of_r_stringEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:42 root: INFO: instruction count: 23: __C32etypeEncode.__m34ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:42 root: INFO: instruction count: 16: __C32etypeEncode.__m35ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:42 root: INFO: instruction count: 4: __C32etypeEncode.__m36ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:42 root: INFO: instruction count: 53: __C32etypeEncode.__m37ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:42 root: INFO: instruction count: 45: __C3indexwriter.__m15ENCODE_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:42 root: INFO: instruction count: 4: __C3indexwriter.__m16ENCODE_r_int64_TO_r_int64
2022-11-09 14:19:42 root: INFO: instruction count: 19: __C3indexwriter.__m17ENCODE_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:42 root: INFO: instruction count: 23: __C3indexwriter.__m18ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:42 root: INFO: instruction count: 25: __C3indexwriter.__m26ENCODE_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:42 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-09 14:19:42 root: INFO: instruction count: 52: __C3indexwriter.__m27flush
2022-11-09 14:19:42 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 312.3 KB, free 411.6 MB)
2022-11-09 14:19:42 root: INFO: RegionPool: REPORT_THRESHOLD: 16.0M allocated (15.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:42 root: INFO: instruction count: 49: __C3indexwriter.__m25ENCODE_r_array_of_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:42 root: INFO: instruction count: 3: __C1etypeEncode.__m2ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:42 root: INFO: instruction count: 25: __C3indexwriter.__m26ENCODE_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:42 root: INFO: RegionPool: REPORT_THRESHOLD: 16.0M allocated (15.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:42 root: INFO: instruction count: 3: __C32etypeEncode.<init>
2022-11-09 14:19:42 root: INFO: instruction count: 3: __C29FSContainer.<init>
2022-11-09 14:19:42 root: INFO: instruction count: 16: __C3indexwriter.__m19ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:42 root: INFO: instruction count: 4: __C3indexwriter.__m20ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:42 root: INFO: instruction count: 53: __C3indexwriter.__m21ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:42 root: INFO: instruction count: 3: __C3indexwriter.__m22ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:42 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.313ms self 0.313ms children 0.000ms %children 0.00%
2022-11-09 14:19:42 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 200.167ms self 0.593ms children 199.574ms %children 99.70%
2022-11-09 14:19:42 root: INFO: instruction count: 150: __C3indexwriter.init
2022-11-09 14:19:42 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1632 bytes result sent to driver
2022-11-09 14:19:42 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 114.5 KB, free 411.5 MB)
2022-11-09 14:19:42 SparkContext: INFO: Starting job: collect at ContextRDD.scala:166
2022-11-09 14:19:42 root: INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:42 root: INFO: instruction count: 3: __C1etypeEncode.<init>
2022-11-09 14:19:42 root: INFO: instruction count: 5: __C1etypeEncode.apply
2022-11-09 14:19:42 root: INFO: instruction count: 3: __C1etypeEncode.__m2ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:42 root: INFO: instruction count: 52: __C3indexwriter.__m27flush
2022-11-09 14:19:42 root: INFO: instruction count: 5: __C32etypeEncode.apply
2022-11-09 14:19:42 root: INFO: instruction count: 28: __C29FSContainer.init_filesystem
2022-11-09 14:19:42 root: INFO: instruction count: 19: __C32etypeEncode.__m33ENCODE_r_tuple_of_r_locusANDr_array_of_r_stringEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:42 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.340ms self 0.340ms children 0.000ms %children 0.00%
2022-11-09 14:19:42 root: INFO: instruction count: 4: __C3indexwriter.setObjects
2022-11-09 14:19:42 SparkContext: INFO: Starting job: collect at ContextRDD.scala:166
2022-11-09 14:19:42 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compe078.hpc.in.bmrc.ox.ac.uk:34810 (size: 114.5 KB, free: 413.7 MB)
2022-11-09 14:19:42 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:42 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:42 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-09 14:19:42 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:166) with 1 output partitions
2022-11-09 14:19:42 root: INFO: RegionPool: REPORT_THRESHOLD: 4.0M allocated (3.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:42 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 4845 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:42 root: INFO: instruction count: 150: __C3indexwriter.init
2022-11-09 14:19:43 root: INFO: instruction count: 4: __C3indexwriter.setObjects
2022-11-09 14:19:43 root: INFO: instruction count: 28: __C3indexwriter.close
2022-11-09 14:19:43 root: INFO: instruction count: 7: __C3indexwriter.trackedOS
2022-11-09 14:19:43 root: INFO: instruction count: 9: __C3indexwriter.setPartitionIndex
2022-11-09 14:19:43 root: INFO: instruction count: 4: __C3indexwriter.addPartitionRegion
2022-11-09 14:19:43 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 6.967 s
2022-11-09 14:19:42 root: INFO: instruction count: 3: __C29FSContainer.<clinit>
2022-11-09 14:19:42 root: INFO: instruction count: 23: __C32etypeEncode.__m34ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:42 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 199.201ms self 104.451ms children 94.751ms %children 47.57%
2022-11-09 14:19:42 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 209.367ms self 147.550ms children 61.817ms %children 29.53%
2022-11-09 14:19:42 root: INFO: instruction count: 28: __C3indexwriter.close
2022-11-09 14:19:43 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 61.817ms self 1.281ms children 60.536ms %children 97.93%
2022-11-09 14:19:42 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8058 bytes)
2022-11-09 14:19:43 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-09 14:19:42 root: INFO: instruction count: 3: __C3indexwriter.<init>
2022-11-09 14:19:42 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:166)
2022-11-09 14:19:42 root: INFO: instruction count: 379: __C3indexwriter.__m23writeLeafNode
2022-11-09 14:19:43 root: INFO: instruction count: 23: __C3indexwriter.__m24ENCODE_o_tuple_of_r_int64ANDr_array_of_r_tuple_of_r_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_int64ANDr_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:43 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:43 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 8.574062 s
2022-11-09 14:19:43 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-09 14:19:43 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 916 bytes result sent to driver
2022-11-09 14:19:43 root: INFO: instruction count: 16: __C32etypeEncode.__m35ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:43 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 5596 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:42 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:166) with 1 output partitions
2022-11-09 14:19:43 root: INFO: instruction count: 7: __C3indexwriter.trackedOS
2022-11-09 14:19:43 root: INFO: RegionPool: REPORT_THRESHOLD: 32.0M allocated (31.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:43 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 94.751ms self 1.385ms children 93.366ms %children 98.54%
2022-11-09 14:19:43 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 3.395ms self 3.395ms children 0.000ms %children 0.00%
2022-11-09 14:19:43 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-09 14:19:43 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-09 14:19:43 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-09 14:19:43 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-09 14:19:43 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-09 14:19:43 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-09 14:19:43 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-09 14:19:43 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-09 14:19:43 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-09 14:19:43 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-09 14:19:43 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-09 14:19:43 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-09 14:19:43 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-09 14:19:43 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-09 14:19:43 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-09 14:19:43 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-09 14:19:43 root: INFO: RegionPool: REPORT_THRESHOLD: 32.0M allocated (31.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:43 root: INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:43 root: INFO: instruction count: 234: __C3indexwriter.apply
2022-11-09 14:19:43 root: INFO: instruction count: 3: __C29FSContainer.<init>
2022-11-09 14:19:43 root: INFO: instruction count: 49: __C3indexwriter.__m25ENCODE_r_array_of_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:43 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:43 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-09 14:19:43 Hail: INFO: Coerced sorted dataset
2022-11-09 14:19:43 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-09 14:19:43 root: INFO: instruction count: 3: __C32etypeEncode.<init>
2022-11-09 14:19:43 root: INFO: instruction count: 3: __C3indexwriter.<init>
2022-11-09 14:19:43 root: INFO: instruction count: 234: __C3indexwriter.apply
2022-11-09 14:19:43 root: INFO: instruction count: 4: __C32etypeEncode.__m36ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:43 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-09 14:19:43 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:166)
2022-11-09 14:19:43 root: INFO: instruction count: 9: __C3indexwriter.setPartitionIndex
2022-11-09 14:19:43 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 3.532ms self 3.532ms children 0.000ms %children 0.00%
2022-11-09 14:19:43 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-09 14:19:44 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-09 14:19:43 root: INFO: RegionPool: REPORT_THRESHOLD: 8.0M allocated (7.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:43 root: INFO: instruction count: 445: __C3indexwriter.__m12writeInternalNode
2022-11-09 14:19:43 root: INFO: instruction count: 28: __C29FSContainer.init_filesystem
2022-11-09 14:19:43 root: INFO: instruction count: 25: __C3indexwriter.__m26ENCODE_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:44 root: INFO: instruction count: 52: __C3indexwriter.__m27flush
2022-11-09 14:19:43 root: INFO: RegionPool: REPORT_THRESHOLD: 4.0M allocated (3.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:44 root: INFO: instruction count: 150: __C3indexwriter.init
2022-11-09 14:19:44 root: INFO: instruction count: 4: __C3indexwriter.setObjects
2022-11-09 14:19:44 root: INFO: instruction count: 28: __C3indexwriter.close
2022-11-09 14:19:44 root: INFO: instruction count: 7: __C3indexwriter.trackedOS
2022-11-09 14:19:44 root: INFO: instruction count: 9: __C3indexwriter.setPartitionIndex
2022-11-09 14:19:44 root: INFO: instruction count: 4: __C3indexwriter.addPartitionRegion
2022-11-09 14:19:43 root: INFO: instruction count: 5: __C32etypeEncode.apply
2022-11-09 14:19:43 root: INFO: instruction count: 445: __C3indexwriter.__m12writeInternalNode
2022-11-09 14:19:43 root: INFO: instruction count: 53: __C32etypeEncode.__m37ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:43 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:166) finished in 7.573 s
2022-11-09 14:19:43 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-09 14:19:44 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:166, took 9.120458 s
2022-11-09 14:19:43 root: INFO: instruction count: 4: __C3indexwriter.addPartitionRegion
2022-11-09 14:19:43 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 14.296ms self 14.296ms children 0.000ms %children 0.00%
2022-11-09 14:19:43 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 4.458ms self 4.458ms children 0.000ms %children 0.00%
2022-11-09 14:19:44 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 916 bytes result sent to driver
2022-11-09 14:19:44 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compa042.hpc.in.bmrc.ox.ac.uk:35350 in memory (size: 7.4 KB, free: 413.7 MB)
2022-11-09 14:19:44 root: INFO: instruction count: 13: __C3indexwriter.__m13ENCODE_o_tuple_of_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:44 root: INFO: instruction count: 3: __C29FSContainer.<clinit>
2022-11-09 14:19:43 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 312.3 KB, free 411.6 MB)
2022-11-09 14:19:44 root: INFO: instruction count: 3: __C29FSContainer.<init>
2022-11-09 14:19:44 root: INFO: instruction count: 19: __C32etypeEncode.__m33ENCODE_r_tuple_of_r_locusANDr_array_of_r_stringEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:44 root: INFO: instruction count: 13: __C3indexwriter.__m13ENCODE_o_tuple_of_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:44 root: INFO: instruction count: 49: __C3indexwriter.__m14ENCODE_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:44 root: INFO: instruction count: 45: __C3indexwriter.__m15ENCODE_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:44 root: INFO: instruction count: 4: __C3indexwriter.__m16ENCODE_r_int64_TO_r_int64
2022-11-09 14:19:44 root: INFO: instruction count: 19: __C3indexwriter.__m17ENCODE_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:44 root: INFO: instruction count: 23: __C3indexwriter.__m18ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:44 root: INFO: instruction count: 16: __C3indexwriter.__m19ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:44 root: INFO: instruction count: 4: __C3indexwriter.__m20ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:44 root: INFO: instruction count: 53: __C3indexwriter.__m21ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:44 root: INFO: instruction count: 3: __C3indexwriter.__m22ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:44 root: INFO: instruction count: 379: __C3indexwriter.__m23writeLeafNode
2022-11-09 14:19:44 root: INFO: instruction count: 23: __C3indexwriter.__m24ENCODE_o_tuple_of_r_int64ANDr_array_of_r_tuple_of_r_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_int64ANDr_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:44 root: INFO: instruction count: 49: __C3indexwriter.__m25ENCODE_r_array_of_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:44 root: INFO: instruction count: 25: __C3indexwriter.__m26ENCODE_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:44 root: INFO: instruction count: 52: __C3indexwriter.__m27flush
2022-11-09 14:19:44 root: INFO: instruction count: 150: __C3indexwriter.init
2022-11-09 14:19:44 root: INFO: instruction count: 4: __C3indexwriter.setObjects
2022-11-09 14:19:44 root: INFO: instruction count: 28: __C3indexwriter.close
2022-11-09 14:19:44 root: INFO: instruction count: 7: __C3indexwriter.trackedOS
2022-11-09 14:19:44 root: INFO: instruction count: 9: __C3indexwriter.setPartitionIndex
2022-11-09 14:19:44 root: INFO: instruction count: 4: __C3indexwriter.addPartitionRegion
2022-11-09 14:19:44 root: INFO: instruction count: 3: __C29FSContainer.<init>
2022-11-09 14:19:44 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 916 bytes result sent to driver
2022-11-09 14:19:43 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:44 root: INFO: instruction count: 3: __C29FSContainer.<init>
2022-11-09 14:19:44 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:44 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-09 14:19:44 root: INFO: instruction count: 3: __C1etypeEncode.<init>
2022-11-09 14:19:44 root: INFO: instruction count: 49: __C3indexwriter.__m14ENCODE_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:44 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-09 14:19:44 Hail: INFO: wrote table with 768121 rows in 1 partition to data/ht/ukb_wes_450k.qced.chr5.ht
    Total size: 9.41 MiB
    * Rows: 9.41 MiB
    * Globals: 11.00 B
    * Smallest partition: 768121 rows (9.41 MiB)
    * Largest partition:  768121 rows (9.41 MiB)
2022-11-09 14:19:44 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-09 14:19:44 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-09 14:19:44 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-09 14:19:44 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-09 14:19:44 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-09 14:19:44 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-09 14:19:44 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-09 14:19:44 root: INFO: RegionPool: REPORT_THRESHOLD: 16.0M allocated (15.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:44 root: INFO: took 20.067s
2022-11-09 14:19:44 root: INFO: instruction count: 28: __C29FSContainer.init_filesystem
2022-11-09 14:19:44 root: INFO: instruction count: 3: __C29FSContainer.<clinit>
2022-11-09 14:19:44 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 1: 
(Begin)
2022-11-09 14:19:44 root: INFO: instruction count: 28: __C29FSContainer.init_filesystem
2022-11-09 14:19:44 root: INFO: instruction count: 3: __C29FSContainer.<clinit>
2022-11-09 14:19:44 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-09 14:19:44 SparkContext: INFO: Starting job: collect at ContextRDD.scala:166
2022-11-09 14:19:44 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 7511 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:44 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 24.262ms self 24.262ms children 0.000ms %children 0.00%
2022-11-09 14:19:44 root: INFO: instruction count: 28: __C29FSContainer.init_filesystem
2022-11-09 14:19:44 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-09 14:19:44 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 7437 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:44 root: INFO: instruction count: 5: __C1etypeEncode.apply
2022-11-09 14:19:44 root: INFO: instruction count: 45: __C3indexwriter.__m15ENCODE_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:45 root: INFO: instruction count: 4: __C3indexwriter.__m16ENCODE_r_int64_TO_r_int64
2022-11-09 14:19:45 root: INFO: instruction count: 19: __C3indexwriter.__m17ENCODE_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:45 root: INFO: instruction count: 23: __C3indexwriter.__m18ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:45 root: INFO: instruction count: 16: __C3indexwriter.__m19ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:45 root: INFO: instruction count: 4: __C3indexwriter.__m20ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:45 root: INFO: instruction count: 53: __C3indexwriter.__m21ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:45 root: INFO: instruction count: 3: __C3indexwriter.__m22ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:45 root: INFO: instruction count: 379: __C3indexwriter.__m23writeLeafNode
2022-11-09 14:19:44 root: INFO: instruction count: 3: __C32etypeEncode.<init>
2022-11-09 14:19:44 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-09 14:19:44 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 114.5 KB, free 411.5 MB)
2022-11-09 14:19:44 root: INFO: instruction count: 23: __C32etypeEncode.__m34ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:44 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-09 14:19:44 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Begin)
2022-11-09 14:19:44 root: INFO: instruction count: 3: __C32etypeEncode.<init>
2022-11-09 14:19:45 root: INFO: instruction count: 5: __C32etypeEncode.apply
2022-11-09 14:19:45 root: INFO: instruction count: 19: __C32etypeEncode.__m33ENCODE_r_tuple_of_r_locusANDr_array_of_r_stringEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:45 root: INFO: instruction count: 23: __C32etypeEncode.__m34ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:45 root: INFO: instruction count: 16: __C32etypeEncode.__m35ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:45 root: INFO: instruction count: 4: __C32etypeEncode.__m36ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:45 root: INFO: instruction count: 53: __C32etypeEncode.__m37ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:45 root: INFO: finished execution of query hail_query_1
2022-11-09 14:19:44 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-09 14:19:45 root: INFO: timing SparkBackend.executeJSON total 21.294s self 166.987ms children 21.127s %children 99.22%
2022-11-09 14:19:44 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:166) finished in 8.884 s
2022-11-09 14:19:45 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 312.3 KB, free 411.6 MB)
2022-11-09 14:19:44 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-09 14:19:45 root: INFO: instruction count: 3: __C1etypeEncode.__m2ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:45 root: INFO: instruction count: 23: __C3indexwriter.__m24ENCODE_o_tuple_of_r_int64ANDr_array_of_r_tuple_of_r_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_int64ANDr_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:45 root: INFO: instruction count: 5: __C32etypeEncode.apply
2022-11-09 14:19:45 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-09 14:19:45 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compf004.hpc.in.bmrc.ox.ac.uk:39715 (size: 114.5 KB, free: 413.7 MB)
2022-11-09 14:19:45 root: INFO: instruction count: 16: __C32etypeEncode.__m35ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:45 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:44 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:166) with 1 output partitions
2022-11-09 14:19:44 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 14.833ms self 14.833ms children 0.000ms %children 0.00%
2022-11-09 14:19:44 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 19.612ms self 19.612ms children 0.000ms %children 0.00%
2022-11-09 14:19:44 root: INFO: instruction count: 3: __C29FSContainer.<clinit>
2022-11-09 14:19:45 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 9.141ms self 9.141ms children 0.000ms %children 0.00%
2022-11-09 14:19:45 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 1.466ms self 1.466ms children 0.000ms %children 0.00%
2022-11-09 14:19:45 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:166, took 10.450730 s
2022-11-09 14:19:45 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 114.5 KB, free 411.5 MB)
2022-11-09 14:19:45 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-09 14:19:45 root: INFO: instruction count: 49: __C3indexwriter.__m25ENCODE_r_array_of_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:45 root: INFO: instruction count: 19: __C32etypeEncode.__m33ENCODE_r_tuple_of_r_locusANDr_array_of_r_stringEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:45 root: INFO: instruction count: 25: __C3indexwriter.__m26ENCODE_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:45 root: INFO: instruction count: 52: __C3indexwriter.__m27flush
2022-11-09 14:19:45 root: INFO: instruction count: 3: __C32etypeEncode.<init>
2022-11-09 14:19:45 root: INFO: instruction count: 5: __C32etypeEncode.apply
2022-11-09 14:19:45 root: INFO: instruction count: 19: __C32etypeEncode.__m33ENCODE_r_tuple_of_r_locusANDr_array_of_r_stringEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:45 root: INFO: instruction count: 23: __C32etypeEncode.__m34ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:45 root: INFO: instruction count: 16: __C32etypeEncode.__m35ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:45 root: INFO: instruction count: 4: __C32etypeEncode.__m36ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:45 root: INFO: instruction count: 4: __C32etypeEncode.__m36ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:45 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:45 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:166)
2022-11-09 14:19:45 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 313.881ms self 0.733ms children 313.148ms %children 99.77%
2022-11-09 14:19:45 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-09 14:19:45 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.336ms self 0.336ms children 0.000ms %children 0.00%
2022-11-09 14:19:45 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 28.398ms self 28.398ms children 0.000ms %children 0.00%
2022-11-09 14:19:45 root: INFO: RegionPool: REPORT_THRESHOLD: 32.0M allocated (31.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:45 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compe070.hpc.in.bmrc.ox.ac.uk:46576 (size: 114.5 KB, free: 413.7 MB)
2022-11-09 14:19:46 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:46 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:46 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-09 14:19:45 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-09 14:19:45 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-09 14:19:45 root: INFO: instruction count: 23: __C32etypeEncode.__m34ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:45 Hail: INFO: wrote table with 657046 rows in 1 partition to data/ht/ukb_wes_450k.qced.chr8.ht
    Total size: 7.98 MiB
    * Rows: 7.98 MiB
    * Globals: 11.00 B
    * Smallest partition: 657046 rows (7.98 MiB)
    * Largest partition:  657046 rows (7.98 MiB)
2022-11-09 14:19:45 root: INFO: instruction count: 150: __C3indexwriter.init
2022-11-09 14:19:45 root: INFO: instruction count: 53: __C32etypeEncode.__m37ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:45 root: INFO: instruction count: 53: __C32etypeEncode.__m37ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:45 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-09 14:19:45 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:45 SparkContext: INFO: Starting job: collect at ContextRDD.scala:166
2022-11-09 14:19:46 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:166) with 1 output partitions
2022-11-09 14:19:46 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:166)
2022-11-09 14:19:46 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:46 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:46 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-09 14:19:45 root: INFO: instruction count: 3: __C32etypeEncode.<init>
2022-11-09 14:19:45 root: INFO: instruction count: 3: __C3indexwriter.<init>
2022-11-09 14:19:45 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 312.770ms self 242.928ms children 69.842ms %children 22.33%
2022-11-09 14:19:45 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 1.433ms self 1.433ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8058 bytes)
2022-11-09 14:19:45 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-09 14:19:45 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:166) finished in 8.834 s
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-09 14:19:46 root: INFO: took 23.755s
2022-11-09 14:19:46 root: INFO: instruction count: 4: __C3indexwriter.setObjects
2022-11-09 14:19:46 root: INFO: instruction count: 28: __C3indexwriter.close
2022-11-09 14:19:46 root: INFO: instruction count: 7: __C3indexwriter.trackedOS
2022-11-09 14:19:46 root: INFO: instruction count: 9: __C3indexwriter.setPartitionIndex
2022-11-09 14:19:46 root: INFO: instruction count: 4: __C3indexwriter.addPartitionRegion
2022-11-09 14:19:46 root: INFO: instruction count: 3: __C29FSContainer.<init>
2022-11-09 14:19:40 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compa040.hpc.in.bmrc.ox.ac.uk:37984 in memory (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:46 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8058 bytes)
2022-11-09 14:19:46 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:46 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-09 14:19:46 root: INFO: instruction count: 5: __C32etypeEncode.apply
2022-11-09 14:19:46 root: INFO: instruction count: 234: __C3indexwriter.apply
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 69.842ms self 1.356ms children 68.486ms %children 98.06%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 24.983ms self 24.983ms children 0.000ms %children 0.00%
2022-11-09 14:19:45 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.167ms self 0.167ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 3.478ms self 3.478ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 4.818ms self 4.818ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 14.675ms self 14.675ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 11.120ms self 11.120ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 1.676ms self 1.676ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 20.481ms self 20.481ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.166ms self 0.166ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.088ms self 0.088ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.145ms self 0.145ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.299ms self 0.299ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.022ms self 0.022ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 10.609ms self 10.609ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.116ms self 0.116ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.016ms self 0.016ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.060ms self 0.060ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.291ms self 0.291ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.022ms self 0.022ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.405ms self 0.405ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.041ms self 0.041ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 8.539ms self 0.020ms children 8.519ms %children 99.77%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.008ms self 0.008ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 8.400ms self 8.400ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.112ms self 0.112ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 276.728ms self 0.035ms children 276.693ms %children 99.99%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 276.580ms self 145.414ms children 131.166ms %children 47.42%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 131.166ms self 0.115ms children 131.051ms %children 99.91%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 7.220ms self 7.220ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.240ms self 0.240ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 30.935ms self 30.935ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 1.229ms self 1.229ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.059ms self 0.059ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 89.689ms self 89.689ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.213ms self 0.213ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.166ms self 0.166ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.243ms self 0.243ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.306ms self 0.306ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.020ms self 0.020ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.223ms self 0.223ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.068ms self 0.068ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.031ms self 0.031ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.031ms self 0.031ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.198ms self 0.198ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.016ms self 0.016ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.164ms self 0.164ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.091ms self 0.091ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 20.135s self 0.026ms children 20.135s %children 100.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.030ms self 0.030ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 20.135s self 20.135s children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.425ms self 0.425ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 392.709ms self 0.025ms children 392.684ms %children 99.99%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.006ms self 0.006ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 392.665ms self 391.653ms children 1.011ms %children 0.26%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 1.011ms self 0.060ms children 0.951ms %children 94.05%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.167ms self 0.167ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.440ms self 0.440ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.056ms self 0.056ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.174ms self 0.174ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.020ms self 0.020ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.093ms self 0.093ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.014ms self 0.014ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.022ms self 0.022ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: instruction count: 16: __C32etypeEncode.__m35ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-09 14:19:46 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:166, took 11.630266 s
2022-11-09 14:19:46 SparkContext: INFO: Starting job: collect at ContextRDD.scala:166
2022-11-09 14:19:46 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 1: 
(Begin)
2022-11-09 14:19:46 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Begin)
2022-11-09 14:19:46 root: INFO: finished execution of query hail_query_1
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON total 25.195s self 125.828ms children 25.069s %children 99.50%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 339.297ms self 0.489ms children 338.809ms %children 99.86%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.274ms self 0.274ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 338.510ms self 294.128ms children 44.383ms %children 13.11%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 44.383ms self 1.034ms children 43.348ms %children 97.67%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 3.233ms self 3.233ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 3.734ms self 3.734ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 10.804ms self 10.804ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 7.946ms self 7.946ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 1.461ms self 1.461ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 14.773ms self 14.773ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.107ms self 0.107ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.057ms self 0.057ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.108ms self 0.108ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.191ms self 0.191ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.015ms self 0.015ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.317ms self 0.317ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.060ms self 0.060ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.022ms self 0.022ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.031ms self 0.031ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.175ms self 0.175ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.015ms self 0.015ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.299ms self 0.299ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.025ms self 0.025ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 6.575ms self 0.011ms children 6.565ms %children 99.84%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.005ms self 0.005ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 6.482ms self 6.482ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.078ms self 0.078ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 281.651ms self 0.013ms children 281.637ms %children 100.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.016ms self 0.016ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 281.612ms self 146.625ms children 134.987ms %children 47.93%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 134.987ms self 0.083ms children 134.904ms %children 99.94%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 5.926ms self 5.926ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.192ms self 0.192ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 5.528ms self 5.528ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 14.043ms self 14.043ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.054ms self 0.054ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 107.945ms self 107.945ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.166ms self 0.166ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.111ms self 0.111ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.190ms self 0.190ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.173ms self 0.173ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.015ms self 0.015ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.178ms self 0.178ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.050ms self 0.050ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.018ms self 0.018ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.147ms self 0.147ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.012ms self 0.012ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.137ms self 0.137ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.009ms self 0.009ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 24.155s self 0.020ms children 24.155s %children 100.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.006ms self 0.006ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 24.155s self 24.155s children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.324ms self 0.324ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 285.892ms self 0.008ms children 285.884ms %children 100.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.004ms self 0.004ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 285.874ms self 285.140ms children 0.734ms %children 0.26%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 0.734ms self 0.038ms children 0.696ms %children 94.82%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.109ms self 0.109ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.252ms self 0.252ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.053ms self 0.053ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.173ms self 0.173ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.020ms self 0.020ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.089ms self 0.089ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.005ms self 0.005ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.014ms self 0.014ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: instruction count: 28: __C29FSContainer.init_filesystem
2022-11-09 14:19:46 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 312.3 KB, free 411.6 MB)
2022-11-09 14:19:46 SparkContext: INFO: Starting job: collect at ContextRDD.scala:166
2022-11-09 14:19:46 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-09 14:19:46 root: INFO: instruction count: 19: __C32etypeEncode.__m33ENCODE_r_tuple_of_r_locusANDr_array_of_r_stringEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:46 root: INFO: instruction count: 445: __C3indexwriter.__m12writeInternalNode
2022-11-09 14:19:46 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.073ms self 0.073ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 root: INFO: instruction count: 4: __C32etypeEncode.__m36ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:46 root: INFO: instruction count: 53: __C32etypeEncode.__m37ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-09 14:19:46 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:166) with 1 output partitions
2022-11-09 14:19:46 root: INFO: instruction count: 3: __C29FSContainer.<clinit>
2022-11-09 14:19:46 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 114.5 KB, free 411.5 MB)
2022-11-09 14:19:46 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compa030.hpc.in.bmrc.ox.ac.uk:36769 (size: 114.5 KB, free: 413.7 MB)
2022-11-09 14:19:46 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:46 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:46 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-09 14:19:46 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8058 bytes)
2022-11-09 14:19:46 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-09 14:19:46 root: INFO: instruction count: 23: __C32etypeEncode.__m34ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:46 root: INFO: instruction count: 13: __C3indexwriter.__m13ENCODE_o_tuple_of_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.160ms self 0.160ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-09 14:19:44 root: INFO: RegionPool: REPORT_THRESHOLD: 4.0M allocated (3.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:46 Hail: INFO: wrote table with 483385 rows in 1 partition to data/ht/ukb_wes_450k.qced.chr20.ht
    Total size: 5.90 MiB
    * Rows: 5.90 MiB
    * Globals: 11.00 B
    * Smallest partition: 483385 rows (5.90 MiB)
    * Largest partition:  483385 rows (5.90 MiB)
2022-11-09 14:19:46 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:166)
2022-11-09 14:19:46 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:46 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:46 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-09 14:19:46 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-09 14:19:46 root: INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:46 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 312.3 KB, free 411.6 MB)
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-09 14:19:46 root: INFO: instruction count: 16: __C32etypeEncode.__m35ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.143ms self 0.143ms children 0.000ms %children 0.00%
2022-11-09 14:19:46 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-09 14:19:46 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:19:46 root: INFO: took 20.725s
2022-11-09 14:19:46 root: INFO: instruction count: 49: __C3indexwriter.__m14ENCODE_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:46 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compe078.hpc.in.bmrc.ox.ac.uk:34810 in memory (size: 7.4 KB, free: 413.7 MB)
2022-11-09 14:19:47 root: INFO: instruction count: 3: __C32etypeEncode.<init>
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-09 14:19:46 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.076ms self 0.076ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-09 14:19:47 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 312.3 KB, free 411.6 MB)
2022-11-09 14:19:46 root: INFO: instruction count: 4: __C32etypeEncode.__m36ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:47 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 114.5 KB, free 411.5 MB)
2022-11-09 14:19:47 root: INFO: instruction count: 45: __C3indexwriter.__m15ENCODE_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:47 AbstractConnector: INFO: Stopped Spark@384ba840{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:19:47 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 1: 
(Begin)
2022-11-09 14:19:47 root: INFO: instruction count: 5: __C32etypeEncode.apply
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.146ms self 0.146ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-09 14:19:47 root: INFO: instruction count: 53: __C32etypeEncode.__m37ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:47 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 114.5 KB, free 411.5 MB)
2022-11-09 14:19:47 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:19:47 AbstractConnector: INFO: Stopped Spark@4c2625ad{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:19:47 SparkUI: INFO: Stopped Spark web UI at http://compe039.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 14:19:47 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compe094.hpc.in.bmrc.ox.ac.uk:33393 (size: 114.5 KB, free: 413.7 MB)
2022-11-09 14:19:47 root: INFO: instruction count: 4: __C3indexwriter.__m16ENCODE_r_int64_TO_r_int64
2022-11-09 14:19:47 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Begin)
2022-11-09 14:19:47 root: INFO: instruction count: 19: __C32etypeEncode.__m33ENCODE_r_tuple_of_r_locusANDr_array_of_r_stringEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:47 root: INFO: finished execution of query hail_query_1
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.278ms self 0.278ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.279ms self 0.279ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-09 14:19:47 root: INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:47 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compe074.hpc.in.bmrc.ox.ac.uk:33207 (size: 114.5 KB, free: 413.7 MB)
2022-11-09 14:19:47 root: INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:47 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:47 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 14:19:47 root: INFO: instruction count: 19: __C3indexwriter.__m17ENCODE_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-09 14:19:47 root: INFO: instruction count: 23: __C3indexwriter.__m18ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.024ms self 0.024ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-09 14:19:47 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:47 SparkContext: INFO: Starting job: collect at ContextRDD.scala:166
2022-11-09 14:19:47 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:47 root: INFO: instruction count: 23: __C32etypeEncode.__m34ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:47 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-09 14:19:47 root: INFO: instruction count: 16: __C32etypeEncode.__m35ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.022ms self 0.022ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-09 14:19:47 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:47 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-09 14:19:47 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:166) with 1 output partitions
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON total 22.350s self 196.899ms children 22.153s %children 99.12%
2022-11-09 14:19:47 root: INFO: instruction count: 16: __C3indexwriter.__m19ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:47 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8058 bytes)
2022-11-09 14:19:47 root: INFO: instruction count: 4: __C32etypeEncode.__m36ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:47 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.861ms self 0.861ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-09 14:19:47 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8057 bytes)
2022-11-09 14:19:47 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:166)
2022-11-09 14:19:47 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-09 14:19:47 root: INFO: instruction count: 4: __C3indexwriter.__m20ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:47 root: INFO: instruction count: 53: __C3indexwriter.__m21ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:47 root: INFO: instruction count: 3: __C3indexwriter.__m22ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-09 14:19:47 root: INFO: instruction count: 379: __C3indexwriter.__m23writeLeafNode
2022-11-09 14:19:47 root: INFO: instruction count: 23: __C3indexwriter.__m24ENCODE_o_tuple_of_r_int64ANDr_array_of_r_tuple_of_r_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_int64ANDr_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-09 14:19:47 root: INFO: instruction count: 49: __C3indexwriter.__m25ENCODE_r_array_of_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:47 root: INFO: instruction count: 25: __C3indexwriter.__m26ENCODE_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-09 14:19:47 root: INFO: instruction count: 52: __C3indexwriter.__m27flush
2022-11-09 14:19:47 root: INFO: instruction count: 150: __C3indexwriter.init
2022-11-09 14:19:47 root: INFO: instruction count: 4: __C3indexwriter.setObjects
2022-11-09 14:19:47 root: INFO: instruction count: 28: __C3indexwriter.close
2022-11-09 14:19:47 root: INFO: instruction count: 7: __C3indexwriter.trackedOS
2022-11-09 14:19:47 root: INFO: instruction count: 9: __C3indexwriter.setPartitionIndex
2022-11-09 14:19:47 root: INFO: instruction count: 4: __C3indexwriter.addPartitionRegion
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-09 14:19:47 root: INFO: instruction count: 3: __C29FSContainer.<init>
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 770.210ms self 0.780ms children 769.430ms %children 99.90%
2022-11-09 14:19:47 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:47 root: INFO: instruction count: 53: __C32etypeEncode.__m37ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:47 SparkContext: INFO: Starting job: collect at ContextRDD.scala:166
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-09 14:19:47 root: INFO: instruction count: 28: __C29FSContainer.init_filesystem
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-09 14:19:47 root: INFO: instruction count: 3: __C29FSContainer.<clinit>
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-09 14:19:47 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:166) with 1 output partitions
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.404ms self 0.404ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.397ms self 0.397ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:47 root: INFO: RegionPool: REPORT_THRESHOLD: 4.0M allocated (3.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-09 14:19:47 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-09 14:19:47 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:166)
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-09 14:19:47 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.087ms self 0.087ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 768.985ms self 705.361ms children 63.625ms %children 8.27%
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 63.625ms self 1.526ms children 62.099ms %children 97.60%
2022-11-09 14:19:47 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.013ms self 0.013ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.094ms self 0.094ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 4.201ms self 4.201ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-09 14:19:47 root: INFO: instruction count: 3: __C32etypeEncode.<init>
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-09 14:19:47 root: INFO: instruction count: 5: __C32etypeEncode.apply
2022-11-09 14:19:46 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:166) with 1 output partitions
2022-11-09 14:19:47 root: INFO: instruction count: 19: __C32etypeEncode.__m33ENCODE_r_tuple_of_r_locusANDr_array_of_r_stringEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-09 14:19:47 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:166)
2022-11-09 14:19:47 root: INFO: instruction count: 23: __C32etypeEncode.__m34ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-09 14:19:47 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-09 14:19:47 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 5.476ms self 5.476ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 312.3 KB, free 411.6 MB)
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.048ms self 0.048ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 root: INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:47 root: INFO: instruction count: 16: __C32etypeEncode.__m35ENCODE_r_binary_TO_r_binary
2022-11-09 14:19:47 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 312.3 KB, free 411.6 MB)
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-09 14:19:47 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 15.923ms self 15.923ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 root: INFO: RegionPool: REPORT_THRESHOLD: 8.0M allocated (7.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 10.205ms self 10.205ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 1.485ms self 1.485ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 22.792ms self 22.792ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.192ms self 0.192ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 916 bytes result sent to driver
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.012ms self 0.012ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 114.5 KB, free 411.5 MB)
2022-11-09 14:19:47 root: INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:47 root: INFO: instruction count: 4: __C32etypeEncode.__m36ENCODE_r_int32_TO_r_int32
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-09 14:19:47 root: INFO: instruction count: 53: __C32etypeEncode.__m37ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-09 14:19:47 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 312.3 KB, free 411.6 MB)
2022-11-09 14:19:47 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 6464 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:47 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-09 14:19:47 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:166) finished in 7.512 s
2022-11-09 14:19:47 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:166, took 7.676228 s
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.235ms self 0.235ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compa023.hpc.in.bmrc.ox.ac.uk:38669 (size: 114.5 KB, free: 413.7 MB)
2022-11-09 14:19:47 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 114.5 KB, free 411.5 MB)
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.100ms self 0.100ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-09 14:19:47 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 114.5 KB, free 411.5 MB)
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.042ms self 0.042ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:47 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compa037.hpc.in.bmrc.ox.ac.uk:40682 (size: 114.5 KB, free: 413.7 MB)
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.154ms self 0.154ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-09 14:19:47 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compa040.hpc.in.bmrc.ox.ac.uk:37984 (size: 114.5 KB, free: 413.7 MB)
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.019ms self 0.019ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.223ms self 0.223ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:47 root: INFO: RegionPool: REPORT_THRESHOLD: 4.0M allocated (3.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:47 SparkContext: INFO: Starting job: collect at ContextRDD.scala:166
2022-11-09 14:19:47 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.316ms self 0.316ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.347ms self 0.347ms children 0.000ms %children 0.00%
2022-11-09 14:19:44 root: INFO: RegionPool: REPORT_THRESHOLD: 8.0M allocated (7.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:47 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-09 14:19:47 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:47 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:166) with 1 output partitions
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.023ms self 0.023ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.019ms self 0.019ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8058 bytes)
2022-11-09 14:19:47 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compa043.hpc.in.bmrc.ox.ac.uk:41694 in memory (size: 7.4 KB, free: 413.7 MB)
2022-11-09 14:19:48 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-09 14:19:47 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-09 14:19:48 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:166)
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.438ms self 0.438ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.101ms self 0.101ms children 0.000ms %children 0.00%
2022-11-09 14:19:47 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-09 14:19:48 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8058 bytes)
2022-11-09 14:19:48 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:47 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.036ms self 0.036ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.329ms self 0.329ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8057 bytes)
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.015ms self 0.015ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-09 14:19:48 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.032ms self 0.032ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.052ms self 0.052ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.237ms self 0.237ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 7.309ms self 0.016ms children 7.292ms %children 99.77%
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-09 14:19:48 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.020ms self 0.020ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 7.023ms self 0.015ms children 7.008ms %children 99.79%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.369ms self 0.369ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 Hail: INFO: wrote table with 882773 rows in 1 partition to data/ht/ukb_wes_450k.qced.chr6.ht
    Total size: 10.82 MiB
    * Rows: 10.82 MiB
    * Globals: 11.00 B
    * Smallest partition: 882773 rows (10.82 MiB)
    * Largest partition:  882773 rows (10.82 MiB)
2022-11-09 14:19:48 root: INFO: took 21.390s
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-09 14:19:48 root: INFO: RegionPool: REPORT_THRESHOLD: 4.0M allocated (3.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.007ms self 0.007ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.040ms self 0.040ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 1: 
(Begin)
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-09 14:19:48 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 312.3 KB, free 411.6 MB)
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.005ms self 0.005ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 12.123ms self 0.021ms children 12.102ms %children 99.83%
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-09 14:19:48 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Begin)
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 7.180ms self 7.180ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.005ms self 0.005ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 114.5 KB, free 411.5 MB)
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-09 14:19:48 root: INFO: finished execution of query hail_query_1
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON total 22.033s self 193.276ms children 21.840s %children 99.12%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 192.516ms self 0.970ms children 191.546ms %children 99.50%
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-09 14:19:48 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compa030.hpc.in.bmrc.ox.ac.uk:36769 in memory (size: 7.4 KB, free: 413.7 MB)
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 6.909ms self 6.909ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.105ms self 0.105ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 11.945ms self 11.945ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compa036.hpc.in.bmrc.ox.ac.uk:35064 (size: 114.5 KB, free: 413.7 MB)
2022-11-09 14:19:48 root: INFO: RegionPool: REPORT_THRESHOLD: 8.0M allocated (7.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:48 root: INFO: RegionPool: REPORT_THRESHOLD: 8.0M allocated (7.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.448ms self 0.448ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 191.034ms self 104.721ms children 86.313ms %children 45.18%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 86.313ms self 5.999ms children 80.314ms %children 93.05%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 5.079ms self 5.079ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 6.605ms self 6.605ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 17.886ms self 17.886ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 13.202ms self 13.202ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 2.331ms self 2.331ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 32.512ms self 32.512ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.212ms self 0.212ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.136ms self 0.136ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.193ms self 0.193ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.483ms self 0.483ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.026ms self 0.026ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 SparkContext: INFO: Starting job: collect at ContextRDD.scala:166
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.602ms self 0.602ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.123ms self 0.123ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.018ms self 0.018ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.064ms self 0.064ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.333ms self 0.333ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.028ms self 0.028ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.480ms self 0.480ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.064ms self 0.064ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 12.309ms self 0.026ms children 12.283ms %children 99.79%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.006ms self 0.006ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 12.116ms self 12.116ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.161ms self 0.161ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 114.562ms self 0.038ms children 114.524ms %children 99.97%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.025ms self 0.025ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 114.471ms self 43.436ms children 71.035ms %children 62.06%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 71.035ms self 0.158ms children 70.878ms %children 99.78%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 9.838ms self 9.838ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.295ms self 0.295ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 12.067ms self 12.067ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 1.560ms self 1.560ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.095ms self 0.095ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 44.940ms self 44.940ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.260ms self 0.260ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.198ms self 0.198ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.265ms self 0.265ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.402ms self 0.402ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.029ms self 0.029ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.278ms self 0.278ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.087ms self 0.087ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.026ms self 0.026ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.049ms self 0.049ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.259ms self 0.259ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.022ms self 0.022ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.210ms self 0.210ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.028ms self 0.028ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 21.393s self 0.024ms children 21.393s %children 100.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.009ms self 0.009ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 21.393s self 21.393s children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.525ms self 0.525ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 127.371ms self 0.027ms children 127.344ms %children 99.98%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.007ms self 0.007ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 127.319ms self 126.001ms children 1.318ms %children 1.04%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 1.318ms self 0.075ms children 1.243ms %children 94.34%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.209ms self 0.209ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.602ms self 0.602ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.072ms self 0.072ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.235ms self 0.235ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.023ms self 0.023ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.102ms self 0.102ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.018ms self 0.018ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.023ms self 0.023ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.153ms self 0.153ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:48 root: INFO: RegionPool: REPORT_THRESHOLD: 16.0M allocated (15.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:48 root: INFO: RegionPool: REPORT_THRESHOLD: 4.0M allocated (3.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:48 root: INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:48 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compf004.hpc.in.bmrc.ox.ac.uk:39715 in memory (size: 7.4 KB, free: 413.7 MB)
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.094ms self 0.094ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:166) with 1 output partitions
2022-11-09 14:19:48 root: INFO: RegionPool: REPORT_THRESHOLD: 16.0M allocated (15.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:48 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:166)
2022-11-09 14:19:48 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:48 DAGScheduler: INFO: Parents of final stage: List()
2022-11-09 14:19:48 root: INFO: RegionPool: REPORT_THRESHOLD: 4.0M allocated (3.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:48 DAGScheduler: INFO: Missing parents: List()
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 237.273ms self 0.028ms children 237.245ms %children 99.99%
2022-11-09 14:19:48 root: INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 364.033ms self 0.028ms children 364.005ms %children 99.99%
2022-11-09 14:19:48 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.020ms self 0.020ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-09 14:19:48 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 69.692ms self 0.024ms children 69.668ms %children 99.97%
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-09 14:19:48 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8058 bytes)
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 363.964ms self 305.482ms children 58.483ms %children 16.07%
2022-11-09 14:19:48 root: INFO: RegionPool: REPORT_THRESHOLD: 8.0M allocated (7.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:48 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compe070.hpc.in.bmrc.ox.ac.uk:46576 in memory (size: 7.4 KB, free: 413.7 MB)
2022-11-09 14:19:48 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:19:48 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compa026.hpc.in.bmrc.ox.ac.uk:45825 in memory (size: 7.4 KB, free: 413.8 MB)
2022-11-09 14:19:48 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compe074.hpc.in.bmrc.ox.ac.uk:33207 in memory (size: 7.4 KB, free: 413.7 MB)
2022-11-09 14:19:49 root: INFO: RegionPool: REPORT_THRESHOLD: 8.0M allocated (7.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-09 14:19:48 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-09 14:19:48 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 58.483ms self 0.125ms children 58.357ms %children 99.79%
2022-11-09 14:19:48 root: INFO: RegionPool: REPORT_THRESHOLD: 16.0M allocated (15.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:49 AbstractConnector: INFO: Stopped Spark@2c6a01d8{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:19:48 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 312.3 KB, free 411.6 MB)
2022-11-09 14:19:49 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-09 14:19:49 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-09 14:19:49 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-09 14:19:48 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.020ms self 0.020ms children 0.000ms %children 0.00%
2022-11-09 14:19:49 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 237.204ms self 116.833ms children 120.371ms %children 50.75%
2022-11-09 14:19:49 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-09 14:19:49 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-09 14:19:49 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-09 14:19:49 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-09 14:19:49 root: INFO: RegionPool: REPORT_THRESHOLD: 4.0M allocated (3.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:49 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-09 14:19:49 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-09 14:19:49 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 69.638ms self 5.107ms children 64.531ms %children 92.67%
2022-11-09 14:19:49 root: INFO: RegionPool: REPORT_THRESHOLD: 4.0M allocated (3.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:49 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 7.326ms self 7.326ms children 0.000ms %children 0.00%
2022-11-09 14:19:49 root: INFO: RegionPool: REPORT_THRESHOLD: 32.0M allocated (31.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:49 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.233ms self 0.233ms children 0.000ms %children 0.00%
2022-11-09 14:19:49 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 9.213ms self 9.213ms children 0.000ms %children 0.00%
2022-11-09 14:19:49 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 1.325ms self 1.325ms children 0.000ms %children 0.00%
2022-11-09 14:19:49 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.067ms self 0.067ms children 0.000ms %children 0.00%
2022-11-09 14:19:49 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 38.522ms self 38.522ms children 0.000ms %children 0.00%
2022-11-09 14:19:49 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.223ms self 0.223ms children 0.000ms %children 0.00%
2022-11-09 14:19:49 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.134ms self 0.134ms children 0.000ms %children 0.00%
2022-11-09 14:19:49 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.229ms self 0.229ms children 0.000ms %children 0.00%
2022-11-09 14:19:49 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-09 14:19:49 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-09 14:19:49 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-09 14:19:49 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-09 14:19:49 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-09 14:19:49 root: INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:49 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-09 14:19:49 root: INFO: RegionPool: REPORT_THRESHOLD: 32.0M allocated (31.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:49 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-09 14:19:49 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 959 bytes result sent to driver
2022-11-09 14:19:49 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-09 14:19:49 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-09 14:19:49 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 120.371ms self 0.126ms children 120.245ms %children 99.90%
2022-11-09 14:19:49 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.310ms self 0.310ms children 0.000ms %children 0.00%
2022-11-09 14:19:49 root: INFO: RegionPool: REPORT_THRESHOLD: 16.0M allocated (15.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:49 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-09 14:19:49 root: INFO: RegionPool: REPORT_THRESHOLD: 16.0M allocated (15.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:49 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-09 14:19:49 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 3853 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:50 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-09 14:19:50 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:166) finished in 5.165 s
2022-11-09 14:19:48 root: INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:49 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-09 14:19:49 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 6.724ms self 6.724ms children 0.000ms %children 0.00%
2022-11-09 14:19:49 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.242ms self 0.242ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.078ms self 0.078ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.033ms self 0.033ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.206ms self 0.206ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.017ms self 0.017ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.161ms self 0.161ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.020ms self 0.020ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 20.775s self 0.031ms children 20.775s %children 100.00%
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.011ms self 0.011ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 20.774s self 20.774s children 0.000ms %children 0.00%
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.438ms self 0.438ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 231.970ms self 0.024ms children 231.946ms %children 99.99%
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.007ms self 0.007ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 231.924ms self 230.792ms children 1.133ms %children 0.49%
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 1.133ms self 0.085ms children 1.048ms %children 92.48%
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.174ms self 0.174ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-09 14:19:50 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-09 14:19:50 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:166, took 7.247264 s
2022-11-09 14:19:49 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compa037.hpc.in.bmrc.ox.ac.uk:40682 in memory (size: 7.4 KB, free: 413.7 MB)
2022-11-09 14:19:50 root: INFO: RegionPool: REPORT_THRESHOLD: 8.0M allocated (7.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:50 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.233ms self 0.233ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 root: INFO: RegionPool: REPORT_THRESHOLD: 8.0M allocated (7.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.485ms self 0.485ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-09 14:19:50 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-09 14:19:50 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-09 14:19:50 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 6.813ms self 6.813ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 Hail: INFO: wrote table with 274770 rows in 1 partition to data/ht/ukb_wes_450k.qced.chr18.ht
    Total size: 3.37 MiB
    * Rows: 3.37 MiB
    * Globals: 11.00 B
    * Smallest partition: 274770 rows (3.37 MiB)
    * Largest partition:  274770 rows (3.37 MiB)
2022-11-09 14:19:50 root: INFO: took 23.240s
2022-11-09 14:19:50 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 1: 
(Begin)
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.074ms self 0.074ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.199ms self 0.199ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.019ms self 0.019ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.096ms self 0.096ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.015ms self 0.015ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.018ms self 0.018ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-09 14:19:50 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-09 14:19:50 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-09 14:19:50 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 36.405ms self 36.405ms children 0.000ms %children 0.00%
2022-11-09 14:19:49 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 64.531ms self 0.107ms children 64.424ms %children 99.83%
2022-11-09 14:19:50 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Begin)
2022-11-09 14:19:50 root: INFO: finished execution of query hail_query_1
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON total 24.125s self 71.977ms children 24.053s %children 99.70%
2022-11-09 14:19:50 root: INFO: RegionPool: REPORT_THRESHOLD: 4.0M allocated (3.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 119.749ms self 0.684ms children 119.065ms %children 99.43%
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.316ms self 0.316ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 118.700ms self 66.575ms children 52.125ms %children 43.91%
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 52.125ms self 1.256ms children 50.869ms %children 97.59%
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 3.217ms self 3.217ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 4.865ms self 4.865ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 12.667ms self 12.667ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 9.334ms self 9.334ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-09 14:19:50 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compa023.hpc.in.bmrc.ox.ac.uk:38669 in memory (size: 7.4 KB, free: 413.7 MB)
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-09 14:19:50 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-09 14:19:50 root: INFO: RegionPool: REPORT_THRESHOLD: 32.0M allocated (31.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.081ms self 0.081ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-09 14:19:50 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:19:51 root: INFO: RegionPool: REPORT_THRESHOLD: 16.0M allocated (15.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 1.384ms self 1.384ms children 0.000ms %children 0.00%
2022-11-09 14:19:50 root: INFO: RegionPool: REPORT_THRESHOLD: 32.0M allocated (31.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:51 root: INFO: RegionPool: REPORT_THRESHOLD: 16.0M allocated (15.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:50 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 17.619ms self 17.619ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 68.446ms self 68.446ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-09 14:19:51 root: INFO: RegionPool: REPORT_THRESHOLD: 64.0M allocated (63.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.149ms self 0.149ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-09 14:19:50 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 6.310ms self 6.310ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.212ms self 0.212ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.085ms self 0.085ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.136ms self 0.136ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.230ms self 0.230ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-09 14:19:48 root: INFO: RegionPool: REPORT_THRESHOLD: 16.0M allocated (15.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 7.449ms self 7.449ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 916 bytes result sent to driver
2022-11-09 14:19:51 root: INFO: RegionPool: REPORT_THRESHOLD: 8.0M allocated (7.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:49 root: INFO: RegionPool: REPORT_THRESHOLD: 8.0M allocated (7.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.279ms self 0.279ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.024ms self 0.024ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.396ms self 0.396ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.090ms self 0.090ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-09 14:19:51 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 9527 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:51 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compe094.hpc.in.bmrc.ox.ac.uk:33393 in memory (size: 7.4 KB, free: 413.7 MB)
2022-11-09 14:19:51 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.140ms self 0.140ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 1.154ms self 1.154ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.012ms self 0.012ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-09 14:19:51 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:166) finished in 9.989 s
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.044ms self 0.044ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.218ms self 0.218ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.224ms self 0.224ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.061ms self 0.061ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:166, took 10.302682 s
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.019ms self 0.019ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 47.681ms self 47.681ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.253ms self 0.253ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.332ms self 0.332ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.049ms self 0.049ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 root: INFO: RegionPool: REPORT_THRESHOLD: 4.0M allocated (3.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.208ms self 0.208ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 7.364ms self 0.016ms children 7.347ms %children 99.78%
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.019ms self 0.019ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-09 14:19:51 Hail: INFO: wrote table with 813074 rows in 1 partition to data/ht/ukb_wes_450k.qced.chr7.ht
    Total size: 9.93 MiB
    * Rows: 9.93 MiB
    * Globals: 11.00 B
    * Smallest partition: 813074 rows (9.93 MiB)
    * Largest partition:  813074 rows (9.93 MiB)
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.128ms self 0.128ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.225ms self 0.225ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.005ms self 0.005ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 916 bytes result sent to driver
2022-11-09 14:19:51 root: INFO: took 25.774s
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-09 14:19:51 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.241ms self 0.241ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 7.240ms self 7.240ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.102ms self 0.102ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 454.195ms self 0.027ms children 454.167ms %children 99.99%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.020ms self 0.020ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 454.129ms self 210.829ms children 243.300ms %children 53.58%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 243.300ms self 0.111ms children 243.189ms %children 99.95%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 6.504ms self 6.504ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.205ms self 0.205ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 7.532ms self 7.532ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 1.119ms self 1.119ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.056ms self 0.056ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 226.235ms self 226.235ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.202ms self 0.202ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.130ms self 0.130ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.231ms self 0.231ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.275ms self 0.275ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.019ms self 0.019ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.228ms self 0.228ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.055ms self 0.055ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.024ms self 0.024ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.028ms self 0.028ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.171ms self 0.171ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.014ms self 0.014ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.160ms self 0.160ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.018ms self 0.018ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 23.243s self 0.020ms children 23.242s %children 100.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.010ms self 0.010ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 23.242s self 23.242s children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.377ms self 0.377ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 228.855ms self 0.022ms children 228.833ms %children 99.99%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.005ms self 0.005ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 228.814ms self 226.971ms children 1.843ms %children 0.81%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 1.843ms self 0.052ms children 1.791ms %children 97.18%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.111ms self 0.111ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.260ms self 0.260ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 1.119ms self 1.119ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.183ms self 0.183ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.097ms self 0.097ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.013ms self 0.013ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.016ms self 0.016ms children 0.000ms %children 0.00%
2022-11-09 14:19:51 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 9041 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:52 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 1: 
(Begin)
2022-11-09 14:19:52 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-09 14:19:52 root: INFO: RegionPool: REPORT_THRESHOLD: 32.0M allocated (31.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:52 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:166) finished in 10.001 s
2022-11-09 14:19:52 root: INFO: RegionPool: REPORT_THRESHOLD: 32.0M allocated (31.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:52 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:166, took 10.145305 s
2022-11-09 14:19:52 root: INFO: RegionPool: REPORT_THRESHOLD: 16.0M allocated (15.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:49 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 114.5 KB, free 411.5 MB)
2022-11-09 14:19:52 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compa026.hpc.in.bmrc.ox.ac.uk:45825 (size: 114.5 KB, free: 413.7 MB)
2022-11-09 14:19:52 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Begin)
2022-11-09 14:19:52 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-09 14:19:52 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-09 14:19:52 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-09 14:19:51 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.061ms self 0.061ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: RegionPool: REPORT_THRESHOLD: 32.0M allocated (31.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:52 root: INFO: RegionPool: REPORT_THRESHOLD: 8.0M allocated (7.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:52 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-09 14:19:52 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-09 14:19:52 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-09 14:19:52 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-09 14:19:52 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-09 14:19:52 root: INFO: RegionPool: REPORT_THRESHOLD: 16.0M allocated (15.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:52 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:19:52 root: INFO: finished execution of query hail_query_1
2022-11-09 14:19:52 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8058 bytes)
2022-11-09 14:19:52 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.271ms self 0.271ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 Hail: INFO: wrote table with 930371 rows in 1 partition to data/ht/ukb_wes_450k.qced.chr12.ht
    Total size: 11.42 MiB
    * Rows: 11.42 MiB
    * Globals: 11.00 B
    * Smallest partition: 930371 rows (11.42 MiB)
    * Largest partition:  930371 rows (11.42 MiB)
2022-11-09 14:19:52 AbstractConnector: INFO: Stopped Spark@deb6fc8{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:19:52 root: INFO: took 25.786s
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.019ms self 0.019ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON total 27.673s self 253.654ms children 27.419s %children 99.08%
2022-11-09 14:19:52 SparkUI: INFO: Stopped Spark web UI at http://compe070.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 14:19:52 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 1: 
(Begin)
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.029ms self 0.029ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 573.977ms self 0.901ms children 573.076ms %children 99.84%
2022-11-09 14:19:52 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 959 bytes result sent to driver
2022-11-09 14:19:52 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Begin)
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.191ms self 0.191ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.412ms self 0.412ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: finished execution of query hail_query_1
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.019ms self 0.019ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 6369 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 572.622ms self 476.816ms children 95.806ms %children 16.73%
2022-11-09 14:19:52 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.016ms self 0.016ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON total 27.363s self 578.405ms children 26.785s %children 97.89%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 95.806ms self 1.706ms children 94.100ms %children 98.22%
2022-11-09 14:19:52 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:166) finished in 8.833 s
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.216ms self 0.216ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 735.363ms self 0.807ms children 734.556ms %children 99.89%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.155ms self 0.155ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:166, took 10.010455 s
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 4.333ms self 4.333ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.371ms self 0.371ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 5.623ms self 5.623ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.020ms self 0.020ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.060ms self 0.060ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: RegionPool: REPORT_THRESHOLD: 64.0M allocated (63.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 734.140ms self 649.394ms children 84.746ms %children 11.54%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 16.464ms self 16.464ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 21.497s self 0.024ms children 21.497s %children 100.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 84.746ms self 1.797ms children 82.949ms %children 97.88%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 13.755ms self 13.755ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: RegionPool: REPORT_THRESHOLD: 64.0M allocated (63.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.011ms self 0.011ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 3.908ms self 3.908ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 1.694ms self 1.694ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 5.003ms self 5.003ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 21.497s self 21.497s children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 36.995ms self 36.995ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 14.781ms self 14.781ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.395ms self 0.395ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 Hail: INFO: wrote table with 424234 rows in 1 partition to data/ht/ukb_wes_450k.qced.chr22.ht
    Total size: 5.16 MiB
    * Rows: 5.16 MiB
    * Globals: 11.00 B
    * Smallest partition: 424234 rows (5.16 MiB)
    * Largest partition:  424234 rows (5.16 MiB)
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.188ms self 0.188ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: took 24.017s
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.112ms self 0.112ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 14.413ms self 14.413ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 916 bytes result sent to driver
2022-11-09 14:19:52 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 1: 
(Begin)
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.170ms self 0.170ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 14.931ms self 14.931ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.024ms self 0.024ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Begin)
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.362ms self 0.362ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: finished execution of query hail_query_1
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.028ms self 0.028ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON total 25.849s self 322.642ms children 25.527s %children 98.75%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 27.943ms self 27.943ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 4177 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.164ms self 0.164ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 555.862ms self 0.724ms children 555.137ms %children 99.87%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 239.246ms self 0.020ms children 239.226ms %children 99.99%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.498ms self 0.498ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.078ms self 0.078ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:166) finished in 4.850 s
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.147ms self 0.147ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.180ms self 0.180ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.097ms self 0.097ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.316ms self 0.316ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:166, took 5.051185 s
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.301ms self 0.301ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.005ms self 0.005ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.017ms self 0.017ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 554.784ms self 500.989ms children 53.795ms %children 9.70%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.051ms self 0.051ms children 0.000ms %children 0.00%
2022-11-09 14:19:52 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.015ms self 0.015ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 239.210ms self 238.209ms children 1.001ms %children 0.42%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.023ms self 0.023ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 53.795ms self 1.300ms children 52.496ms %children 97.58%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.276ms self 0.276ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 3.397ms self 3.397ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.024ms self 0.024ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 4.670ms self 4.670ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 13.415ms self 13.415ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 14.177ms self 14.177ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.439ms self 0.439ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.157ms self 0.157ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.093ms self 0.093ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.014ms self 0.014ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.051ms self 0.051ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.254ms self 0.254ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.382ms self 0.382ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.045ms self 0.045ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 8.200ms self 0.019ms children 8.181ms %children 99.77%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.009ms self 0.009ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 8.050ms self 8.050ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.122ms self 0.122ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 175.630ms self 0.028ms children 175.602ms %children 99.98%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 175.562ms self 59.889ms children 115.674ms %children 65.89%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 115.674ms self 0.129ms children 115.545ms %children 99.89%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 7.470ms self 7.470ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.238ms self 0.238ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 23.655ms self 23.655ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 1.225ms self 1.225ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.060ms self 0.060ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 81.055ms self 81.055ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.250ms self 0.250ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.147ms self 0.147ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.232ms self 0.232ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.335ms self 0.335ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.022ms self 0.022ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.261ms self 0.261ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.084ms self 0.084ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.024ms self 0.024ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.036ms self 0.036ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.225ms self 0.225ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.019ms self 0.019ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.206ms self 0.206ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.019ms self 0.019ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 25.804s self 0.025ms children 25.804s %children 100.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.011ms self 0.011ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 25.804s self 25.804s children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.502ms self 0.502ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 61.017ms self 0.021ms children 60.996ms %children 99.97%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.007ms self 0.007ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 60.977ms self 59.868ms children 1.109ms %children 1.82%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 1.109ms self 0.067ms children 1.042ms %children 93.92%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.179ms self 0.179ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.485ms self 0.485ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.068ms self 0.068ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.194ms self 0.194ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.019ms self 0.019ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.042ms self 0.042ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 8.818ms self 8.818ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: RegionPool: REPORT_THRESHOLD: 16.0M allocated (15.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 1.001ms self 0.079ms children 0.922ms %children 92.06%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.097ms self 0.097ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 916 bytes result sent to driver
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 23.477ms self 0.029ms children 23.449ms %children 99.88%
2022-11-09 14:19:53 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 6257 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:53 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-09 14:19:53 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:166) finished in 6.911 s
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.011ms self 0.011ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.012ms self 0.012ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 Hail: INFO: wrote table with 306387 rows in 1 partition to data/ht/ukb_wes_450k.qced.chr13.ht
    Total size: 3.76 MiB
    * Rows: 3.76 MiB
    * Globals: 11.00 B
    * Smallest partition: 306387 rows (3.76 MiB)
    * Largest partition:  306387 rows (3.76 MiB)
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 1.402ms self 1.402ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.005ms self 0.005ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 18.265ms self 18.265ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 959 bytes result sent to driver
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 21.867s self 0.019ms children 21.867s %children 100.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.025ms self 0.025ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: took 22.227s
2022-11-09 14:19:53 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:166, took 6.925031 s
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 9.171ms self 9.171ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.147ms self 0.147ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.148ms self 0.148ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.073ms self 0.073ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 1: 
(Begin)
2022-11-09 14:19:53 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 5201 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 14.273ms self 14.273ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.006ms self 0.006ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.141ms self 0.141ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Begin)
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.290ms self 0.290ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 593.265ms self 0.031ms children 593.234ms %children 99.99%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.024ms self 0.024ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.389ms self 0.389ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 593.127ms self 317.172ms children 275.955ms %children 46.53%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.082ms self 0.082ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 275.955ms self 0.142ms children 275.812ms %children 99.95%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.013ms self 0.013ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: finished execution of query hail_query_1
2022-11-09 14:19:53 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:166) finished in 5.536 s
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.421ms self 0.421ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 21.867s self 21.867s children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.390ms self 0.390ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.060ms self 0.060ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 959 bytes result sent to driver
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 8.854ms self 8.854ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.045ms self 0.045ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON total 24.956s self 432.378ms children 24.524s %children 98.27%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.222ms self 0.222ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 765.265ms self 0.951ms children 764.314ms %children 99.88%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.017ms self 0.017ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:166, took 6.479000 s
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.326ms self 0.326ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.262ms self 0.262ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.037ms self 0.037ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 13.586ms self 13.586ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.416ms self 0.416ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 763.789ms self 690.131ms children 73.658ms %children 9.64%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 73.658ms self 1.762ms children 71.896ms %children 97.61%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 4.112ms self 4.112ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 6.122ms self 6.122ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 17.976ms self 17.976ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 15.770ms self 15.770ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 1.817ms self 1.817ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 23.795ms self 23.795ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.178ms self 0.178ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.097ms self 0.097ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.202ms self 0.202ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.384ms self 0.384ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.026ms self 0.026ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.459ms self 0.459ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.112ms self 0.112ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.073ms self 0.073ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.066ms self 0.066ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.280ms self 0.280ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.026ms self 0.026ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.402ms self 0.402ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.109ms self 0.109ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 11.092ms self 0.024ms children 11.067ms %children 99.78%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.006ms self 0.006ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 10.859ms self 10.859ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.203ms self 0.203ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 1.430s self 0.034ms children 1.430s %children 100.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.024ms self 0.024ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 1.430s self 718.364ms children 711.726ms %children 49.77%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 711.726ms self 0.173ms children 711.554ms %children 99.98%
2022-11-09 14:19:53 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 959 bytes result sent to driver
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 222.791ms self 0.021ms children 222.770ms %children 99.99%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 7.890ms self 0.019ms children 7.871ms %children 99.77%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 1.437ms self 1.437ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.005ms self 0.005ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.074ms self 0.074ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 7.740ms self 7.740ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 5990 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 8.612ms self 8.612ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.173ms self 0.173ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 5475 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 249.561ms self 249.561ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-09 14:19:53 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.266ms self 0.266ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:166) finished in 6.546 s
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.126ms self 0.126ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.275ms self 0.275ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 896.692ms self 0.033ms children 896.660ms %children 100.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.178ms self 0.178ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:166, took 8.534807 s
2022-11-09 14:19:53 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:166) finished in 5.764 s
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.006ms self 0.006ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 12.292ms self 12.292ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.289ms self 0.289ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 1.419ms self 1.419ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.360ms self 0.360ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:166, took 5.898809 s
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.019ms self 0.019ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 896.574ms self 603.828ms children 292.746ms %children 32.65%
2022-11-09 14:19:53 Hail: INFO: wrote table with 907305 rows in 1 partition to data/ht/ukb_wes_450k.qced.chr16.ht
    Total size: 10.97 MiB
    * Rows: 10.97 MiB
    * Globals: 11.00 B
    * Smallest partition: 907305 rows (10.97 MiB)
    * Largest partition:  907305 rows (10.97 MiB)
2022-11-09 14:19:53 root: INFO: took 19.721s
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.067ms self 0.067ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.022ms self 0.022ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 682.621ms self 682.621ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.296ms self 0.296ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:19:53 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 1: 
(Begin)
2022-11-09 14:19:53 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Begin)
2022-11-09 14:19:53 root: INFO: finished execution of query hail_query_1
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON total 20.474s self 80.575ms children 20.393s %children 99.61%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 314.872ms self 0.882ms children 313.990ms %children 99.72%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.428ms self 0.428ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 313.515ms self 205.595ms children 107.920ms %children 34.42%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 107.920ms self 2.159ms children 105.760ms %children 98.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 4.040ms self 4.040ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 6.132ms self 6.132ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 23.627ms self 23.627ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 28.736ms self 28.736ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 1.843ms self 1.843ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 36.583ms self 36.583ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.297ms self 0.297ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.424ms self 0.424ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.210ms self 0.210ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.624ms self 0.624ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.027ms self 0.027ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.917ms self 0.917ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.335ms self 0.335ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.025ms self 0.025ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.073ms self 0.073ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.354ms self 0.354ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.026ms self 0.026ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 1.487ms self 1.487ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.047ms self 0.047ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 10.055ms self 0.023ms children 10.032ms %children 99.77%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.006ms self 0.006ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 9.887ms self 9.887ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.139ms self 0.139ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 278.668ms self 0.023ms children 278.645ms %children 99.99%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.030ms self 0.030ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 278.567ms self 163.261ms children 115.306ms %children 41.39%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 115.306ms self 0.141ms children 115.165ms %children 99.88%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 9.471ms self 9.471ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.249ms self 0.249ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 19.403ms self 19.403ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 4.073ms self 4.073ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.091ms self 0.091ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 79.833ms self 79.833ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.245ms self 0.245ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.166ms self 0.166ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.280ms self 0.280ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.388ms self 0.388ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.025ms self 0.025ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.298ms self 0.298ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 222.752ms self 221.783ms children 0.969ms %children 0.44%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 292.746ms self 0.115ms children 292.631ms %children 99.96%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.291ms self 0.291ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.084ms self 0.084ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 Hail: INFO: wrote table with 676921 rows in 1 partition to data/ht/ukb_wes_450k.qced.chr4.ht
    Total size: 8.31 MiB
    * Rows: 8.31 MiB
    * Globals: 11.00 B
    * Smallest partition: 676921 rows (8.31 MiB)
    * Largest partition:  676921 rows (8.31 MiB)
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.040ms self 0.040ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.089ms self 0.089ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.026ms self 0.026ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.045ms self 0.045ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.266ms self 0.266ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.018ms self 0.018ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.200ms self 0.200ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.047ms self 0.047ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 19.724s self 0.023ms children 19.724s %children 100.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.023ms self 0.023ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 19.723s self 19.723s children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.480ms self 0.480ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 66.050ms self 0.014ms children 66.036ms %children 99.98%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.007ms self 0.007ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 66.019ms self 64.721ms children 1.298ms %children 1.97%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 1.298ms self 0.080ms children 1.218ms %children 93.81%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.225ms self 0.225ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.542ms self 0.542ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.089ms self 0.089ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.240ms self 0.240ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.025ms self 0.025ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.098ms self 0.098ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.011ms self 0.011ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.022ms self 0.022ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.102ms self 0.102ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 0.969ms self 0.057ms children 0.913ms %children 94.14%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 6.944ms self 6.944ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.163ms self 0.163ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 2.791ms self 2.791ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.219ms self 0.219ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: took 26.720s
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 10.606ms self 10.606ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.011ms self 0.011ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 AbstractConnector: INFO: Stopped Spark@56104b1c{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.599ms self 0.599ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.039ms self 0.039ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 Hail: INFO: wrote table with 388613 rows in 1 partition to data/ht/ukb_wes_450k.qced.chrX.ht
    Total size: 4.84 MiB
    * Rows: 4.84 MiB
    * Globals: 11.00 B
    * Smallest partition: 388613 rows (4.84 MiB)
    * Largest partition:  388613 rows (4.84 MiB)
2022-11-09 14:19:53 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 1: 
(Begin)
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 1.169ms self 1.169ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.152ms self 0.152ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.055ms self 0.055ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.238ms self 0.238ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 271.865ms self 271.865ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.026ms self 0.026ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.024ms self 0.024ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: took 23.701s
2022-11-09 14:19:53 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Begin)
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.208ms self 0.208ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.161ms self 0.161ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.245ms self 0.245ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.312ms self 0.312ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.020ms self 0.020ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.277ms self 0.277ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.076ms self 0.076ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.024ms self 0.024ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.196ms self 0.196ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.045ms self 0.045ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.404ms self 0.404ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 1: 
(Begin)
2022-11-09 14:19:53 root: INFO: finished execution of query hail_query_1
2022-11-09 14:19:53 root: INFO: RegionPool: REPORT_THRESHOLD: 4.0M allocated (3.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:53 Hail: INFO: wrote table with 692610 rows in 1 partition to data/ht/ukb_wes_450k.qced.chr10.ht
    Total size: 8.48 MiB
    * Rows: 8.48 MiB
    * Globals: 11.00 B
    * Smallest partition: 692610 rows (8.48 MiB)
    * Largest partition:  692610 rows (8.48 MiB)
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.311ms self 0.311ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: took 27.485s
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.219ms self 0.219ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.059ms self 0.059ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON total 27.327s self 142.103ms children 27.185s %children 99.48%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.172ms self 0.172ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.083ms self 0.083ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.105ms self 0.105ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 25.872s self 0.022ms children 25.872s %children 100.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.016ms self 0.016ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Begin)
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 253.443ms self 1.664ms children 251.779ms %children 99.34%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.030ms self 0.030ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 1: 
(Begin)
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.031ms self 0.031ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.044ms self 0.044ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 1.563ms self 1.563ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.034ms self 0.034ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.319ms self 0.319ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.024ms self 0.024ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 22.251s self 0.030ms children 22.251s %children 100.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.010ms self 0.010ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 22.250s self 22.250s children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.614ms self 0.614ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 66.369ms self 0.024ms children 66.345ms %children 99.96%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.008ms self 0.008ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 66.323ms self 65.008ms children 1.315ms %children 1.98%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 1.315ms self 0.082ms children 1.233ms %children 93.77%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.009ms self 0.009ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.170ms self 0.170ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: finished execution of query hail_query_1
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.401ms self 0.401ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.096ms self 0.096ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Begin)
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 25.871s self 25.871s children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.183ms self 0.183ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.065ms self 0.065ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 251.332ms self 157.998ms children 93.335ms %children 37.14%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON total 26.399s self 317.357ms children 26.082s %children 98.80%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 93.335ms self 2.034ms children 91.300ms %children 97.82%
2022-11-09 14:19:53 root: INFO: finished execution of query hail_query_1
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.524ms self 0.524ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON total 28.872s self 265.717ms children 28.606s %children 99.08%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 24.034s self 0.020ms children 24.034s %children 100.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.012ms self 0.012ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 4.027ms self 4.027ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.593ms self 0.593ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 6.719ms self 6.719ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 356.830ms self 0.024ms children 356.806ms %children 99.99%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 727.163ms self 0.838ms children 726.325ms %children 99.88%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.009ms self 0.009ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.018ms self 0.018ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 844.797ms self 1.785ms children 843.011ms %children 99.79%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.078ms self 0.078ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.630ms self 0.630ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.007ms self 0.007ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 842.320ms self 683.346ms children 158.973ms %children 18.87%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 24.034s self 24.034s children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 18.482ms self 18.482ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.243ms self 0.243ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 12.716ms self 12.716ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 356.785ms self 355.497ms children 1.287ms %children 0.36%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 158.973ms self 2.621ms children 156.352ms %children 98.35%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.383ms self 0.383ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.360ms self 0.360ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.024ms self 0.024ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 1.867ms self 1.867ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 1.287ms self 0.102ms children 1.185ms %children 92.04%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 42.969ms self 42.969ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.208ms self 0.208ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.322ms self 0.322ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.112ms self 0.112ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 26.410ms self 26.410ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 32.074ms self 0.025ms children 32.049ms %children 99.92%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 725.907ms self 648.805ms children 77.102ms %children 10.62%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.561ms self 0.561ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 77.102ms self 1.928ms children 75.174ms %children 97.50%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.015ms self 0.015ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 20.975ms self 20.975ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.020ms self 0.020ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 33.836ms self 33.836ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.094ms self 0.094ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 16.149ms self 16.149ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.205ms self 0.205ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.165ms self 0.165ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: RegionPool: REPORT_THRESHOLD: 32.0M allocated (31.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 4.795ms self 4.795ms children 0.000ms %children 0.00%
2022-11-09 14:19:53 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.006ms self 0.006ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 1.926ms self 1.926ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.020ms self 0.020ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 41.926ms self 41.926ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 6.593ms self 6.593ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 32.022ms self 31.030ms children 0.992ms %children 3.10%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.208ms self 0.208ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.098ms self 0.098ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 19.205ms self 19.205ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.014ms self 0.014ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 13.068ms self 13.068ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.622ms self 0.622ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 3.226ms self 3.226ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.295ms self 0.295ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.024ms self 0.024ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 0.992ms self 0.082ms children 0.910ms %children 91.70%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.032ms self 0.032ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 25.792ms self 25.792ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.106ms self 0.106ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.143ms self 0.143ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 1.107ms self 1.107ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.399ms self 0.399ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.060ms self 0.060ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.189ms self 0.189ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.019ms self 0.019ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.099ms self 0.099ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.015ms self 0.015ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.210ms self 0.210ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.184ms self 0.184ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.343ms self 0.343ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.109ms self 0.109ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.185ms self 0.185ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.441ms self 0.441ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 AbstractConnector: INFO: Stopped Spark@18ab7669{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.751ms self 0.751ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.023ms self 0.023ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.027ms self 0.027ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.534ms self 0.534ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.113ms self 0.113ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 SparkUI: INFO: Stopped Spark web UI at http://compa030.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.027ms self 0.027ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.071ms self 0.071ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.018ms self 0.018ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.725ms self 0.725ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.366ms self 0.366ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.062ms self 0.062ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.282ms self 0.282ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.025ms self 0.025ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.327ms self 0.327ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 AbstractConnector: INFO: Stopped Spark@7742710{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.065ms self 0.065ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 MemoryStore: INFO: MemoryStore cleared
2022-11-09 14:19:54 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.024ms self 0.024ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 1.237ms self 1.237ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.444ms self 0.444ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 SparkUI: INFO: Stopped Spark web UI at http://compa036.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.305ms self 0.305ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.045ms self 0.045ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.058ms self 0.058ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 AbstractConnector: INFO: Stopped Spark@7ca191fd{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:19:54 root: INFO: RegionPool: REPORT_THRESHOLD: 8.0M allocated (7.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.027ms self 0.027ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 12.345ms self 12.345ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.062ms self 0.062ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 24.833ms self 0.053ms children 24.780ms %children 99.79%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.020ms self 0.020ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 24.563ms self 24.563ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.197ms self 0.197ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 1.392s self 0.035ms children 1.392s %children 100.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.040ms self 0.040ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 1.392s self 778.358ms children 613.682ms %children 44.09%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 613.682ms self 0.466ms children 613.216ms %children 99.92%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 16.594ms self 16.594ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.862ms self 0.862ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 20.640ms self 20.640ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 4.749ms self 4.749ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.102ms self 0.102ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 561.669ms self 561.669ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.871ms self 0.871ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.372ms self 0.372ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.532ms self 0.532ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 2.029ms self 2.029ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.041ms self 0.041ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 1.497ms self 1.497ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.143ms self 0.143ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.049ms self 0.049ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.799ms self 0.799ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 1.808ms self 1.808ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.052ms self 0.052ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 11.375ms self 0.026ms children 11.348ms %children 99.77%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 9.381ms self 0.020ms children 9.361ms %children 99.79%
2022-11-09 14:19:54 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.006ms self 0.006ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.408ms self 0.408ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.006ms self 0.006ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 SparkUI: INFO: Stopped Spark web UI at http://compf004.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 9.234ms self 9.234ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: RegionPool: FREE: 24.0M allocated (24.0M blocks / 0 chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.122ms self 0.122ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 11.180ms self 11.180ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 323.020ms self 0.031ms children 322.988ms %children 99.99%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.049ms self 0.049ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.162ms self 0.162ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.027ms self 0.027ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 AbstractConnector: INFO: Stopped Spark@37ef3dbf{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 322.938ms self 211.208ms children 111.730ms %children 34.60%
2022-11-09 14:19:54 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 960 bytes result sent to driver
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 23.730s self 0.022ms children 23.730s %children 100.00%
2022-11-09 14:19:54 MemoryStore: INFO: MemoryStore cleared
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 99.815ms self 0.043ms children 99.773ms %children 99.96%
2022-11-09 14:19:54 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 14:19:54 SparkUI: INFO: Stopped Spark web UI at http://compa043.hpc.in.bmrc.ox.ac.uk:4041
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.011ms self 0.011ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 7166 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:54 BlockManager: INFO: BlockManager stopped
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.026ms self 0.026ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 111.730ms self 0.133ms children 111.597ms %children 99.88%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 23.729s self 23.729s children 0.000ms %children 0.00%
2022-11-09 14:19:54 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-09 14:19:54 BlockManagerMaster: INFO: BlockManagerMaster stopped
2022-11-09 14:19:54 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:166) finished in 7.604 s
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 8.668ms self 8.668ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.377ms self 0.377ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 99.663ms self 49.432ms children 50.231ms %children 50.40%
2022-11-09 14:19:54 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 50.231ms self 0.145ms children 50.087ms %children 99.71%
2022-11-09 14:19:54 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:166, took 7.823501 s
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.300ms self 0.300ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 90.343ms self 0.030ms children 90.312ms %children 99.97%
2022-11-09 14:19:54 OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: INFO: OutputCommitCoordinator stopped!
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.006ms self 0.006ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 8.219ms self 8.219ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 9.070ms self 9.070ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 1.346ms self 1.346ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 90.272ms self 88.511ms children 1.762ms %children 1.95%
2022-11-09 14:19:54 SparkContext: INFO: Successfully stopped SparkContext
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 1.762ms self 0.133ms children 1.629ms %children 92.47%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.300ms self 0.300ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.061ms self 0.061ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 16.549ms self 16.549ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 91.182ms self 91.182ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 MemoryStore: INFO: MemoryStore cleared
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.153ms self 0.153ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 1.684ms self 1.684ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.783ms self 0.783ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.106ms self 0.106ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.253ms self 0.253ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 BlockManager: INFO: BlockManager stopped
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.154ms self 0.154ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 20.400ms self 20.400ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.252ms self 0.252ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 BlockManagerMaster: INFO: BlockManagerMaster stopped
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.305ms self 0.305ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.260ms self 0.260ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.117ms self 0.117ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.027ms self 0.027ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.166ms self 0.166ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.259ms self 0.259ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.325ms self 0.325ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.078ms self 0.078ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.281ms self 0.281ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.029ms self 0.029ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.046ms self 0.046ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.035ms self 0.035ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.369ms self 0.369ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.233ms self 0.233ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 959 bytes result sent to driver
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.204ms self 0.204ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.024ms self 0.024ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.034ms self 0.034ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.269ms self 0.269ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.032ms self 0.032ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.088ms self 0.088ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.018ms self 0.018ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.029ms self 0.029ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.175ms self 0.175ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 6763 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.024ms self 0.024ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.038ms self 0.038ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 27.494s self 0.031ms children 27.494s %children 100.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.251ms self 0.251ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.008ms self 0.008ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 27.493s self 27.493s children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.020ms self 0.020ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 Hail: INFO: wrote table with 1311552 rows in 1 partition to data/ht/ukb_wes_450k.qced.chr19.ht
    Total size: 15.97 MiB
    * Rows: 15.97 MiB
    * Globals: 11.00 B
    * Smallest partition: 1311552 rows (15.97 MiB)
    * Largest partition:  1311552 rows (15.97 MiB)
2022-11-09 14:19:54 root: INFO: took 21.848s
2022-11-09 14:19:54 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:166) finished in 7.169 s
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.601ms self 0.601ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.183ms self 0.183ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 52.344ms self 0.025ms children 52.319ms %children 99.95%
2022-11-09 14:19:54 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:166, took 7.463943 s
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.008ms self 0.008ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.083ms self 0.083ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 52.282ms self 50.829ms children 1.453ms %children 2.78%
2022-11-09 14:19:54 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 1: 
(Begin)
2022-11-09 14:19:54 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Begin)
2022-11-09 14:19:54 root: INFO: finished execution of query hail_query_1
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 26.771s self 0.047ms children 26.771s %children 100.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 1.453ms self 0.070ms children 1.383ms %children 95.18%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON total 22.749s self 231.745ms children 22.517s %children 98.98%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 320.684ms self 1.114ms children 319.570ms %children 99.65%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 1.462ms self 1.462ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 318.038ms self 249.737ms children 68.301ms %children 21.48%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 68.301ms self 2.357ms children 65.944ms %children 96.55%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 7.774ms self 7.774ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 8.325ms self 8.325ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 16.677ms self 16.677ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 10.534ms self 10.534ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 1.584ms self 1.584ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 18.950ms self 18.950ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.010ms self 0.010ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.222ms self 0.222ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.174ms self 0.174ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.082ms self 0.082ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.154ms self 0.154ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.339ms self 0.339ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.443ms self 0.443ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.098ms self 0.098ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.015ms self 0.015ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.053ms self 0.053ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.263ms self 0.263ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.020ms self 0.020ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.436ms self 0.436ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.070ms self 0.070ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 16.823ms self 0.025ms children 16.798ms %children 99.85%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.014ms self 0.014ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 16.671ms self 16.671ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.113ms self 0.113ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 289.349ms self 0.035ms children 289.314ms %children 99.99%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.020ms self 0.020ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 289.247ms self 153.454ms children 135.793ms %children 46.95%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 135.793ms self 0.229ms children 135.564ms %children 99.83%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 16.079ms self 16.079ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.614ms self 0.614ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 26.771s self 26.771s children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.129ms self 0.129ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.273ms self 0.273ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.029ms self 0.029ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.116ms self 0.116ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.029ms self 0.029ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.025ms self 0.025ms children 0.000ms %children 0.00%
2022-11-09 14:19:54 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.298ms self 0.298ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 9.052ms self 9.052ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 1.283ms self 1.283ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.063ms self 0.063ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 104.487ms self 104.487ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.579ms self 0.579ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.420ms self 0.420ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.685ms self 0.685ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.674ms self 0.674ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.047ms self 0.047ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.573ms self 0.573ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.178ms self 0.178ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.053ms self 0.053ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.542ms self 0.542ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 48.833ms self 0.038ms children 48.795ms %children 99.92%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.009ms self 0.009ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 48.754ms self 47.263ms children 1.491ms %children 3.06%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 1.491ms self 0.151ms children 1.341ms %children 89.89%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.215ms self 0.215ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.624ms self 0.624ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.093ms self 0.093ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.090ms self 0.090ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.490ms self 0.490ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.040ms self 0.040ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.472ms self 0.472ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.047ms self 0.047ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 21.852s self 0.026ms children 21.852s %children 100.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.014ms self 0.014ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 21.852s self 21.852s children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.467ms self 0.467ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 37.681ms self 0.018ms children 37.664ms %children 99.95%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.006ms self 0.006ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 37.646ms self 35.980ms children 1.666ms %children 4.43%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 1.666ms self 0.096ms children 1.570ms %children 94.22%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.245ms self 0.245ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.721ms self 0.721ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.129ms self 0.129ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.278ms self 0.278ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.034ms self 0.034ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.163ms self 0.163ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.011ms self 0.011ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.031ms self 0.031ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.264ms self 0.264ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 AbstractConnector: INFO: Stopped Spark@18ab7669{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.026ms self 0.026ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.118ms self 0.118ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.032ms self 0.032ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 SparkUI: INFO: Stopped Spark web UI at http://compe094.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 14:19:55 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 14:19:55 MemoryStore: INFO: MemoryStore cleared
2022-11-09 14:19:55 BlockManager: INFO: BlockManager stopped
2022-11-09 14:19:55 BlockManagerMaster: INFO: BlockManagerMaster stopped
2022-11-09 14:19:55 OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: INFO: OutputCommitCoordinator stopped!
2022-11-09 14:19:55 SparkContext: INFO: Successfully stopped SparkContext
2022-11-09 14:19:55 ShutdownHookManager: INFO: Shutdown hook called
2022-11-09 14:19:55 ShutdownHookManager: INFO: Deleting directory /tmp/spark-befa8f15-80e2-4c84-8f82-88be437d1255/pyspark-bcc76f0b-61ce-4d3b-95e4-a4a0a749a0d9
2022-11-09 14:19:55 ShutdownHookManager: INFO: Deleting directory /tmp/spark-d04006e5-2a6c-45af-94f9-4dcdae683c4a
2022-11-09 14:19:55 ShutdownHookManager: INFO: Deleting directory /tmp/spark-befa8f15-80e2-4c84-8f82-88be437d1255
2022-11-09 14:19:55 Hail: INFO: wrote table with 561200 rows in 1 partition to data/ht/ukb_wes_450k.qced.chr14.ht
    Total size: 6.88 MiB
    * Rows: 6.88 MiB
    * Globals: 11.00 B
    * Smallest partition: 561200 rows (6.88 MiB)
    * Largest partition:  561200 rows (6.88 MiB)
2022-11-09 14:19:55 root: INFO: took 23.045s
2022-11-09 14:19:55 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 1: 
(Begin)
2022-11-09 14:19:55 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Begin)
2022-11-09 14:19:55 root: INFO: finished execution of query hail_query_1
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON total 24.831s self 196.237ms children 24.635s %children 99.21%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 659.878ms self 1.011ms children 658.867ms %children 99.85%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.396ms self 0.396ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 658.416ms self 587.317ms children 71.099ms %children 10.80%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 71.099ms self 1.719ms children 69.381ms %children 97.58%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 4.028ms self 4.028ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 7.016ms self 7.016ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 17.430ms self 17.430ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 13.071ms self 13.071ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 1.923ms self 1.923ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 23.409ms self 23.409ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.200ms self 0.200ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.103ms self 0.103ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.200ms self 0.200ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.408ms self 0.408ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.029ms self 0.029ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.560ms self 0.560ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.110ms self 0.110ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.018ms self 0.018ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.072ms self 0.072ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.331ms self 0.331ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.024ms self 0.024ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.450ms self 0.450ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.055ms self 0.055ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 10.939ms self 0.025ms children 10.914ms %children 99.77%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.007ms self 0.007ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 10.761ms self 10.761ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.146ms self 0.146ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 911.808ms self 0.050ms children 911.758ms %children 99.99%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.027ms self 0.027ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 911.695ms self 601.312ms children 310.384ms %children 34.04%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 310.384ms self 0.175ms children 310.209ms %children 99.94%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 8.799ms self 8.799ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.274ms self 0.274ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 11.657ms self 11.657ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 1.613ms self 1.613ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.086ms self 0.086ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 284.005ms self 284.005ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.251ms self 0.251ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.160ms self 0.160ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.261ms self 0.261ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 1.946ms self 1.946ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.030ms self 0.030ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.389ms self 0.389ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.117ms self 0.117ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.030ms self 0.030ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.055ms self 0.055ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.278ms self 0.278ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.024ms self 0.024ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.234ms self 0.234ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.036ms self 0.036ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 23.048s self 0.027ms children 23.048s %children 100.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.018ms self 0.018ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 23.048s self 23.048s children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.568ms self 0.568ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 3.727ms self 0.013ms children 3.714ms %children 99.64%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.009ms self 0.009ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 3.693ms self 0.925ms children 2.768ms %children 74.95%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 2.768ms self 0.085ms children 2.683ms %children 96.94%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.143ms self 0.143ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 2.018ms self 2.018ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.133ms self 0.133ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.259ms self 0.259ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.022ms self 0.022ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.108ms self 0.108ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.012ms self 0.012ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.018ms self 0.018ms children 0.000ms %children 0.00%
2022-11-09 14:19:55 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:19:55 AbstractConnector: INFO: Stopped Spark@47ec85a4{HTTP/1.1,[http/1.1]}{0.0.0.0:4041}
2022-11-09 14:19:55 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:19:55 SparkUI: INFO: Stopped Spark web UI at http://compa023.hpc.in.bmrc.ox.ac.uk:4041
2022-11-09 14:19:55 AbstractConnector: INFO: Stopped Spark@7052f7e2{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:19:55 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 14:19:55 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:19:55 SparkUI: INFO: Stopped Spark web UI at http://compe074.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 14:19:55 MemoryStore: INFO: MemoryStore cleared
2022-11-09 14:19:55 AbstractConnector: INFO: Stopped Spark@4cb1453e{HTTP/1.1,[http/1.1]}{0.0.0.0:4042}
2022-11-09 14:19:55 root: INFO: RegionPool: REPORT_THRESHOLD: 16.0M allocated (15.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:55 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 14:19:55 BlockManager: INFO: BlockManager stopped
2022-11-09 14:19:55 SparkUI: INFO: Stopped Spark web UI at http://compa040.hpc.in.bmrc.ox.ac.uk:4042
2022-11-09 14:19:55 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 14:19:55 MemoryStore: INFO: MemoryStore cleared
2022-11-09 14:19:55 BlockManager: INFO: BlockManager stopped
2022-11-09 14:19:55 BlockManagerMaster: INFO: BlockManagerMaster stopped
2022-11-09 14:19:55 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:19:55 OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: INFO: OutputCommitCoordinator stopped!
2022-11-09 14:19:55 AbstractConnector: INFO: Stopped Spark@73937ff9{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:19:55 SparkUI: INFO: Stopped Spark web UI at http://compa037.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 14:19:55 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 14:19:55 MemoryStore: INFO: MemoryStore cleared
2022-11-09 14:19:55 BlockManager: INFO: BlockManager stopped
2022-11-09 14:19:55 BlockManagerMaster: INFO: BlockManagerMaster stopped
2022-11-09 14:19:55 OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: INFO: OutputCommitCoordinator stopped!
2022-11-09 14:19:55 SparkContext: INFO: Successfully stopped SparkContext
2022-11-09 14:19:55 ShutdownHookManager: INFO: Shutdown hook called
2022-11-09 14:19:55 ShutdownHookManager: INFO: Deleting directory /tmp/spark-d8f4df06-23b6-4691-860f-e2cd99a9f098/pyspark-8a9c05bb-ea0f-4f19-b481-ca9c749eb6d5
2022-11-09 14:19:55 ShutdownHookManager: INFO: Deleting directory /tmp/spark-97d6a241-d7dc-4f57-a0ed-3bebcae0e179
2022-11-09 14:19:55 ShutdownHookManager: INFO: Deleting directory /tmp/spark-d8f4df06-23b6-4691-860f-e2cd99a9f098
2022-11-09 14:19:56 root: INFO: RegionPool: REPORT_THRESHOLD: 32.0M allocated (31.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-09 14:19:57 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 916 bytes result sent to driver
2022-11-09 14:19:57 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 5100 ms on localhost (executor driver) (1/1)
2022-11-09 14:19:57 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:166) finished in 8.664 s
2022-11-09 14:19:57 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:166, took 9.044833 s
2022-11-09 14:19:57 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-09 14:19:57 Hail: INFO: wrote table with 606085 rows in 1 partition to data/ht/ukb_wes_450k.qced.chr15.ht
    Total size: 7.41 MiB
    * Rows: 7.41 MiB
    * Globals: 11.00 B
    * Smallest partition: 606085 rows (7.41 MiB)
    * Largest partition:  606085 rows (7.41 MiB)
2022-11-09 14:19:57 root: INFO: took 23.932s
2022-11-09 14:19:57 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 1: 
(Begin)
2022-11-09 14:19:57 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Begin)
2022-11-09 14:19:57 root: INFO: finished execution of query hail_query_1
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON total 24.687s self 126.243ms children 24.561s %children 99.49%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 239.049ms self 0.984ms children 238.066ms %children 99.59%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.441ms self 0.441ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 237.552ms self 133.591ms children 103.961ms %children 43.76%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 103.961ms self 2.517ms children 101.444ms %children 97.58%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 4.709ms self 4.709ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 7.440ms self 7.440ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 19.253ms self 19.253ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 15.669ms self 15.669ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 13.114ms self 13.114ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 38.638ms self 38.638ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.250ms self 0.250ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.146ms self 0.146ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.215ms self 0.215ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.418ms self 0.418ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.026ms self 0.026ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.573ms self 0.573ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.134ms self 0.134ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.016ms self 0.016ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.072ms self 0.072ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.325ms self 0.325ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.025ms self 0.025ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.419ms self 0.419ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.073ms self 0.073ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 13.410ms self 0.024ms children 13.387ms %children 99.82%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.006ms self 0.006ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 13.226ms self 13.226ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.154ms self 0.154ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 370.060ms self 0.092ms children 369.968ms %children 99.98%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.028ms self 0.028ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 369.906ms self 188.955ms children 180.951ms %children 48.92%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 180.951ms self 2.673ms children 178.278ms %children 98.52%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 9.373ms self 9.373ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.285ms self 0.285ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 13.406ms self 13.406ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 1.724ms self 1.724ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.073ms self 0.073ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 150.589ms self 150.589ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.298ms self 0.298ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.178ms self 0.178ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.296ms self 0.296ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.472ms self 0.472ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.029ms self 0.029ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.316ms self 0.316ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.233ms self 0.233ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.081ms self 0.081ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.096ms self 0.096ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.447ms self 0.447ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.027ms self 0.027ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.355ms self 0.355ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.034ms self 0.034ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 23.936s self 0.023ms children 23.936s %children 100.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.014ms self 0.014ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 23.936s self 23.936s children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.410ms self 0.410ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 1.844ms self 0.014ms children 1.830ms %children 99.26%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.008ms self 0.008ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 1.811ms self 0.809ms children 1.002ms %children 55.35%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 1.002ms self 0.059ms children 0.944ms %children 94.16%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.141ms self 0.141ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.324ms self 0.324ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.070ms self 0.070ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.253ms self 0.253ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.029ms self 0.029ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.126ms self 0.126ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.012ms self 0.012ms children 0.000ms %children 0.00%
2022-11-09 14:19:57 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.024ms self 0.024ms children 0.000ms %children 0.00%
2022-11-09 14:19:58 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-09 14:19:58 AbstractConnector: INFO: Stopped Spark@409b2f27{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-09 14:19:58 SparkUI: INFO: Stopped Spark web UI at http://compa026.hpc.in.bmrc.ox.ac.uk:4040
2022-11-09 14:19:58 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-09 14:19:58 MemoryStore: INFO: MemoryStore cleared
2022-11-09 14:19:58 BlockManager: INFO: BlockManager stopped
2022-11-09 14:19:58 BlockManagerMaster: INFO: BlockManagerMaster stopped
2022-11-09 14:19:58 OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: INFO: OutputCommitCoordinator stopped!
2022-11-09 14:19:58 SparkContext: INFO: Successfully stopped SparkContext
2022-11-09 14:19:58 ShutdownHookManager: INFO: Shutdown hook called
2022-11-09 14:19:58 ShutdownHookManager: INFO: Deleting directory /tmp/spark-089143dd-1126-4055-8f98-4f39f4dd3d5e
2022-11-09 14:19:58 ShutdownHookManager: INFO: Deleting directory /tmp/spark-089143dd-1126-4055-8f98-4f39f4dd3d5e/pyspark-1327dedb-6114-4928-800a-fa59ae897c56
2022-11-09 14:19:58 ShutdownHookManager: INFO: Deleting directory /tmp/spark-5d27a87e-bc8d-43b9-a6ee-2be3c0ca81df
2022-11-10 10:41:00 Hail: INFO: Running Hail version 0.2.61-3c86d3ba497a
2022-11-10 10:41:02 SparkContext: WARN: Using an existing SparkContext; some configuration may not take effect.
2022-11-10 10:41:02 root: INFO: RegionPool: initialized for thread 15: Thread-5
2022-11-10 10:41:03 MemoryStore: INFO: Block broadcast_0 stored as values in memory (estimated size 237.3 KB, free 413.7 MB)
2022-11-10 10:41:03 MemoryStore: INFO: Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.0 KB, free 413.7 MB)
2022-11-10 10:41:03 BlockManagerInfo: INFO: Added broadcast_0_piece0 in memory on compe044.hpc.in.bmrc.ox.ac.uk:41238 (size: 23.0 KB, free: 413.9 MB)
2022-11-10 10:41:03 SparkContext: INFO: Created broadcast 0 from broadcast at SparkBackend.scala:250
2022-11-10 10:41:04 root: INFO: globbing path data/vcf/ukb_wes_450k.qced.sites_only.chr9.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr9.vcf.bgz
2022-11-10 10:41:04 root: INFO: globbing path file:/gpfs3/well/lindgren-ukbb/projects/ukbb-11867/nbaya/ukb_wes_450k_gwas/data/vcf/ukb_wes_450k.qced.sites_only.chr9.vcf.bgz returned 1 files: ukb_wes_450k.qced.sites_only.chr9.vcf.bgz
2022-11-10 10:41:04 MemoryStore: INFO: Block broadcast_1 stored as values in memory (estimated size 1699.1 KB, free 412.0 MB)
2022-11-10 10:41:04 MemoryStore: INFO: Block broadcast_1_piece0 stored as bytes in memory (estimated size 123.7 KB, free 411.9 MB)
2022-11-10 10:41:04 BlockManagerInfo: INFO: Added broadcast_1_piece0 in memory on compe044.hpc.in.bmrc.ox.ac.uk:41238 (size: 123.7 KB, free: 413.8 MB)
2022-11-10 10:41:04 SparkContext: INFO: Created broadcast 1 from broadcast at SparkBackend.scala:250
2022-11-10 10:41:04 root: INFO: timing SparkBackend.parse_matrix_ir total 1.893s self 1.893s children 0.000ms %children 0.00%
2022-11-10 10:41:04 root: INFO: timing SparkBackend.parse_value_ir total 57.286ms self 57.286ms children 0.000ms %children 0.00%
2022-11-10 10:41:04 root: INFO: starting execution of query hail_query_1 of initial size 8
2022-11-10 10:41:04 root: INFO: optimize optimize: relationalLowerer, initial IR: before: IR size 8: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr9.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (MatrixRowsTable
      (MatrixRead None False False
        "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr9.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
    (InsertFields
      (SelectFields (locus alleles)
        (SelectFields 
          (locus alleles rsid qual filters info)
          (Ref row)))
      None)))
2022-11-10 10:41:04 root: INFO: optimize optimize: relationalLowerer, initial IR: after: IR size 3:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr9.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (MatrixRowsTable
    (MatrixRead
      Matrix{global:Struct{},col_key:[s],col:Struct{s:String},row_key:[[locus,alleles]],row:Struct{locus:Locus(GRCh38),alleles:Array[String]},entry:Struct{}}
      True False
      "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr9.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")))
2022-11-10 10:41:04 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: before: IR size 16: 
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr9.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableMapRows
    (TableMapGlobals
      (TableMapGlobals
        (TableMapRows
          (TableRead
            Table{global:Struct{__cols:Array[Struct{s:String}]},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String],`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`:Array[Struct{}]}}
            False
            "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr9.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}")
          (InsertFields
            (Ref row)
            None
            (`the entries! [877f12a8827e18f61222c6c8c5fb04a8]`
              (MakeArray Array[Struct{}]))))
        (InsertFields
          (Ref global)
          None
          (__cols (MakeArray Array[Struct{s:String}]))))
      (SelectFields () (Ref global)))
    (SelectFields (locus alleles) (Ref row))))
2022-11-10 10:41:05 root: INFO: Prune: InsertFields: eliminating field 'the entries! [877f12a8827e18f61222c6c8c5fb04a8]'
2022-11-10 10:41:05 root: INFO: optimize optimize: relationalLowerer, after LowerMatrixToTable: after: IR size 2:
(TableWrite
  "{\"name\":\"TableNativeWriter\",\"path\":\"data/ht/ukb_wes_450k.qced.chr9.ht\",\"overwrite\":true,\"stageLocally\":false,\"codecSpecJSONStr\":null}"
  (TableRead
    Table{global:Struct{},key:[locus,alleles],row:Struct{locus:Locus(GRCh38),alleles:Array[String]}}
    False
    "{\"files\":[\"data/vcf/ukb_wes_450k.qced.sites_only.chr9.vcf.bgz\"],\"callFields\":[\"PGT\"],\"entryFloatTypeName\":\"Float64\",\"rg\":\"GRCh38\",\"contigRecoding\":{},\"arrayElementsRequired\":true,\"skipInvalidLoci\":false,\"gzAsBGZ\":true,\"forceGZ\":false,\"filterAndReplace\":{},\"partitionsJSON\":null,\"name\":\"MatrixVCFReader\"}"))
2022-11-10 10:41:05 root: INFO: interpreting non compilable node: TableWrite
2022-11-10 10:41:05 SparkContext: INFO: Starting job: runJob at ContextRDD.scala:228
2022-11-10 10:41:05 DAGScheduler: INFO: Got job 0 (runJob at ContextRDD.scala:228) with 1 output partitions
2022-11-10 10:41:05 DAGScheduler: INFO: Final stage: ResultStage 0 (runJob at ContextRDD.scala:228)
2022-11-10 10:41:05 DAGScheduler: INFO: Parents of final stage: List()
2022-11-10 10:41:05 DAGScheduler: INFO: Missing parents: List()
2022-11-10 10:41:05 DAGScheduler: INFO: Submitting ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84), which has no missing parents
2022-11-10 10:41:05 MemoryStore: INFO: Block broadcast_2 stored as values in memory (estimated size 15.4 KB, free 411.9 MB)
2022-11-10 10:41:05 MemoryStore: INFO: Block broadcast_2_piece0 stored as bytes in memory (estimated size 7.4 KB, free 411.9 MB)
2022-11-10 10:41:05 BlockManagerInfo: INFO: Added broadcast_2_piece0 in memory on compe044.hpc.in.bmrc.ox.ac.uk:41238 (size: 7.4 KB, free: 413.8 MB)
2022-11-10 10:41:05 SparkContext: INFO: Created broadcast 2 from broadcast at DAGScheduler.scala:1161
2022-11-10 10:41:05 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 0 (GenericTableValueRDD[1] at RDD at GenericTableValue.scala:84) (first 15 tasks are for partitions Vector(0))
2022-11-10 10:41:05 TaskSchedulerImpl: INFO: Adding task set 0.0 with 1 tasks
2022-11-10 10:41:05 TaskSetManager: INFO: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 8052 bytes)
2022-11-10 10:41:05 Executor: INFO: Running task 0.0 in stage 0.0 (TID 0)
2022-11-10 10:41:05 root: INFO: RegionPool: initialized for thread 51: Executor task launch worker for task 0
2022-11-10 10:41:05 root: INFO: RegionPool: REPORT_THRESHOLD: 256.0K allocated (256.0K blocks / 0 chunks), regions.size = 2, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-10 10:41:05 root: INFO: RegionPool: REPORT_THRESHOLD: 512.0K allocated (512.0K blocks / 0 chunks), regions.size = 6, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-10 10:41:05 root: INFO: RegionPool: REPORT_THRESHOLD: 1.0M allocated (1.0M blocks / 0 chunks), regions.size = 15, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-10 10:41:08 Executor: INFO: Finished task 0.0 in stage 0.0 (TID 0). 1526 bytes result sent to driver
2022-11-10 10:41:08 TaskSetManager: INFO: Finished task 0.0 in stage 0.0 (TID 0) in 3265 ms on localhost (executor driver) (1/1)
2022-11-10 10:41:08 DAGScheduler: INFO: ResultStage 0 (runJob at ContextRDD.scala:228) finished in 3.406 s
2022-11-10 10:41:08 TaskSchedulerImpl: INFO: Removed TaskSet 0.0, whose tasks have all completed, from pool 
2022-11-10 10:41:08 DAGScheduler: INFO: Job 0 finished: runJob at ContextRDD.scala:228, took 3.518339 s
2022-11-10 10:41:09 Hail: INFO: Coerced sorted dataset
2022-11-10 10:41:09 root: INFO: encoder cache miss (0 hits, 1 misses, 0.000)
2022-11-10 10:41:09 root: INFO: instruction count: 3: __C1etypeEncode.<init>
2022-11-10 10:41:09 root: INFO: instruction count: 5: __C1etypeEncode.apply
2022-11-10 10:41:09 root: INFO: instruction count: 3: __C1etypeEncode.__m2ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-10 10:41:09 root: INFO: instruction count: 3: __C3indexwriter.<init>
2022-11-10 10:41:09 root: INFO: instruction count: 234: __C3indexwriter.apply
2022-11-10 10:41:09 root: INFO: instruction count: 445: __C3indexwriter.__m12writeInternalNode
2022-11-10 10:41:09 root: INFO: instruction count: 13: __C3indexwriter.__m13ENCODE_o_tuple_of_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-10 10:41:09 root: INFO: instruction count: 49: __C3indexwriter.__m14ENCODE_r_array_of_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-10 10:41:09 root: INFO: instruction count: 45: __C3indexwriter.__m15ENCODE_r_tuple_of_r_int64ANDr_int64ANDr_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_int64ANDr_int64ANDr_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-10 10:41:09 root: INFO: instruction count: 4: __C3indexwriter.__m16ENCODE_r_int64_TO_r_int64
2022-11-10 10:41:09 root: INFO: instruction count: 19: __C3indexwriter.__m17ENCODE_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-10 10:41:09 root: INFO: instruction count: 23: __C3indexwriter.__m18ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-10 10:41:09 root: INFO: instruction count: 16: __C3indexwriter.__m19ENCODE_r_binary_TO_r_binary
2022-11-10 10:41:09 root: INFO: instruction count: 4: __C3indexwriter.__m20ENCODE_r_int32_TO_r_int32
2022-11-10 10:41:09 root: INFO: instruction count: 53: __C3indexwriter.__m21ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-10 10:41:09 root: INFO: instruction count: 3: __C3indexwriter.__m22ENCODE_r_tuple_of_END_TO_r_struct_of_END
2022-11-10 10:41:09 root: INFO: instruction count: 379: __C3indexwriter.__m23writeLeafNode
2022-11-10 10:41:09 root: INFO: instruction count: 23: __C3indexwriter.__m24ENCODE_o_tuple_of_r_int64ANDr_array_of_r_tuple_of_r_tuple_of_r_locusANDr_array_of_r_stringENDANDr_int64ANDr_tuple_of_ENDENDEND_TO_o_struct_of_r_int64ANDr_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDENDEND
2022-11-10 10:41:09 root: INFO: instruction count: 49: __C3indexwriter.__m25ENCODE_r_array_of_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_array_of_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-10 10:41:09 root: INFO: instruction count: 25: __C3indexwriter.__m26ENCODE_r_tuple_of_r_tuple_of_r_tuple_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_tuple_of_ENDEND_TO_r_struct_of_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryENDANDr_int64ANDr_struct_of_ENDEND
2022-11-10 10:41:09 root: INFO: instruction count: 52: __C3indexwriter.__m27flush
2022-11-10 10:41:09 root: INFO: instruction count: 150: __C3indexwriter.init
2022-11-10 10:41:09 root: INFO: instruction count: 4: __C3indexwriter.setObjects
2022-11-10 10:41:09 root: INFO: instruction count: 28: __C3indexwriter.close
2022-11-10 10:41:09 root: INFO: instruction count: 7: __C3indexwriter.trackedOS
2022-11-10 10:41:09 root: INFO: instruction count: 9: __C3indexwriter.setPartitionIndex
2022-11-10 10:41:09 root: INFO: instruction count: 4: __C3indexwriter.addPartitionRegion
2022-11-10 10:41:09 root: INFO: instruction count: 3: __C29FSContainer.<init>
2022-11-10 10:41:09 root: INFO: instruction count: 28: __C29FSContainer.init_filesystem
2022-11-10 10:41:09 root: INFO: instruction count: 3: __C29FSContainer.<clinit>
2022-11-10 10:41:09 root: INFO: encoder cache miss (0 hits, 2 misses, 0.000)
2022-11-10 10:41:09 root: INFO: instruction count: 3: __C32etypeEncode.<init>
2022-11-10 10:41:09 root: INFO: instruction count: 5: __C32etypeEncode.apply
2022-11-10 10:41:09 root: INFO: instruction count: 19: __C32etypeEncode.__m33ENCODE_r_tuple_of_r_locusANDr_array_of_r_stringEND_TO_r_struct_of_r_struct_of_r_binaryANDr_int32ENDANDr_array_of_r_binaryEND
2022-11-10 10:41:09 root: INFO: instruction count: 23: __C32etypeEncode.__m34ENCODE_r_tuple_of_r_binaryANDr_int32END_TO_r_struct_of_r_binaryANDr_int32END
2022-11-10 10:41:09 root: INFO: instruction count: 16: __C32etypeEncode.__m35ENCODE_r_binary_TO_r_binary
2022-11-10 10:41:09 root: INFO: instruction count: 4: __C32etypeEncode.__m36ENCODE_r_int32_TO_r_int32
2022-11-10 10:41:09 root: INFO: instruction count: 53: __C32etypeEncode.__m37ENCODE_r_array_of_r_binary_TO_r_array_of_r_binary
2022-11-10 10:41:10 SparkContext: INFO: Starting job: collect at ContextRDD.scala:166
2022-11-10 10:41:10 DAGScheduler: INFO: Got job 1 (collect at ContextRDD.scala:166) with 1 output partitions
2022-11-10 10:41:10 DAGScheduler: INFO: Final stage: ResultStage 1 (collect at ContextRDD.scala:166)
2022-11-10 10:41:10 DAGScheduler: INFO: Parents of final stage: List()
2022-11-10 10:41:10 DAGScheduler: INFO: Missing parents: List()
2022-11-10 10:41:10 DAGScheduler: INFO: Submitting ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160), which has no missing parents
2022-11-10 10:41:10 MemoryStore: INFO: Block broadcast_3 stored as values in memory (estimated size 312.3 KB, free 411.6 MB)
2022-11-10 10:41:10 MemoryStore: INFO: Block broadcast_3_piece0 stored as bytes in memory (estimated size 114.5 KB, free 411.5 MB)
2022-11-10 10:41:10 BlockManagerInfo: INFO: Added broadcast_3_piece0 in memory on compe044.hpc.in.bmrc.ox.ac.uk:41238 (size: 114.5 KB, free: 413.7 MB)
2022-11-10 10:41:10 SparkContext: INFO: Created broadcast 3 from broadcast at DAGScheduler.scala:1161
2022-11-10 10:41:10 DAGScheduler: INFO: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[4] at mapPartitions at ContextRDD.scala:160) (first 15 tasks are for partitions Vector(0))
2022-11-10 10:41:10 TaskSchedulerImpl: INFO: Adding task set 1.0 with 1 tasks
2022-11-10 10:41:10 TaskSetManager: INFO: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 8057 bytes)
2022-11-10 10:41:10 Executor: INFO: Running task 0.0 in stage 1.0 (TID 1)
2022-11-10 10:41:10 root: INFO: RegionPool: REPORT_THRESHOLD: 2.0M allocated (1.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-10 10:41:11 root: INFO: RegionPool: REPORT_THRESHOLD: 4.0M allocated (3.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-10 10:41:11 root: INFO: RegionPool: REPORT_THRESHOLD: 8.0M allocated (7.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 5
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 17
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 4
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 20
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 18
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 3
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 25
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 19
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 23
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 21
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 9
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 14
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 22
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 15
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 24
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 12
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 1
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 10
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 6
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 8
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 7
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 13
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 16
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 2
2022-11-10 10:41:11 ContextCleaner: INFO: Cleaned accumulator 11
2022-11-10 10:41:11 BlockManagerInfo: INFO: Removed broadcast_2_piece0 on compe044.hpc.in.bmrc.ox.ac.uk:41238 in memory (size: 7.4 KB, free: 413.7 MB)
2022-11-10 10:41:12 root: INFO: RegionPool: REPORT_THRESHOLD: 16.0M allocated (15.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-10 10:41:13 root: INFO: RegionPool: REPORT_THRESHOLD: 32.0M allocated (31.7M blocks / 320.0K chunks), regions.size = 27, 0 current java objects, 0 max java objects, thread 51: Executor task launch worker for task 0
2022-11-10 10:41:14 Executor: INFO: Finished task 0.0 in stage 1.0 (TID 1). 916 bytes result sent to driver
2022-11-10 10:41:14 TaskSetManager: INFO: Finished task 0.0 in stage 1.0 (TID 1) in 4275 ms on localhost (executor driver) (1/1)
2022-11-10 10:41:14 DAGScheduler: INFO: ResultStage 1 (collect at ContextRDD.scala:166) finished in 4.307 s
2022-11-10 10:41:14 DAGScheduler: INFO: Job 1 finished: collect at ContextRDD.scala:166, took 4.313655 s
2022-11-10 10:41:14 TaskSchedulerImpl: INFO: Removed TaskSet 1.0, whose tasks have all completed, from pool 
2022-11-10 10:41:14 Hail: INFO: wrote table with 756948 rows in 1 partition to data/ht/ukb_wes_450k.qced.chr9.ht
    Total size: 9.24 MiB
    * Rows: 9.24 MiB
    * Globals: 11.00 B
    * Smallest partition: 756948 rows (9.24 MiB)
    * Largest partition:  756948 rows (9.24 MiB)
2022-11-10 10:41:14 root: INFO: took 9.675s
2022-11-10 10:41:14 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: before: IR size 1: 
(Begin)
2022-11-10 10:41:14 root: INFO: optimize optimize: relationalLowerer, after InterpretNonCompilable: after: IR size 1:
(Begin)
2022-11-10 10:41:14 root: INFO: finished execution of query hail_query_1
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON total 9.963s self 44.911ms children 9.918s %children 99.55%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR total 165.668ms self 0.718ms children 164.950ms %children 99.57%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.343ms self 0.343ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation total 164.564ms self 104.633ms children 59.931ms %children 36.42%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize total 59.931ms self 1.711ms children 58.221ms %children 97.15%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 3.621ms self 3.621ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 6.316ms self 6.316ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 15.028ms self 15.028ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 9.799ms self 9.799ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 1.615ms self 1.615ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 19.750ms self 19.750ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.164ms self 0.164ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.081ms self 0.081ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.148ms self 0.148ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.332ms self 0.332ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.024ms self 0.024ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.455ms self 0.455ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/FoldConstants total 0.103ms self 0.103ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.014ms self 0.014ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/Simplify total 0.061ms self 0.061ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardLets total 0.273ms self 0.273ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/ForwardRelationalLets total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/LoweringTransformation/Optimize/PruneDeadFields total 0.415ms self 0.415ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, initial IR/Verify total 0.043ms self 0.043ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable total 12.196ms self 0.020ms children 12.177ms %children 99.84%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.005ms self 0.005ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/LoweringTransformation total 12.055ms self 12.055ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/LowerMatrixToTable/Verify total 0.118ms self 0.118ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable total 56.641ms self 0.017ms children 56.624ms %children 99.97%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.020ms self 0.020ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation total 56.593ms self 17.002ms children 39.592ms %children 69.96%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize total 39.592ms self 0.121ms children 39.471ms %children 99.70%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 16.181ms self 16.181ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.254ms self 0.254ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 7.849ms self 7.849ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 7.554ms self 7.554ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.091ms self 0.091ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 5.805ms self 5.805ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.220ms self 0.220ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.146ms self 0.146ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.254ms self 0.254ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.292ms self 0.292ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.022ms self 0.022ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.245ms self 0.245ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/FoldConstants total 0.085ms self 0.085ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.022ms self 0.022ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/Simplify total 0.036ms self 0.036ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardLets total 0.219ms self 0.219ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.020ms self 0.020ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/LoweringTransformation/Optimize/PruneDeadFields total 0.175ms self 0.175ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after LowerMatrixToTable/Verify total 0.011ms self 0.011ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable total 9.682s self 0.020ms children 9.682s %children 100.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.006ms self 0.006ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/LoweringTransformation total 9.682s self 9.682s children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/InterpretNonCompilable/Verify total 0.319ms self 0.319ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable total 1.414ms self 0.011ms children 1.403ms %children 99.21%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.006ms self 0.006ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation total 1.390ms self 0.600ms children 0.789ms %children 56.81%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize total 0.789ms self 0.049ms children 0.740ms %children 93.73%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/FoldConstants total 0.100ms self 0.100ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ExtractIntervalFilters total 0.274ms self 0.274ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/Simplify total 0.062ms self 0.062ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardLets total 0.188ms self 0.188ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/ForwardRelationalLets total 0.021ms self 0.021ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/LoweringTransformation/Optimize/PruneDeadFields total 0.095ms self 0.095ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/optimize: relationalLowerer, after InterpretNonCompilable/Verify total 0.007ms self 0.007ms children 0.000ms %children 0.00%
2022-11-10 10:41:14 root: INFO: timing SparkBackend.executeJSON/convertRegionValueToAnnotation total 0.019ms self 0.019ms children 0.000ms %children 0.00%
2022-11-10 10:41:15 SparkContext: INFO: Invoking stop() from shutdown hook
2022-11-10 10:41:15 AbstractConnector: INFO: Stopped Spark@1d26a1ec{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2022-11-10 10:41:15 SparkUI: INFO: Stopped Spark web UI at http://compe044.hpc.in.bmrc.ox.ac.uk:4040
2022-11-10 10:41:15 MapOutputTrackerMasterEndpoint: INFO: MapOutputTrackerMasterEndpoint stopped!
2022-11-10 10:41:15 MemoryStore: INFO: MemoryStore cleared
2022-11-10 10:41:15 BlockManager: INFO: BlockManager stopped
2022-11-10 10:41:15 BlockManagerMaster: INFO: BlockManagerMaster stopped
2022-11-10 10:41:15 OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: INFO: OutputCommitCoordinator stopped!
2022-11-10 10:41:15 SparkContext: INFO: Successfully stopped SparkContext
2022-11-10 10:41:15 ShutdownHookManager: INFO: Shutdown hook called
2022-11-10 10:41:15 ShutdownHookManager: INFO: Deleting directory /tmp/spark-4b95188c-4ae8-4620-9fee-51709917f28e/pyspark-cec928da-0fdc-4d9f-9aeb-42c784cdfef7
2022-11-10 10:41:15 ShutdownHookManager: INFO: Deleting directory /tmp/spark-19d8648c-4db4-4aa9-a564-92537a0e4f8b
2022-11-10 10:41:15 ShutdownHookManager: INFO: Deleting directory /tmp/spark-4b95188c-4ae8-4620-9fee-51709917f28e
